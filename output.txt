INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.128s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.017s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.165s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.007s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.168s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.067s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.161s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.182s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.060s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.073s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 6.895s]> Epoch [1/1] | loss: 0.0862, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.971s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.343s]> Epoch [1/1] | loss: 0.0850, test loss: 0.0868, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.902s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:47  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.053s]> Epoch [1/1] | loss: 0.0860, test loss: 0.0881, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.891s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.465s]> Epoch [1/1] | loss: 0.0821, test loss: 0.0646, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.566s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a84.91]-[f0.7056]-[p0.9184]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.84      1.00      0.91        41

    accuracy                           0.85        53
   macro avg       0.92      0.67      0.71        53
weighted avg       0.87      0.85      0.82        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.333333    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.836735    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.911111    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.873700    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.818029    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.918367    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.705556    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.287s]> Epoch [1/1] | loss: 0.0746, test loss: 0.0454, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.406s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a83.02]-[f0.7948]-[p0.7748]-[r0.8608].pt"
              precision    recall  f1-score   support

           0       0.58      0.92      0.71        12
           1       0.97      0.80      0.88        41

    accuracy                           0.83        53
   macro avg       0.77      0.86      0.79        53
weighted avg       0.88      0.83      0.84        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.578947    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.916667    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.709677    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.970588    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.804878    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.880000    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.881915    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.830189    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.841436    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.774768    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.860772    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.794839    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.830189    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.777s]> Epoch [1/1] | loss: 0.0855, test loss: 0.0880, lr: 0.001000
Log [0.0h, 0.0m, 0.006s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.482s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.309s]> Epoch [1/1] | loss: 0.0855, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.514s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.952s]> Epoch [1/1] | loss: 0.0851, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.392s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.792s]> Epoch [1/1] | loss: 0.0757, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.008s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.329s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.970s]> Epoch [1/1] | loss: 0.0853, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.367s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.340s]> Epoch [1/1] | loss: 0.0774, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.187s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 7.542s]> Epoch [1/1] | loss: 0.0834, test loss: 0.0861, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.267s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:48  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.142s]> Epoch [1/1] | loss: 0.0850, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.384s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.692s]> Epoch [1/1] | loss: 0.0859, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.223s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.285s]> Epoch [1/1] | loss: 0.0817, test loss: 0.0881, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.356s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:21:49  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.148s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.166s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.194s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.179s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.229s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.142s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.229s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.142s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.268s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.054s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.383s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 9.907s]> Epoch [1/1] | loss: 0.0856, test loss: 0.0439, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.333s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.837s]> Epoch [1/1] | loss: 0.0863, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.301s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.717s]> Epoch [1/1] | loss: 0.0854, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.519s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.555s]> Epoch [1/1] | loss: 0.0860, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.017s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.977s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.982s]> Epoch [1/1] | loss: 0.0850, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.934s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.156s]> Epoch [1/1] | loss: 0.0870, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.030s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 9.916s]> Epoch [1/1] | loss: 0.0864, test loss: 0.0454, lr: 0.001000
Log [0.0h, 0.0m, 0.008s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.316s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.469s]> Epoch [1/1] | loss: 0.0837, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.257s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 10.533s]> Epoch [1/1] | loss: 0.0850, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.866s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.188s]> Epoch [1/1] | loss: 0.0845, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.271s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:09  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.227s]> Epoch [1/1] | loss: 0.0705, test loss: 0.0614, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.936s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a51.80]-[f0.4323]-[p0.5266]-[r0.5734].pt"
              precision    recall  f1-score   support

           0       0.13      0.64      0.21        14
           1       0.93      0.50      0.65       125

    accuracy                           0.52       139
   macro avg       0.53      0.57      0.43       139
weighted avg       0.85      0.52      0.61       139

Log [0.0h, 0.0m, 10.694s]> Epoch [1/1] | loss: 0.0721, test loss: 0.0556, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.713s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a61.15]-[f0.4845]-[p0.5353]-[r0.5937].pt"
              precision    recall  f1-score   support

           0       0.14      0.57      0.23        14
           1       0.93      0.62      0.74       125

    accuracy                           0.61       139
   macro avg       0.54      0.59      0.48       139
weighted avg       0.85      0.61      0.69       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.142857    14.0
1   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.228571    14.0
3   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.927711   125.0
4   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.616000   125.0
5   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.740385   125.0
6   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.848661   139.0
7   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.611511   139.0
8   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.688835   139.0
9   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.535284   139.0
10  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.593714   139.0
11  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.484478   139.0
12  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.611511   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.515s]> Epoch [1/1] | loss: 0.0866, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.978s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.732s]> Epoch [1/1] | loss: 0.0849, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.026s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.092s]> Epoch [1/1] | loss: 0.0798, test loss: 0.0589, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.582s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/transformer-[a51.08]-[f0.4200]-[p0.5137]-[r0.5377].pt"
              precision    recall  f1-score   support

           0       0.11      0.57      0.19        14
           1       0.91      0.50      0.65       125

    accuracy                           0.51       139
   macro avg       0.51      0.54      0.42       139
weighted avg       0.83      0.51      0.60       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.114286    14.0
1   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.190476    14.0
3   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.913043   125.0
4   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.504000   125.0
5   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.649485   125.0
6   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.832593   139.0
7   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.510791   139.0
8   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.603253   139.0
9   2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.513665   139.0
10  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.537714   139.0
11  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.419980   139.0
12  2025-04-14 07:22:10  A-1-1cn --> E-2-2cn  ...  0.510791   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.060s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.013s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.159s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.252s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.225s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.215s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.070s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.166s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.222s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 7.865s]> Epoch [1/1] | loss: 0.0831, test loss: 0.1206, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.340s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:26  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.884s]> Epoch [1/1] | loss: 0.0857, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.349s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.395s]> Epoch [1/1] | loss: 0.0854, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.344s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.587s]> Epoch [1/1] | loss: 0.0707, test loss: 0.1112, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.268s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.5611]-[p0.5938]-[r0.5659].pt"
              precision    recall  f1-score   support

           0       0.50      0.29      0.36         7
           1       0.69      0.85      0.76        13

    accuracy                           0.65        20
   macro avg       0.59      0.57      0.56        20
weighted avg       0.62      0.65      0.62        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.363636     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.687500    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.758621    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.621875    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.620376    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.593750    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.565934    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.561129    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.711s]> Epoch [1/1] | loss: 0.0865, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.201s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.406s]> Epoch [1/1] | loss: 0.0837, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.248s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.091s]> Epoch [1/1] | loss: 0.0866, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.200s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:27  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.197s]> Epoch [1/1] | loss: 0.0866, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.579s]> Epoch [1/1] | loss: 0.0852, test loss: 0.1298, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.143s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.610s]> Epoch [1/1] | loss: 0.0819, test loss: 0.1337, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.280s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a60.00]-[f0.3750]-[p0.3158]-[r0.4615].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.63      0.92      0.75        13

    accuracy                           0.60        20
   macro avg       0.32      0.46      0.38        20
weighted avg       0.41      0.60      0.49        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.631579    13.0
4   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.750000    13.0
6   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.410526    20.0
7   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.600000    20.0
8   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.487500    20.0
9   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.315789    20.0
10  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.461538    20.0
11  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.375000    20.0
12  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.600000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.758s]> Epoch [1/1] | loss: 0.0866, test loss: 0.1300, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.158s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.305s]> Epoch [1/1] | loss: 0.0778, test loss: 0.1208, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.117s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.4982]-[p0.5833]-[r0.5330].pt"
              precision    recall  f1-score   support

           0       0.50      0.14      0.22         7
           1       0.67      0.92      0.77        13

    accuracy                           0.65        20
   macro avg       0.58      0.53      0.50        20
weighted avg       0.61      0.65      0.58        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.142857     7.0
2   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.222222     7.0
3   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.666667    13.0
4   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.774194    13.0
6   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.608333    20.0
7   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.581004    20.0
9   2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.583333    20.0
10  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.532967    20.0
11  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.498208    20.0
12  2025-04-14 07:22:28  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.210s]> Epoch [1/1] | loss: 0.0751, test loss: 0.0812, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.098s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a55.00]-[f0.5489]-[p0.6310]-[r0.6209].pt"
              precision    recall  f1-score   support

           0       0.43      0.86      0.57         7
           1       0.83      0.38      0.53        13

    accuracy                           0.55        20
   macro avg       0.63      0.62      0.55        20
weighted avg       0.69      0.55      0.54        20

Log [0.0h, 0.0m, 9.542s]> Epoch [1/1] | loss: 0.0788, test loss: 0.0821, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.162s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a80.00]-[f0.7619]-[p0.8000]-[r0.7473].pt"
              precision    recall  f1-score   support

           0       0.80      0.57      0.67         7
           1       0.80      0.92      0.86        13

    accuracy                           0.80        20
   macro avg       0.80      0.75      0.76        20
weighted avg       0.80      0.80      0.79        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000     7.0
1   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.571429     7.0
2   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.666667     7.0
3   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000    13.0
4   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.857143    13.0
6   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000    20.0
7   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000    20.0
8   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.790476    20.0
9   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000    20.0
10  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.747253    20.0
11  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.761905    20.0
12  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.800000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.413s]> Epoch [1/1] | loss: 0.0861, test loss: 0.1301, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.085s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:22:29  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.266s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.282s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.212s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.072s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.065s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.215s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.079s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.237s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.204s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.183s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.220s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 8.260s]> Epoch [1/1] | loss: 0.0793, test loss: 0.1672, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.344s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a66.67]-[f0.6541]-[p0.7083]-[r0.7812].pt"
              precision    recall  f1-score   support

           0       1.00      0.56      0.72        16
           1       0.42      1.00      0.59         5

    accuracy                           0.67        21
   macro avg       0.71      0.78      0.65        21
weighted avg       0.86      0.67      0.69        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.562500    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.720000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.416667     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.588235     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.861111    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.666667    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.688627    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.708333    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.781250    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.654118    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.666667    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.899s]> Epoch [1/1] | loss: 0.0870, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.353s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.703s]> Epoch [1/1] | loss: 0.0827, test loss: 0.1861, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.273s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.269s]> Epoch [1/1] | loss: 0.0869, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.313s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.597s]> Epoch [1/1] | loss: 0.0841, test loss: 0.2697, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.384s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.718s]> Epoch [1/1] | loss: 0.0864, test loss: 0.2699, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.162s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:46  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.924s]> Epoch [1/1] | loss: 0.0858, test loss: 0.2695, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.405s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.992s]> Epoch [1/1] | loss: 0.0859, test loss: 0.2698, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.181s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.917s]> Epoch [1/1] | loss: 0.0796, test loss: 0.0772, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.136s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.888889    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.941176    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.750000     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.915344    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.895658    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.944444    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.845588    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.554s]> Epoch [1/1] | loss: 0.0863, test loss: 0.2685, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.198s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.541s]> Epoch [1/1] | loss: 0.0853, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.136s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.266s]> Epoch [1/1] | loss: 0.0832, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.113s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.048s]> Epoch [1/1] | loss: 0.0789, test loss: 0.0961, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.097s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.841s]> Epoch [1/1] | loss: 0.0729, test loss: 0.2114, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.098s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a47.62]-[f0.4762]-[p0.6562]-[r0.6562].pt"
              precision    recall  f1-score   support

           0       1.00      0.31      0.48        16
           1       0.31      1.00      0.48         5

    accuracy                           0.48        21
   macro avg       0.66      0.66      0.48        21
weighted avg       0.84      0.48      0.48        21

                   date    transfer_strategy  ...     perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.00000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.31250    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.31250     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.00000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.83631    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.65625    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.65625    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.47619    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.152s]> Epoch [1/1] | loss: 0.0864, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.143s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:22:47  A-1-1cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.185s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.148s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.181s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.213s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.230s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.176s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.179s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.066s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.216s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.156s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 7.798s]> Epoch [1/1] | loss: 0.0460, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.089s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:05  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.162s]> Epoch [1/1] | loss: 0.0460, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.815s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 7.716s]> Epoch [1/1] | loss: 0.0460, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.795s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.969s]> Epoch [1/1] | loss: 0.0462, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.073s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.575s]> Epoch [1/1] | loss: 0.0469, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.016s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.953s]> Epoch [1/1] | loss: 0.0455, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.327s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 7.906s]> Epoch [1/1] | loss: 0.0472, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.914s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.100s]> Epoch [1/1] | loss: 0.0462, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.696s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.800s]> Epoch [1/1] | loss: 0.0457, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.003s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:06  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.431s]> Epoch [1/1] | loss: 0.0445, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.233s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.164s]> Epoch [1/1] | loss: 0.0457, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.741s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.782s]> Epoch [1/1] | loss: 0.0465, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.997s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.829s]> Epoch [1/1] | loss: 0.0461, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.806s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.665s]> Epoch [1/1] | loss: 0.0465, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.020s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.704s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.557s]> Epoch [1/1] | loss: 0.0460, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.018s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:23:07  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.072s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 4.648s]> Epoch [1/1] | loss: 0.0451, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.416s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:20  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.563s]> Epoch [1/1] | loss: 0.0465, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.533s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.161s]> Epoch [1/1] | loss: 0.0455, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.277s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.426s]> Epoch [1/1] | loss: 0.0452, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.278s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.277s]> Epoch [1/1] | loss: 0.0457, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.022s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.422s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:21  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.925s]> Epoch [1/1] | loss: 0.0462, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.354s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.452s]> Epoch [1/1] | loss: 0.0451, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.209s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

Log [0.0h, 0.0m, 6.015s]> Epoch [1/1] | loss: 0.0461, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.313s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.187s]> Epoch [1/1] | loss: 0.0453, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.347s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.992s]> Epoch [1/1] | loss: 0.0453, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.186s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.523s]> Epoch [1/1] | loss: 0.0452, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.120s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.286s]> Epoch [1/1] | loss: 0.0456, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.282s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.463s]> Epoch [1/1] | loss: 0.0460, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.198s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.265s]> Epoch [1/1] | loss: 0.0451, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.016s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.216s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.424s]> Epoch [1/1] | loss: 0.0446, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.118s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:23:22  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.064s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.063s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.193s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.066s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 4.387s]> Epoch [1/1] | loss: 0.0464, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.581s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:36  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.553s]> Epoch [1/1] | loss: 0.0474, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.362s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.687s]> Epoch [1/1] | loss: 0.0456, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.318s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.191s]> Epoch [1/1] | loss: 0.0448, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.342s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.955s]> Epoch [1/1] | loss: 0.0456, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.343s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.329s]> Epoch [1/1] | loss: 0.0456, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.190s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.878s]> Epoch [1/1] | loss: 0.0461, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.196s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:37  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.059s]> Epoch [1/1] | loss: 0.0450, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.202s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.293s]> Epoch [1/1] | loss: 0.0457, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.264s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.213s]> Epoch [1/1] | loss: 0.0457, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.190s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

Log [0.0h, 0.0m, 6.266s]> Epoch [1/1] | loss: 0.0465, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.506s]> Epoch [1/1] | loss: 0.0466, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.118s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.497s]> Epoch [1/1] | loss: 0.0456, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.201s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.024s]> Epoch [1/1] | loss: 0.0461, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.109s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.229s]> Epoch [1/1] | loss: 0.0460, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.159s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:23:38  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.139s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.060s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 4.810s]> Epoch [1/1] | loss: 0.0443, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.352s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:51  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.108s]> Epoch [1/1] | loss: 0.0456, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.364s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.051s]> Epoch [1/1] | loss: 0.0441, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.459s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.164s]> Epoch [1/1] | loss: 0.0466, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.253s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.244s]> Epoch [1/1] | loss: 0.0455, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.248s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:52  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.366s]> Epoch [1/1] | loss: 0.0438, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.254s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.918s]> Epoch [1/1] | loss: 0.0462, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.175s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.932s]> Epoch [1/1] | loss: 0.0449, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.192s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.755s]> Epoch [1/1] | loss: 0.0458, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.309s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.713s]> Epoch [1/1] | loss: 0.0463, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.115s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.589s]> Epoch [1/1] | loss: 0.0460, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.152s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.487s]> Epoch [1/1] | loss: 0.0460, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.099s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:53  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.701s]> Epoch [1/1] | loss: 0.0465, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.017s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.224s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.396s]> Epoch [1/1] | loss: 0.0457, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.705s]> Epoch [1/1] | loss: 0.0470, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.078s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:23:54  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.215s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.194s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.135s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.273s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.056s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.060s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.249s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 5.292s]> Epoch [1/1] | loss: 0.1061, test loss: 0.0640, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.076s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a76.05]-[f0.6891]-[p0.6771]-[r0.7165].pt"
              precision    recall  f1-score   support

           0       0.47      0.64      0.54        58
           1       0.89      0.80      0.84       205

    accuracy                           0.76       263
   macro avg       0.68      0.72      0.69       263
weighted avg       0.79      0.76      0.77       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.468354    58.0
1   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.637931    58.0
2   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.540146    58.0
3   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.885870   205.0
4   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.795122   205.0
5   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.838046   205.0
6   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.793794   263.0
7   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.760456   263.0
8   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.772350   263.0
9   2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.677112   263.0
10  2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.716526   263.0
11  2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.689096   263.0
12  2025-04-14 07:24:09  O-2-2cn --> A-1-1cn  ...  0.760456   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.902s]> Epoch [1/1] | loss: 0.1181, test loss: 0.0852, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.883s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.174s]> Epoch [1/1] | loss: 0.1010, test loss: 0.0681, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.093s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a78.33]-[f0.4559]-[p0.8912]-[r0.5086].pt"
              precision    recall  f1-score   support

           0       1.00      0.02      0.03        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.89      0.51      0.46       263
weighted avg       0.83      0.78      0.69       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.017241    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.033898    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.782443   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.877944   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.830421   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.783270   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.691805   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.891221   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.508621   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.455921   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.783270   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.769s]> Epoch [1/1] | loss: 0.1297, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.321s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.261s]> Epoch [1/1] | loss: 0.1308, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.445s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.142s]> Epoch [1/1] | loss: 0.1062, test loss: 0.0800, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.841s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 5.185s]> Epoch [1/1] | loss: 0.1023, test loss: 0.0797, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.246s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.152s]> Epoch [1/1] | loss: 0.1206, test loss: 0.0773, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.550s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.475s]> Epoch [1/1] | loss: 0.1240, test loss: 0.0573, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.066s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a83.65]-[f0.7719]-[p0.7622]-[r0.7839].pt"
              precision    recall  f1-score   support

           0       0.62      0.69      0.65        58
           1       0.91      0.88      0.89       205

    accuracy                           0.84       263
   macro avg       0.76      0.78      0.77       263
weighted avg       0.84      0.84      0.84       263

Log [0.0h, 0.0m, 5.542s]> Epoch [1/1] | loss: 0.1267, test loss: 0.0784, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.160s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.499s]> Epoch [1/1] | loss: 0.1045, test loss: 0.0861, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.812s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.200s]> Epoch [1/1] | loss: 0.1119, test loss: 0.0859, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.827s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.287s]> Epoch [1/1] | loss: 0.1344, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.078s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.384s]> Epoch [1/1] | loss: 0.1409, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.139s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:10  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.109s]> Epoch [1/1] | loss: 0.0878, test loss: 0.0861, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.816s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:24:11  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.160s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.185s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.158s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.063s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 4.147s]> Epoch [1/1] | loss: 0.1198, test loss: 0.0448, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.150s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:24  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.610s]> Epoch [1/1] | loss: 0.0952, test loss: 0.0438, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.248s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a76.98]-[f0.5680]-[p0.5633]-[r0.6183].pt"
              precision    recall  f1-score   support

           0       0.20      0.43      0.27        14
           1       0.93      0.81      0.86       125

    accuracy                           0.77       139
   macro avg       0.56      0.62      0.57       139
weighted avg       0.85      0.77      0.80       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.200000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.428571    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.272727    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.926606   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.863248   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.853422   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.769784   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.803771   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.563303   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.618286   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.567988   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.769784   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.451s]> Epoch [1/1] | loss: 0.1159, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.172s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.399s]> Epoch [1/1] | loss: 0.1215, test loss: 0.0454, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.574s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 3.353s]> Epoch [1/1] | loss: 0.1151, test loss: 0.0444, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.186s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 3.765s]> Epoch [1/1] | loss: 0.1278, test loss: 0.0449, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.146s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.575s]> Epoch [1/1] | loss: 0.1312, test loss: 0.0454, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.083s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.441s]> Epoch [1/1] | loss: 0.0850, test loss: 0.0428, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.924s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 4.641s]> Epoch [1/1] | loss: 0.1136, test loss: 0.0431, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.044s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.952s]> Epoch [1/1] | loss: 0.1205, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.092s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.575s]> Epoch [1/1] | loss: 0.1297, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.782s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.762s]> Epoch [1/1] | loss: 0.1282, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.297s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:24:25  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.339s]> Epoch [1/1] | loss: 0.0868, test loss: 0.0426, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.861s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 5.138s]> Epoch [1/1] | loss: 0.1000, test loss: 0.0603, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.759s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a11.51]-[f0.1085]-[p0.5511]-[r0.5080].pt"
              precision    recall  f1-score   support

           0       0.10      1.00      0.19        14
           1       1.00      0.02      0.03       125

    accuracy                           0.12       139
   macro avg       0.55      0.51      0.11       139
weighted avg       0.91      0.12      0.05       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.102190    14.0
1   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  1.000000    14.0
2   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.185430    14.0
3   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
4   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.016000   125.0
5   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.031496   125.0
6   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.909573   139.0
7   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.115108   139.0
8   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.047000   139.0
9   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.551095   139.0
10  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.508000   139.0
11  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.108463   139.0
12  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.115108   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.355s]> Epoch [1/1] | loss: 0.0867, test loss: 0.0416, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.699s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/transformer-[a92.09]-[f0.7583]-[p0.7908]-[r0.7340].pt"
              precision    recall  f1-score   support

           0       0.64      0.50      0.56        14
           1       0.95      0.97      0.96       125

    accuracy                           0.92       139
   macro avg       0.79      0.73      0.76       139
weighted avg       0.91      0.92      0.92       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.636364    14.0
1   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.560000    14.0
3   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.945312   125.0
4   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.968000   125.0
5   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.956522   125.0
6   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.914195   139.0
7   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.920863   139.0
8   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.916584   139.0
9   2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.790838   139.0
10  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.734000   139.0
11  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.758261   139.0
12  2025-04-14 07:24:26  O-2-2cn --> E-2-2cn  ...  0.920863   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 2.645s]> Epoch [1/1] | loss: 0.1041, test loss: 0.1116, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.053s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 3.196s]> Epoch [1/1] | loss: 0.0935, test loss: 0.1255, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.053s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.237s]> Epoch [1/1] | loss: 0.1207, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.136s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.060s]> Epoch [1/1] | loss: 0.0943, test loss: 0.1435, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.073s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 2.838s]> Epoch [1/1] | loss: 0.0908, test loss: 0.1465, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.056s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:37  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 2.762s]> Epoch [1/1] | loss: 0.0813, test loss: 0.1314, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.050s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 3.337s]> Epoch [1/1] | loss: 0.0974, test loss: 0.1104, lr: 0.001000
Log [0.0h, 0.0m, 0.014s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.094s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 2.889s]> Epoch [1/1] | loss: 0.1250, test loss: 0.1469, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.062s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 2.896s]> Epoch [1/1] | loss: 0.0943, test loss: 0.1420, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.096s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.196s]> Epoch [1/1] | loss: 0.1268, test loss: 0.1465, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.051s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.328s]> Epoch [1/1] | loss: 0.0955, test loss: 0.1395, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.082s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.140s]> Epoch [1/1] | loss: 0.1281, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.049s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.080s]> Epoch [1/1] | loss: 0.1326, test loss: 0.1177, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.055s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:38  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.165s]> Epoch [1/1] | loss: 0.1250, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.044s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 2.883s]> Epoch [1/1] | loss: 0.1305, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.104s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:24:39  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.056s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 3.095s]> Epoch [1/1] | loss: 0.1206, test loss: 0.2696, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.208s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 2.771s]> Epoch [1/1] | loss: 0.1216, test loss: 0.2654, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.134s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 3.414s]> Epoch [1/1] | loss: 0.0932, test loss: 0.2608, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.204s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 2.923s]> Epoch [1/1] | loss: 0.0984, test loss: 0.2593, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.144s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 3.199s]> Epoch [1/1] | loss: 0.1326, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.108s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.324s]> Epoch [1/1] | loss: 0.1230, test loss: 0.1685, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.275s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a42.86]-[f0.4273]-[p0.6471]-[r0.6250].pt"
              precision    recall  f1-score   support

           0       1.00      0.25      0.40        16
           1       0.29      1.00      0.45         5

    accuracy                           0.43        21
   macro avg       0.65      0.62      0.43        21
weighted avg       0.83      0.43      0.41        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.250000    16.0
2   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.400000    16.0
3   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.294118     5.0
4   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.454545     5.0
6   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.831933    21.0
7   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.428571    21.0
8   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.412987    21.0
9   2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.647059    21.0
10  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.625000    21.0
11  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.427273    21.0
12  2025-04-14 07:24:50  O-2-2cn --> G-3-4cn  ...  0.428571    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.312s]> Epoch [1/1] | loss: 0.1338, test loss: 0.2698, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.143s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.136s]> Epoch [1/1] | loss: 0.1271, test loss: 0.2414, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.161s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.300s]> Epoch [1/1] | loss: 0.1364, test loss: 0.2698, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.149s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.422s]> Epoch [1/1] | loss: 0.1300, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.105s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 3.074s]> Epoch [1/1] | loss: 0.1074, test loss: 0.2433, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.133s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.212s]> Epoch [1/1] | loss: 0.0975, test loss: 0.1641, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.119s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a28.57]-[f0.2588]-[p0.6250]-[r0.5312].pt"
              precision    recall  f1-score   support

           0       1.00      0.06      0.12        16
           1       0.25      1.00      0.40         5

    accuracy                           0.29        21
   macro avg       0.62      0.53      0.26        21
weighted avg       0.82      0.29      0.18        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.062500    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.117647    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.250000     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.400000     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.821429    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.285714    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.184874    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.625000    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.531250    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.258824    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.285714    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.192s]> Epoch [1/1] | loss: 0.0881, test loss: 0.0956, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.106s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

Log [0.0h, 0.0m, 4.040s]> Epoch [1/1] | loss: 0.1016, test loss: 0.2673, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.187s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.569s]> Epoch [1/1] | loss: 0.1268, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.142s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:24:51  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.162s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.202s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.122s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.201s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.132s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.128s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.058s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.080s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.181s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.071s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 7.777s]> Epoch [1/1] | loss: 0.0901, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.664s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.965s]> Epoch [1/1] | loss: 0.0868, test loss: 0.0880, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.774s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.249s]> Epoch [1/1] | loss: 0.0881, test loss: 0.0881, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.690s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:08  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.652s]> Epoch [1/1] | loss: 0.0894, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.495s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.581s]> Epoch [1/1] | loss: 0.0840, test loss: 0.0654, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.448s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a28.30]-[f0.2617]-[p0.6200]-[r0.5366].pt"
              precision    recall  f1-score   support

           0       0.24      1.00      0.39        12
           1       1.00      0.07      0.14        41

    accuracy                           0.28        53
   macro avg       0.62      0.54      0.26        53
weighted avg       0.83      0.28      0.19        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.240000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.387097    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.073171    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.136364    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.827925    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.283019    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.193133    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.620000    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.536585    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.261730    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.283019    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.186s]> Epoch [1/1] | loss: 0.0834, test loss: 0.0653, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.796s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a22.64]-[f0.1846]-[p0.1132]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.23      1.00      0.37        12
           1       0.00      0.00      0.00        41

    accuracy                           0.23        53
   macro avg       0.11      0.50      0.18        53
weighted avg       0.05      0.23      0.08        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.226415    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.369231    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.051264    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.226415    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.083599    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.113208    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.184615    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.226415    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.596s]> Epoch [1/1] | loss: 0.0889, test loss: 0.0880, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.618s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.889s]> Epoch [1/1] | loss: 0.0826, test loss: 0.0630, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.308s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a50.94]-[f0.5050]-[p0.6234]-[r0.6535].pt"
              precision    recall  f1-score   support

           0       0.31      0.92      0.46        12
           1       0.94      0.39      0.55        41

    accuracy                           0.51        53
   macro avg       0.62      0.65      0.51        53
weighted avg       0.80      0.51      0.53        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.305556    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.916667    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.458333    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.941176    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.390244    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.551724    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.797262    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.509434    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.530579    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.623366    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.653455    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.505029    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.509434    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.441s]> Epoch [1/1] | loss: 0.0842, test loss: 0.0881, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.519s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.935s]> Epoch [1/1] | loss: 0.0880, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.195s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.788s]> Epoch [1/1] | loss: 0.0891, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.386s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.108s]> Epoch [1/1] | loss: 0.0888, test loss: 0.0676, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.349s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:09  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.623s]> Epoch [1/1] | loss: 0.0816, test loss: 0.0667, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.364s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.900s]> Epoch [1/1] | loss: 0.0876, test loss: 0.0873, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.427s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.200s]> Epoch [1/1] | loss: 0.0895, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.414s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:25:10  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.072s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.067s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.168s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.162s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.154s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.169s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.184s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 8.568s]> Epoch [1/1] | loss: 0.0859, test loss: 0.0438, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.040s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.652s]> Epoch [1/1] | loss: 0.0842, test loss: 0.0806, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.857s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a10.07]-[f0.0915]-[p0.0504]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.10      1.00      0.18        14
           1       0.00      0.00      0.00       125

    accuracy                           0.10       139
   macro avg       0.05      0.50      0.09       139
weighted avg       0.01      0.10      0.02       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.100719    14.0
1   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000    14.0
2   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.183007    14.0
3   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000   125.0
4   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000   125.0
5   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000   125.0
6   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.010144   139.0
7   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.100719   139.0
8   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.018432   139.0
9   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.050360   139.0
10  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.091503   139.0
12  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.100719   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.048s]> Epoch [1/1] | loss: 0.0763, test loss: 0.0705, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.306s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a34.53]-[f0.3176]-[p0.5039]-[r0.5091].pt"
              precision    recall  f1-score   support

           0       0.10      0.71      0.18        14
           1       0.90      0.30      0.46       125

    accuracy                           0.35       139
   macro avg       0.50      0.51      0.32       139
weighted avg       0.82      0.35      0.43       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.103093    14.0
1   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.714286    14.0
2   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.180180    14.0
3   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.904762   125.0
4   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.304000   125.0
5   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.455090   125.0
6   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.824018   139.0
7   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.345324   139.0
8   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.427401   139.0
9   2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.503927   139.0
10  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.509143   139.0
11  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.317635   139.0
12  2025-04-14 07:25:28  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.345324   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.254s]> Epoch [1/1] | loss: 0.0863, test loss: 0.0453, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.953s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

Log [0.0h, 0.0m, 9.284s]> Epoch [1/1] | loss: 0.0895, test loss: 0.0452, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.149s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.125s]> Epoch [1/1] | loss: 0.0887, test loss: 0.0452, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.135s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.599s]> Epoch [1/1] | loss: 0.0899, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.055s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.714s]> Epoch [1/1] | loss: 0.0905, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.916s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.737s]> Epoch [1/1] | loss: 0.0855, test loss: 0.0440, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.631s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.246s]> Epoch [1/1] | loss: 0.0900, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.956s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.383s]> Epoch [1/1] | loss: 0.0873, test loss: 0.0447, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.116s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.970s]> Epoch [1/1] | loss: 0.0896, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.881s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.451s]> Epoch [1/1] | loss: 0.0894, test loss: 0.0453, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.874s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.696s]> Epoch [1/1] | loss: 0.0784, test loss: 0.0727, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.896s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a33.09]-[f0.3104]-[p0.5150]-[r0.5329].pt"
              precision    recall  f1-score   support

           0       0.11      0.79      0.19        14
           1       0.92      0.28      0.43       125

    accuracy                           0.33       139
   macro avg       0.51      0.53      0.31       139
weighted avg       0.84      0.33      0.41       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.108911    14.0
1   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.191304    14.0
3   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.921053   125.0
4   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.280000   125.0
5   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.429448   125.0
6   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.839254   139.0
7   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.330935   139.0
8   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.405462   139.0
9   2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.514982   139.0
10  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.532857   139.0
11  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.310376   139.0
12  2025-04-14 07:25:29  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.330935   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.237s]> Epoch [1/1] | loss: 0.0896, test loss: 0.0455, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.900s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/transformer-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:25:30  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.161s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.136s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.166s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.064s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.086s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.081s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.192s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 7.070s]> Epoch [1/1] | loss: 0.0841, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.020s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.093s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.206s]> Epoch [1/1] | loss: 0.0888, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.175s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.059s]> Epoch [1/1] | loss: 0.0774, test loss: 0.0895, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.079s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:25:45  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.400s]> Epoch [1/1] | loss: 0.0875, test loss: 0.1456, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.078s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.653s]> Epoch [1/1] | loss: 0.0799, test loss: 0.1323, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.187s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.709s]> Epoch [1/1] | loss: 0.0851, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.087s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:46  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.721s]> Epoch [1/1] | loss: 0.0821, test loss: 0.1483, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.094s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.354s]> Epoch [1/1] | loss: 0.0850, test loss: 0.1317, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.192s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.885s]> Epoch [1/1] | loss: 0.0864, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.054s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.363s]> Epoch [1/1] | loss: 0.0795, test loss: 0.0715, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.055s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.5833]-[p0.7500]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       1.00      0.33      0.50         3

    accuracy                           0.60         5
   macro avg       0.75      0.67      0.58         5
weighted avg       0.80      0.60      0.57         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.566667     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750000     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.996s]> Epoch [1/1] | loss: 0.0764, test loss: 0.0662, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.046s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.5833]-[p0.7500]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       0.50      1.00      0.67         2
           1       1.00      0.33      0.50         3

    accuracy                           0.60         5
   macro avg       0.75      0.67      0.58         5
weighted avg       0.80      0.60      0.57         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.566667     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750000     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.289s]> Epoch [1/1] | loss: 0.0872, test loss: 0.1470, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.093s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.903s]> Epoch [1/1] | loss: 0.0878, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.105s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.076s]> Epoch [1/1] | loss: 0.0853, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.081s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.714s]> Epoch [1/1] | loss: 0.0884, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.046s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:25:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.199s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.199s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.012s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.227s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.020s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.269s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 7.457s]> Epoch [1/1] | loss: 0.0879, test loss: 0.2571, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.494s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.209s]> Epoch [1/1] | loss: 0.0857, test loss: 0.2631, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.416s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:04  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.229s]> Epoch [1/1] | loss: 0.0752, test loss: 0.0867, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.255s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.459s]> Epoch [1/1] | loss: 0.0894, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.293s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 8.138s]> Epoch [1/1] | loss: 0.0883, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.386s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:05  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.512s]> Epoch [1/1] | loss: 0.0809, test loss: 0.1062, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.180s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.915344    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.895658    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.944444    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.845588    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.850s]> Epoch [1/1] | loss: 0.0889, test loss: 0.2676, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.296s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.702s]> Epoch [1/1] | loss: 0.0878, test loss: 0.2679, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.156s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.594s]> Epoch [1/1] | loss: 0.0851, test loss: 0.1276, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.182s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.621s]> Epoch [1/1] | loss: 0.0846, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.193s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.656s]> Epoch [1/1] | loss: 0.0878, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.225s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.450s]> Epoch [1/1] | loss: 0.0852, test loss: 0.2699, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.214s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.922s]> Epoch [1/1] | loss: 0.0845, test loss: 0.0889, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.141s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.961s]> Epoch [1/1] | loss: 0.0853, test loss: 0.2561, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.094s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.243s]> Epoch [1/1] | loss: 0.0755, test loss: 0.1184, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.090s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/transformer-[a80.95]-[f0.7857]-[p0.7778]-[r0.8750].pt"
              precision    recall  f1-score   support

           0       1.00      0.75      0.86        16
           1       0.56      1.00      0.71         5

    accuracy                           0.81        21
   macro avg       0.78      0.88      0.79        21
weighted avg       0.89      0.81      0.82        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000    16.0
2   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    16.0
3   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.555556     5.0
4   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.714286     5.0
6   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.894180    21.0
7   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0
8   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.823129    21.0
9   2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.777778    21.0
10  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    21.0
11  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.785714    21.0
12  2025-04-14 07:26:06  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.015s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.129s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.185s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.172s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.192s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.016s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.007s]> Generating data lookup
Log [0.0h, 0.0m, 0.183s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.063s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.119s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.171s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.065s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.218s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.176s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 8.643s]> Epoch [1/1] | loss: 0.0564, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.308s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.363s]> Epoch [1/1] | loss: 0.0567, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.350s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.797s]> Epoch [1/1] | loss: 0.0567, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.393s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.713s]> Epoch [1/1] | loss: 0.0570, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.285s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.323s]> Epoch [1/1] | loss: 0.0567, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.959s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.189s]> Epoch [1/1] | loss: 0.0545, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.199s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.161s]> Epoch [1/1] | loss: 0.0574, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.479s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.929s]> Epoch [1/1] | loss: 0.0565, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.473s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.520s]> Epoch [1/1] | loss: 0.0571, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.369s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.506s]> Epoch [1/1] | loss: 0.0563, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.248s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.335s]> Epoch [1/1] | loss: 0.0571, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.137s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 8.647s]> Epoch [1/1] | loss: 0.0568, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.770s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:26  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.023s]> Epoch [1/1] | loss: 0.0567, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.982s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.546s]> Epoch [1/1] | loss: 0.0563, test loss: 0.0862, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.978s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.759s]> Epoch [1/1] | loss: 0.0554, test loss: 0.0861, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.889s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/transformer-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:26:27  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.085s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.147s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.073s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 5.657s]> Epoch [1/1] | loss: 0.0589, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.391s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.779s]> Epoch [1/1] | loss: 0.0584, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.379s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.964s]> Epoch [1/1] | loss: 0.0552, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.362s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:42  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.231s]> Epoch [1/1] | loss: 0.0586, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.247s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

Log [0.0h, 0.0m, 5.938s]> Epoch [1/1] | loss: 0.0584, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.369s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.292s]> Epoch [1/1] | loss: 0.0564, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.337s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.499s]> Epoch [1/1] | loss: 0.0584, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.330s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.760s]> Epoch [1/1] | loss: 0.0584, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.234s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.540s]> Epoch [1/1] | loss: 0.0590, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.276s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.049s]> Epoch [1/1] | loss: 0.0580, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.225s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.195s]> Epoch [1/1] | loss: 0.0591, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.193s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.282s]> Epoch [1/1] | loss: 0.0587, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.193s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.138s]> Epoch [1/1] | loss: 0.0554, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.154s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.767s]> Epoch [1/1] | loss: 0.0585, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.120s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.882s]> Epoch [1/1] | loss: 0.0587, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.172s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:26:43  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.063s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 6.027s]> Epoch [1/1] | loss: 0.0533, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.169s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.758s]> Epoch [1/1] | loss: 0.0540, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.112s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

Log [0.0h, 0.0m, 5.631s]> Epoch [1/1] | loss: 0.0538, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.097s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.985s]> Epoch [1/1] | loss: 0.0531, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.162s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.648s]> Epoch [1/1] | loss: 0.0544, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.082s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.008s]> Epoch [1/1] | loss: 0.0536, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.067s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.046s]> Epoch [1/1] | loss: 0.0524, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.179s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:58  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.999s]> Epoch [1/1] | loss: 0.0537, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.128s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.096s]> Epoch [1/1] | loss: 0.0536, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.056s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.209s]> Epoch [1/1] | loss: 0.0533, test loss: 0.1465, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.107s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.231s]> Epoch [1/1] | loss: 0.0540, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.084s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.916s]> Epoch [1/1] | loss: 0.0536, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.040s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.060s]> Epoch [1/1] | loss: 0.0538, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.122s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.000s]> Epoch [1/1] | loss: 0.0531, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.133s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.712s]> Epoch [1/1] | loss: 0.0535, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.052s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:26:59  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.012s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.059s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.068s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.062s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 6.192s]> Epoch [1/1] | loss: 0.0566, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.413s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:14  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.422s]> Epoch [1/1] | loss: 0.0566, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.284s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.621s]> Epoch [1/1] | loss: 0.0569, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.301s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.417s]> Epoch [1/1] | loss: 0.0572, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.392s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.177s]> Epoch [1/1] | loss: 0.0561, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.189s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.564s]> Epoch [1/1] | loss: 0.0566, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.310s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.464s]> Epoch [1/1] | loss: 0.0553, test loss: 0.2604, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.185s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.635s]> Epoch [1/1] | loss: 0.0561, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.233s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.839s]> Epoch [1/1] | loss: 0.0552, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.343s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.179s]> Epoch [1/1] | loss: 0.0571, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.129s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:15  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 7.026s]> Epoch [1/1] | loss: 0.0566, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.104s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.801s]> Epoch [1/1] | loss: 0.0565, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.305s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.528s]> Epoch [1/1] | loss: 0.0566, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.149s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.593s]> Epoch [1/1] | loss: 0.0569, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.199s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.375s]> Epoch [1/1] | loss: 0.0568, test loss: 0.2699, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.161s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:27:16  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.082s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.160s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.059s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.143s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.144s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.171s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.177s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.054s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.162s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.056s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.063s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 9.982s]> Epoch [1/1] | loss: 0.0699, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.681s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.449s]> Epoch [1/1] | loss: 0.0698, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.896s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:35  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.363s]> Epoch [1/1] | loss: 0.0704, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.625s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.678s]> Epoch [1/1] | loss: 0.0675, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.717s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.505s]> Epoch [1/1] | loss: 0.0680, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.579s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.155s]> Epoch [1/1] | loss: 0.0692, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.020s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.331s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:36  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.318s]> Epoch [1/1] | loss: 0.0699, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.324s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.762s]> Epoch [1/1] | loss: 0.0651, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.440s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.033s]> Epoch [1/1] | loss: 0.0681, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.364s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.397s]> Epoch [1/1] | loss: 0.0696, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.409s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 10.613s]> Epoch [1/1] | loss: 0.0684, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.297s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.547s]> Epoch [1/1] | loss: 0.0696, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.229s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.239s]> Epoch [1/1] | loss: 0.0682, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.245s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.571s]> Epoch [1/1] | loss: 0.0700, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.224s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:37  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.580s]> Epoch [1/1] | loss: 0.0685, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.264s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:27:38  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.194s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.143s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.004s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.247s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.012s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.283s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.259s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.174s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 10.590s]> Epoch [1/1] | loss: 0.0743, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.403s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.100s]> Epoch [1/1] | loss: 0.0742, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.656s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.374s]> Epoch [1/1] | loss: 0.0739, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.346s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:57  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.809s]> Epoch [1/1] | loss: 0.0717, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.590s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.402s]> Epoch [1/1] | loss: 0.0723, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.485s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.474s]> Epoch [1/1] | loss: 0.0733, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.231s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:58  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.050s]> Epoch [1/1] | loss: 0.0699, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.160s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

Log [0.0h, 0.0m, 11.983s]> Epoch [1/1] | loss: 0.0655, test loss: 0.0504, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.193s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a85.71]-[f0.4615]-[p0.4444]-[r0.4800].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      0.96      0.92        25

    accuracy                           0.86        28
   macro avg       0.44      0.48      0.46        28
weighted avg       0.79      0.86      0.82        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.888889    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.960000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.923077    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.793651    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.824176    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.444444    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.480000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.461538    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.775s]> Epoch [1/1] | loss: 0.0728, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.188s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.307s]> Epoch [1/1] | loss: 0.0707, test loss: 0.0476, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.305s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.951s]> Epoch [1/1] | loss: 0.0736, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.247s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.814s]> Epoch [1/1] | loss: 0.0731, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.261s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.090s]> Epoch [1/1] | loss: 0.0717, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.251s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.679s]> Epoch [1/1] | loss: 0.0725, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.152s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

Log [0.0h, 0.0m, 11.149s]> Epoch [1/1] | loss: 0.0623, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.297s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:27:59  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.171s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.181s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.173s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.218s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.195s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.216s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.188s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.119s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.085s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.149s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.008s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.047s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.078s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.137s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.242s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 9.596s]> Epoch [1/1] | loss: 0.0721, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.363s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:18  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.177s]> Epoch [1/1] | loss: 0.0683, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.451s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.023s]> Epoch [1/1] | loss: 0.0716, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.259s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.329s]> Epoch [1/1] | loss: 0.0682, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.318s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.614s]> Epoch [1/1] | loss: 0.0709, test loss: 0.1301, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.366s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:21  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.381s]> Epoch [1/1] | loss: 0.0724, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.164s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.892s]> Epoch [1/1] | loss: 0.0711, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.174s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.155s]> Epoch [1/1] | loss: 0.0716, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.207s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.280s]> Epoch [1/1] | loss: 0.0715, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.309s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.291s]> Epoch [1/1] | loss: 0.0713, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.111s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.621s]> Epoch [1/1] | loss: 0.0554, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.343s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.130s]> Epoch [1/1] | loss: 0.0723, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.125s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.828s]> Epoch [1/1] | loss: 0.0700, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.030s]> Epoch [1/1] | loss: 0.0695, test loss: 0.1302, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.085s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.556s]> Epoch [1/1] | loss: 0.0704, test loss: 0.1301, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.197s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/transformer-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:28:22  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.161s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.226s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.209s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.144s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.136s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.129s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.067s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.170s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.079s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.134s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.177s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 11.542s]> Epoch [1/1] | loss: 0.0617, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.322s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.938s]> Epoch [1/1] | loss: 0.0725, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.474s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:44  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.027s]> Epoch [1/1] | loss: 0.0710, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.283s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.743s]> Epoch [1/1] | loss: 0.0715, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.408s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.802s]> Epoch [1/1] | loss: 0.0689, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.197s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.439s]> Epoch [1/1] | loss: 0.0717, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.147s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.395s]> Epoch [1/1] | loss: 0.0662, test loss: 0.2578, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.253s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a28.57]-[f0.2588]-[p0.6250]-[r0.5312].pt"
              precision    recall  f1-score   support

           0       1.00      0.06      0.12        16
           1       0.25      1.00      0.40         5

    accuracy                           0.29        21
   macro avg       0.62      0.53      0.26        21
weighted avg       0.82      0.29      0.18        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.062500    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.117647    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.250000     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.400000     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.821429    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.285714    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.184874    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.625000    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.531250    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.258824    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.285714    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.467s]> Epoch [1/1] | loss: 0.0666, test loss: 0.2692, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.256s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.313s]> Epoch [1/1] | loss: 0.0715, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.176s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.278s]> Epoch [1/1] | loss: 0.0716, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.174s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.475s]> Epoch [1/1] | loss: 0.0609, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.321s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.963s]> Epoch [1/1] | loss: 0.0702, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.109s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.139s]> Epoch [1/1] | loss: 0.0692, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.119s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.827s]> Epoch [1/1] | loss: 0.0723, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.086s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.854s]> Epoch [1/1] | loss: 0.0678, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.202s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:28:45  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.054s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.159s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.008s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.204s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.070s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.110s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.172s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.069s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.128s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.092s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.107s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.196s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.069s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.106s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.093s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.143s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.005s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.024s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.061s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.225s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.163s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.087s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.160s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.069s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.139s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 10.462s]> Epoch [1/1] | loss: 0.0731, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.635s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:07  ...    12.0
1   2025-04-14 07:29:07  ...    12.0
2   2025-04-14 07:29:07  ...    12.0
3   2025-04-14 07:29:07  ...    41.0
4   2025-04-14 07:29:07  ...    41.0
5   2025-04-14 07:29:07  ...    41.0
6   2025-04-14 07:29:07  ...    53.0
7   2025-04-14 07:29:07  ...    53.0
8   2025-04-14 07:29:07  ...    53.0
9   2025-04-14 07:29:07  ...    53.0
10  2025-04-14 07:29:07  ...    53.0
11  2025-04-14 07:29:07  ...    53.0
12  2025-04-14 07:29:07  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.597s]> Epoch [1/1] | loss: 0.0715, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.860s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:08  ...    12.0
1   2025-04-14 07:29:08  ...    12.0
2   2025-04-14 07:29:08  ...    12.0
3   2025-04-14 07:29:08  ...    41.0
4   2025-04-14 07:29:08  ...    41.0
5   2025-04-14 07:29:08  ...    41.0
6   2025-04-14 07:29:08  ...    53.0
7   2025-04-14 07:29:08  ...    53.0
8   2025-04-14 07:29:08  ...    53.0
9   2025-04-14 07:29:08  ...    53.0
10  2025-04-14 07:29:08  ...    53.0
11  2025-04-14 07:29:08  ...    53.0
12  2025-04-14 07:29:08  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.887s]> Epoch [1/1] | loss: 0.0727, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.761s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:08  ...    12.0
1   2025-04-14 07:29:08  ...    12.0
2   2025-04-14 07:29:08  ...    12.0
3   2025-04-14 07:29:08  ...    41.0
4   2025-04-14 07:29:08  ...    41.0
5   2025-04-14 07:29:08  ...    41.0
6   2025-04-14 07:29:08  ...    53.0
7   2025-04-14 07:29:08  ...    53.0
8   2025-04-14 07:29:08  ...    53.0
9   2025-04-14 07:29:08  ...    53.0
10  2025-04-14 07:29:08  ...    53.0
11  2025-04-14 07:29:08  ...    53.0
12  2025-04-14 07:29:08  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.351s]> Epoch [1/1] | loss: 0.0719, test loss: 0.0867, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.562s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:08  ...    12.0
1   2025-04-14 07:29:08  ...    12.0
2   2025-04-14 07:29:08  ...    12.0
3   2025-04-14 07:29:08  ...    41.0
4   2025-04-14 07:29:08  ...    41.0
5   2025-04-14 07:29:08  ...    41.0
6   2025-04-14 07:29:08  ...    53.0
7   2025-04-14 07:29:08  ...    53.0
8   2025-04-14 07:29:08  ...    53.0
9   2025-04-14 07:29:08  ...    53.0
10  2025-04-14 07:29:08  ...    53.0
11  2025-04-14 07:29:08  ...    53.0
12  2025-04-14 07:29:08  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.427s]> Epoch [1/1] | loss: 0.0716, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.620s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:08  ...    12.0
1   2025-04-14 07:29:08  ...    12.0
2   2025-04-14 07:29:08  ...    12.0
3   2025-04-14 07:29:08  ...    41.0
4   2025-04-14 07:29:08  ...    41.0
5   2025-04-14 07:29:08  ...    41.0
6   2025-04-14 07:29:08  ...    53.0
7   2025-04-14 07:29:08  ...    53.0
8   2025-04-14 07:29:08  ...    53.0
9   2025-04-14 07:29:08  ...    53.0
10  2025-04-14 07:29:08  ...    53.0
11  2025-04-14 07:29:08  ...    53.0
12  2025-04-14 07:29:08  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.730s]> Epoch [1/1] | loss: 0.0695, test loss: 0.0881, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.802s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 12.574s]> Epoch [1/1] | loss: 0.0707, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.567s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.196s]> Epoch [1/1] | loss: 0.0684, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.490s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.504s]> Epoch [1/1] | loss: 0.0721, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.495s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.073s]> Epoch [1/1] | loss: 0.0713, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.589s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.261s]> Epoch [1/1] | loss: 0.0694, test loss: 0.0872, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.629s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.694s]> Epoch [1/1] | loss: 0.0725, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.503s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 11.875s]> Epoch [1/1] | loss: 0.0720, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.408s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.462s]> Epoch [1/1] | loss: 0.0721, test loss: 0.0875, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.530s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.765s]> Epoch [1/1] | loss: 0.0724, test loss: 0.0882, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.407s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/transformer-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:29:09  ...    12.0
1   2025-04-14 07:29:09  ...    12.0
2   2025-04-14 07:29:09  ...    12.0
3   2025-04-14 07:29:09  ...    41.0
4   2025-04-14 07:29:09  ...    41.0
5   2025-04-14 07:29:09  ...    41.0
6   2025-04-14 07:29:09  ...    53.0
7   2025-04-14 07:29:09  ...    53.0
8   2025-04-14 07:29:09  ...    53.0
9   2025-04-14 07:29:09  ...    53.0
10  2025-04-14 07:29:09  ...    53.0
11  2025-04-14 07:29:09  ...    53.0
12  2025-04-14 07:29:09  ...    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.214s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.207s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.192s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.193s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.124s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.264s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.148s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.148s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.185s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.013s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.235s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 10.516s]> Epoch [1/1] | loss: 0.0763, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.012s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.642s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.410s]> Epoch [1/1] | loss: 0.0766, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.451s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.325s]> Epoch [1/1] | loss: 0.0717, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.479s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.766s]> Epoch [1/1] | loss: 0.0759, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.400s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.455s]> Epoch [1/1] | loss: 0.0770, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.228s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.821s]> Epoch [1/1] | loss: 0.0751, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.473s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:31  ...     3.0
1   2025-04-14 07:29:31  ...     3.0
2   2025-04-14 07:29:31  ...     3.0
3   2025-04-14 07:29:31  ...    25.0
4   2025-04-14 07:29:31  ...    25.0
5   2025-04-14 07:29:31  ...    25.0
6   2025-04-14 07:29:31  ...    28.0
7   2025-04-14 07:29:31  ...    28.0
8   2025-04-14 07:29:31  ...    28.0
9   2025-04-14 07:29:31  ...    28.0
10  2025-04-14 07:29:31  ...    28.0
11  2025-04-14 07:29:31  ...    28.0
12  2025-04-14 07:29:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.293s]> Epoch [1/1] | loss: 0.0765, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.256s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.175s]> Epoch [1/1] | loss: 0.0728, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.230s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.299s]> Epoch [1/1] | loss: 0.0715, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.352s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.776s]> Epoch [1/1] | loss: 0.0738, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.184s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.285s]> Epoch [1/1] | loss: 0.0764, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.112s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.628s]> Epoch [1/1] | loss: 0.0762, test loss: 0.0476, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.215s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.604s]> Epoch [1/1] | loss: 0.0744, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.166s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.158s]> Epoch [1/1] | loss: 0.0750, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.239s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.343s]> Epoch [1/1] | loss: 0.0756, test loss: 0.0477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.185s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/transformer-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:29:32  ...     3.0
1   2025-04-14 07:29:32  ...     3.0
2   2025-04-14 07:29:32  ...     3.0
3   2025-04-14 07:29:32  ...    25.0
4   2025-04-14 07:29:32  ...    25.0
5   2025-04-14 07:29:32  ...    25.0
6   2025-04-14 07:29:32  ...    28.0
7   2025-04-14 07:29:32  ...    28.0
8   2025-04-14 07:29:32  ...    28.0
9   2025-04-14 07:29:32  ...    28.0
10  2025-04-14 07:29:32  ...    28.0
11  2025-04-14 07:29:32  ...    28.0
12  2025-04-14 07:29:32  ...    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.182s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.183s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.243s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.226s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.124s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.229s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.003s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.181s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.132s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.149s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 11.244s]> Epoch [1/1] | loss: 0.0696, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.082s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:53  ...     2.0
1   2025-04-14 07:29:53  ...     2.0
2   2025-04-14 07:29:53  ...     2.0
3   2025-04-14 07:29:53  ...     3.0
4   2025-04-14 07:29:53  ...     3.0
5   2025-04-14 07:29:53  ...     3.0
6   2025-04-14 07:29:53  ...     5.0
7   2025-04-14 07:29:53  ...     5.0
8   2025-04-14 07:29:53  ...     5.0
9   2025-04-14 07:29:53  ...     5.0
10  2025-04-14 07:29:53  ...     5.0
11  2025-04-14 07:29:53  ...     5.0
12  2025-04-14 07:29:53  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.339s]> Epoch [1/1] | loss: 0.0742, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.143s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:53  ...     2.0
1   2025-04-14 07:29:53  ...     2.0
2   2025-04-14 07:29:53  ...     2.0
3   2025-04-14 07:29:53  ...     3.0
4   2025-04-14 07:29:53  ...     3.0
5   2025-04-14 07:29:53  ...     3.0
6   2025-04-14 07:29:53  ...     5.0
7   2025-04-14 07:29:53  ...     5.0
8   2025-04-14 07:29:53  ...     5.0
9   2025-04-14 07:29:53  ...     5.0
10  2025-04-14 07:29:53  ...     5.0
11  2025-04-14 07:29:53  ...     5.0
12  2025-04-14 07:29:53  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.242s]> Epoch [1/1] | loss: 0.0712, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.087s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:54  ...     2.0
1   2025-04-14 07:29:54  ...     2.0
2   2025-04-14 07:29:54  ...     2.0
3   2025-04-14 07:29:54  ...     3.0
4   2025-04-14 07:29:54  ...     3.0
5   2025-04-14 07:29:54  ...     3.0
6   2025-04-14 07:29:54  ...     5.0
7   2025-04-14 07:29:54  ...     5.0
8   2025-04-14 07:29:54  ...     5.0
9   2025-04-14 07:29:54  ...     5.0
10  2025-04-14 07:29:54  ...     5.0
11  2025-04-14 07:29:54  ...     5.0
12  2025-04-14 07:29:54  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.309s]> Epoch [1/1] | loss: 0.0739, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.084s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.166s]> Epoch [1/1] | loss: 0.0742, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.405s]> Epoch [1/1] | loss: 0.0713, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.059s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.226s]> Epoch [1/1] | loss: 0.0735, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.108s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.116s]> Epoch [1/1] | loss: 0.0671, test loss: 0.1471, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.100s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.564s]> Epoch [1/1] | loss: 0.0706, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.099s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.586s]> Epoch [1/1] | loss: 0.0730, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.055s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.270s]> Epoch [1/1] | loss: 0.0742, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.070s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:55  ...     2.0
1   2025-04-14 07:29:55  ...     2.0
2   2025-04-14 07:29:55  ...     2.0
3   2025-04-14 07:29:55  ...     3.0
4   2025-04-14 07:29:55  ...     3.0
5   2025-04-14 07:29:55  ...     3.0
6   2025-04-14 07:29:55  ...     5.0
7   2025-04-14 07:29:55  ...     5.0
8   2025-04-14 07:29:55  ...     5.0
9   2025-04-14 07:29:55  ...     5.0
10  2025-04-14 07:29:55  ...     5.0
11  2025-04-14 07:29:55  ...     5.0
12  2025-04-14 07:29:55  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.420s]> Epoch [1/1] | loss: 0.0723, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.085s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:56  ...     2.0
1   2025-04-14 07:29:56  ...     2.0
2   2025-04-14 07:29:56  ...     2.0
3   2025-04-14 07:29:56  ...     3.0
4   2025-04-14 07:29:56  ...     3.0
5   2025-04-14 07:29:56  ...     3.0
6   2025-04-14 07:29:56  ...     5.0
7   2025-04-14 07:29:56  ...     5.0
8   2025-04-14 07:29:56  ...     5.0
9   2025-04-14 07:29:56  ...     5.0
10  2025-04-14 07:29:56  ...     5.0
11  2025-04-14 07:29:56  ...     5.0
12  2025-04-14 07:29:56  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.249s]> Epoch [1/1] | loss: 0.0705, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.053s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:56  ...     2.0
1   2025-04-14 07:29:56  ...     2.0
2   2025-04-14 07:29:56  ...     2.0
3   2025-04-14 07:29:56  ...     3.0
4   2025-04-14 07:29:56  ...     3.0
5   2025-04-14 07:29:56  ...     3.0
6   2025-04-14 07:29:56  ...     5.0
7   2025-04-14 07:29:56  ...     5.0
8   2025-04-14 07:29:56  ...     5.0
9   2025-04-14 07:29:56  ...     5.0
10  2025-04-14 07:29:56  ...     5.0
11  2025-04-14 07:29:56  ...     5.0
12  2025-04-14 07:29:56  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.472s]> Epoch [1/1] | loss: 0.0741, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.049s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:56  ...     2.0
1   2025-04-14 07:29:56  ...     2.0
2   2025-04-14 07:29:56  ...     2.0
3   2025-04-14 07:29:56  ...     3.0
4   2025-04-14 07:29:56  ...     3.0
5   2025-04-14 07:29:56  ...     3.0
6   2025-04-14 07:29:56  ...     5.0
7   2025-04-14 07:29:56  ...     5.0
8   2025-04-14 07:29:56  ...     5.0
9   2025-04-14 07:29:56  ...     5.0
10  2025-04-14 07:29:56  ...     5.0
11  2025-04-14 07:29:56  ...     5.0
12  2025-04-14 07:29:56  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.911s]> Epoch [1/1] | loss: 0.0677, test loss: 0.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.048s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/transformer-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:29:56  ...     2.0
1   2025-04-14 07:29:56  ...     2.0
2   2025-04-14 07:29:56  ...     2.0
3   2025-04-14 07:29:56  ...     3.0
4   2025-04-14 07:29:56  ...     3.0
5   2025-04-14 07:29:56  ...     3.0
6   2025-04-14 07:29:56  ...     5.0
7   2025-04-14 07:29:56  ...     5.0
8   2025-04-14 07:29:56  ...     5.0
9   2025-04-14 07:29:56  ...     5.0
10  2025-04-14 07:29:56  ...     5.0
11  2025-04-14 07:29:56  ...     5.0
12  2025-04-14 07:29:56  ...     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.124s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.129s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.201s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.200s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.064s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.226s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.154s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.222s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.143s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.233s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.045s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.137s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.169s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.054s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.136s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.089s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 11.931s]> Epoch [1/1] | loss: 0.0726, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.440s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 11.776s]> Epoch [1/1] | loss: 0.0732, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.431s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:17  ...    16.0
1   2025-04-14 07:30:17  ...    16.0
2   2025-04-14 07:30:17  ...    16.0
3   2025-04-14 07:30:17  ...     5.0
4   2025-04-14 07:30:17  ...     5.0
5   2025-04-14 07:30:17  ...     5.0
6   2025-04-14 07:30:17  ...    21.0
7   2025-04-14 07:30:17  ...    21.0
8   2025-04-14 07:30:17  ...    21.0
9   2025-04-14 07:30:17  ...    21.0
10  2025-04-14 07:30:17  ...    21.0
11  2025-04-14 07:30:17  ...    21.0
12  2025-04-14 07:30:17  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.213s]> Epoch [1/1] | loss: 0.0745, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.309s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:18  ...    16.0
1   2025-04-14 07:30:18  ...    16.0
2   2025-04-14 07:30:18  ...    16.0
3   2025-04-14 07:30:18  ...     5.0
4   2025-04-14 07:30:18  ...     5.0
5   2025-04-14 07:30:18  ...     5.0
6   2025-04-14 07:30:18  ...    21.0
7   2025-04-14 07:30:18  ...    21.0
8   2025-04-14 07:30:18  ...    21.0
9   2025-04-14 07:30:18  ...    21.0
10  2025-04-14 07:30:18  ...    21.0
11  2025-04-14 07:30:18  ...    21.0
12  2025-04-14 07:30:18  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.565s]> Epoch [1/1] | loss: 0.0749, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.366s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:18  ...    16.0
1   2025-04-14 07:30:18  ...    16.0
2   2025-04-14 07:30:18  ...    16.0
3   2025-04-14 07:30:18  ...     5.0
4   2025-04-14 07:30:18  ...     5.0
5   2025-04-14 07:30:18  ...     5.0
6   2025-04-14 07:30:18  ...    21.0
7   2025-04-14 07:30:18  ...    21.0
8   2025-04-14 07:30:18  ...    21.0
9   2025-04-14 07:30:18  ...    21.0
10  2025-04-14 07:30:18  ...    21.0
11  2025-04-14 07:30:18  ...    21.0
12  2025-04-14 07:30:18  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.493s]> Epoch [1/1] | loss: 0.0742, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.339s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:18  ...    16.0
1   2025-04-14 07:30:18  ...    16.0
2   2025-04-14 07:30:18  ...    16.0
3   2025-04-14 07:30:18  ...     5.0
4   2025-04-14 07:30:18  ...     5.0
5   2025-04-14 07:30:18  ...     5.0
6   2025-04-14 07:30:18  ...    21.0
7   2025-04-14 07:30:18  ...    21.0
8   2025-04-14 07:30:18  ...    21.0
9   2025-04-14 07:30:18  ...    21.0
10  2025-04-14 07:30:18  ...    21.0
11  2025-04-14 07:30:18  ...    21.0
12  2025-04-14 07:30:18  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.552s]> Epoch [1/1] | loss: 0.0750, test loss: 0.2699, lr: 0.001000
Log [0.0h, 0.0m, 0.017s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.174s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 12.968s]> Epoch [1/1] | loss: 0.0724, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.272s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.185s]> Epoch [1/1] | loss: 0.0735, test loss: 0.2696, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.315s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.720s]> Epoch [1/1] | loss: 0.0738, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.146s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 13.038s]> Epoch [1/1] | loss: 0.0736, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.147s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.515s]> Epoch [1/1] | loss: 0.0691, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.144s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.246s]> Epoch [1/1] | loss: 0.0707, test loss: 0.2345, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.165s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.472s]> Epoch [1/1] | loss: 0.0748, test loss: 0.2698, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.196s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.257s]> Epoch [1/1] | loss: 0.0750, test loss: 0.2701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.104s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.429s]> Epoch [1/1] | loss: 0.0739, test loss: 0.2700, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.140s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/transformer-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:30:19  ...    16.0
1   2025-04-14 07:30:19  ...    16.0
2   2025-04-14 07:30:19  ...    16.0
3   2025-04-14 07:30:19  ...     5.0
4   2025-04-14 07:30:19  ...     5.0
5   2025-04-14 07:30:19  ...     5.0
6   2025-04-14 07:30:19  ...    21.0
7   2025-04-14 07:30:19  ...    21.0
8   2025-04-14 07:30:19  ...    21.0
9   2025-04-14 07:30:19  ...    21.0
10  2025-04-14 07:30:19  ...    21.0
11  2025-04-14 07:30:19  ...    21.0
12  2025-04-14 07:30:19  ...    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.002s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.148s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.085s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.081s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.158s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.128s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.122s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.067s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.152s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.192s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.058s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.139s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.149s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.015s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.104s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Transformer>
Log [0.0h, 0.0m, 11.894s]> Epoch [1/1] | loss: 0.0734, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.177s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:41  ...    17.0
1   2025-04-14 07:30:41  ...    17.0
2   2025-04-14 07:30:41  ...    17.0
3   2025-04-14 07:30:41  ...    69.0
4   2025-04-14 07:30:41  ...    69.0
5   2025-04-14 07:30:41  ...    69.0
6   2025-04-14 07:30:41  ...    86.0
7   2025-04-14 07:30:41  ...    86.0
8   2025-04-14 07:30:41  ...    86.0
9   2025-04-14 07:30:41  ...    86.0
10  2025-04-14 07:30:41  ...    86.0
11  2025-04-14 07:30:41  ...    86.0
12  2025-04-14 07:30:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.785s]> Epoch [1/1] | loss: 0.0702, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.252s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:41  ...    17.0
1   2025-04-14 07:30:41  ...    17.0
2   2025-04-14 07:30:41  ...    17.0
3   2025-04-14 07:30:41  ...    69.0
4   2025-04-14 07:30:41  ...    69.0
5   2025-04-14 07:30:41  ...    69.0
6   2025-04-14 07:30:41  ...    86.0
7   2025-04-14 07:30:41  ...    86.0
8   2025-04-14 07:30:41  ...    86.0
9   2025-04-14 07:30:41  ...    86.0
10  2025-04-14 07:30:41  ...    86.0
11  2025-04-14 07:30:41  ...    86.0
12  2025-04-14 07:30:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.257s]> Epoch [1/1] | loss: 0.0732, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.028s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 11.975s]> Epoch [1/1] | loss: 0.0742, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.537s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.566s]> Epoch [1/1] | loss: 0.0733, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.184s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.008s]> Epoch [1/1] | loss: 0.0706, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.659s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.998s]> Epoch [1/1] | loss: 0.0745, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.067s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.996s]> Epoch [1/1] | loss: 0.0743, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.684s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 12.732s]> Epoch [1/1] | loss: 0.0737, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.703s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.672s]> Epoch [1/1] | loss: 0.0691, test loss: 0.0784, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.888s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.725s]> Epoch [1/1] | loss: 0.0708, test loss: 0.0784, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.464s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.202s]> Epoch [1/1] | loss: 0.0674, test loss: 0.0784, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.463s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.144s]> Epoch [1/1] | loss: 0.0712, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.445s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.556s]> Epoch [1/1] | loss: 0.0740, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.336s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:42  ...    17.0
1   2025-04-14 07:30:42  ...    17.0
2   2025-04-14 07:30:42  ...    17.0
3   2025-04-14 07:30:42  ...    69.0
4   2025-04-14 07:30:42  ...    69.0
5   2025-04-14 07:30:42  ...    69.0
6   2025-04-14 07:30:42  ...    86.0
7   2025-04-14 07:30:42  ...    86.0
8   2025-04-14 07:30:42  ...    86.0
9   2025-04-14 07:30:42  ...    86.0
10  2025-04-14 07:30:42  ...    86.0
11  2025-04-14 07:30:42  ...    86.0
12  2025-04-14 07:30:42  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.021s]> Epoch [1/1] | loss: 0.0739, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: Transformer
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.409s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/transformer-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:30:43  ...    17.0
1   2025-04-14 07:30:43  ...    17.0
2   2025-04-14 07:30:43  ...    17.0
3   2025-04-14 07:30:43  ...    69.0
4   2025-04-14 07:30:43  ...    69.0
5   2025-04-14 07:30:43  ...    69.0
6   2025-04-14 07:30:43  ...    86.0
7   2025-04-14 07:30:43  ...    86.0
8   2025-04-14 07:30:43  ...    86.0
9   2025-04-14 07:30:43  ...    86.0
10  2025-04-14 07:30:43  ...    86.0
11  2025-04-14 07:30:43  ...    86.0
12  2025-04-14 07:30:43  ...    86.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.047s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.068s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 16.738s]> Epoch [1/1] | loss: 0.0572, test loss: 0.1020, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.607s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a92.45]-[f0.8767]-[p0.9556]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       1.00      0.67      0.80        12
           1       0.91      1.00      0.95        41

    accuracy                           0.92        53
   macro avg       0.96      0.83      0.88        53
weighted avg       0.93      0.92      0.92        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.800000    12.0
3   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.911111    41.0
4   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.953488    41.0
6   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.931237    53.0
7   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0
8   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.918736    53.0
9   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.955556    53.0
10  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.833333    53.0
11  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.876744    53.0
12  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.813s]> Epoch [1/1] | loss: 0.0623, test loss: 0.1695, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.708s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a88.68]-[f0.8384]-[p0.8384]-[r0.8384].pt"
              precision    recall  f1-score   support

           0       0.75      0.75      0.75        12
           1       0.93      0.93      0.93        41

    accuracy                           0.89        53
   macro avg       0.84      0.84      0.84        53
weighted avg       0.89      0.89      0.89        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
1   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
3   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.926829    41.0
4   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.926829    41.0
5   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.926829    41.0
6   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.886792    53.0
7   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.886792    53.0
8   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.886792    53.0
9   2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.838415    53.0
10  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.838415    53.0
11  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.838415    53.0
12  2025-04-14 07:31:10  A-1-1cn^ --> A-1-1cn^^  ...  0.886792    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.048s]> Epoch [1/1] | loss: 0.0636, test loss: 0.2823, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.629s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a81.13]-[f0.7573]-[p0.7407]-[r0.7896].pt"
              precision    recall  f1-score   support

           0       0.56      0.75      0.64        12
           1       0.92      0.83      0.87        41

    accuracy                           0.81        53
   macro avg       0.74      0.79      0.76        53
weighted avg       0.84      0.81      0.82        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.562500    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.642857    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.918919    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.829268    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.871795    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.838220    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.811321    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.819960    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.740709    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.789634    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.757326    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.811321    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.970s]> Epoch [1/1] | loss: 0.0603, test loss: 0.2543, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.344s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a77.36]-[f0.7211]-[p0.7071]-[r0.7652].pt"
              precision    recall  f1-score   support

           0       0.50      0.75      0.60        12
           1       0.91      0.78      0.84        41

    accuracy                           0.77        53
   macro avg       0.71      0.77      0.72        53
weighted avg       0.82      0.77      0.79        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.600000    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.914286    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.780488    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.842105    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.820485    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.787289    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.707143    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.765244    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.721053    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.430s]> Epoch [1/1] | loss: 0.0571, test loss: 0.1668, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.631s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a90.57]-[f0.8397]-[p0.9457]-[r0.7917].pt"
              precision    recall  f1-score   support

           0       1.00      0.58      0.74        12
           1       0.89      1.00      0.94        41

    accuracy                           0.91        53
   macro avg       0.95      0.79      0.84        53
weighted avg       0.92      0.91      0.90        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.583333    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.736842    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.891304    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.942529    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.915915    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.905660    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.895958    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.945652    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.791667    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.839685    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.905660    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.689s]> Epoch [1/1] | loss: 0.0592, test loss: 0.1187, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.313s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a84.91]-[f0.7962]-[p0.7830]-[r0.8140].pt"
              precision    recall  f1-score   support

           0       0.64      0.75      0.69        12
           1       0.92      0.88      0.90        41

    accuracy                           0.85        53
   macro avg       0.78      0.81      0.80        53
weighted avg       0.86      0.85      0.85        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.642857    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.692308    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.923077    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.878049    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.900000    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.859631    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.852975    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.782967    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.814024    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.796154    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.292s]> Epoch [1/1] | loss: 0.0573, test loss: 0.3116, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.388s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a84.91]-[f0.8059]-[p0.7855]-[r0.8435].pt"
              precision    recall  f1-score   support

           0       0.62      0.83      0.71        12
           1       0.95      0.85      0.90        41

    accuracy                           0.85        53
   macro avg       0.79      0.84      0.81        53
weighted avg       0.87      0.85      0.86        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.625000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.833333    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.714286    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.945946    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.853659    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.897436    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.873279    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.855968    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.785473    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.843496    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.805861    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.199s]> Epoch [1/1] | loss: 0.0728, test loss: 0.1395, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.498s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a35.85]-[f0.3527]-[p0.6304]-[r0.5854].pt"
              precision    recall  f1-score   support

           0       0.26      1.00      0.41        12
           1       1.00      0.17      0.29        41

    accuracy                           0.36        53
   macro avg       0.63      0.59      0.35        53
weighted avg       0.83      0.36      0.32        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.260870    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.413793    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.170732    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.291667    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.832650    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.358491    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.319318    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.630435    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.585366    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.352730    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.358491    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.849s]> Epoch [1/1] | loss: 0.0621, test loss: 0.4103, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.645s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a77.36]-[f0.7476]-[p0.7500]-[r0.8537].pt"
              precision    recall  f1-score   support

           0       0.50      1.00      0.67        12
           1       1.00      0.71      0.83        41

    accuracy                           0.77        53
   macro avg       0.75      0.85      0.75        53
weighted avg       0.89      0.77      0.79        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.707317    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.828571    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.886792    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.791914    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.853659    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.747619    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.173s]> Epoch [1/1] | loss: 0.0606, test loss: 0.0758, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.631s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a86.79]-[f0.7548]-[p0.9271]-[r0.7083].pt"
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.85      1.00      0.92        41

    accuracy                           0.87        53
   macro avg       0.93      0.71      0.75        53
weighted avg       0.89      0.87      0.85        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.416667    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.588235    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.854167    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.921348    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.887186    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.867925    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.845926    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.927083    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.708333    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.754792    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.867925    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.676s]> Epoch [1/1] | loss: 0.0596, test loss: 0.3307, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.127s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a81.13]-[f0.7573]-[p0.7407]-[r0.7896].pt"
              precision    recall  f1-score   support

           0       0.56      0.75      0.64        12
           1       0.92      0.83      0.87        41

    accuracy                           0.81        53
   macro avg       0.74      0.79      0.76        53
weighted avg       0.84      0.81      0.82        53

Log [0.0h, 0.0m, 18.305s]> Epoch [1/1] | loss: 0.0563, test loss: 0.4618, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.166s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a77.36]-[f0.7402]-[p0.7339]-[r0.8242].pt"
              precision    recall  f1-score   support

           0       0.50      0.92      0.65        12
           1       0.97      0.73      0.83        41

    accuracy                           0.77        53
   macro avg       0.73      0.82      0.74        53
weighted avg       0.86      0.77      0.79        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.916667    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.647059    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.967742    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.731707    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.833333    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.861838    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.791158    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.733871    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.824187    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.740196    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.291s]> Epoch [1/1] | loss: 0.0661, test loss: 0.1230, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.198s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a92.45]-[f0.8853]-[p0.9151]-[r0.8628].pt"
              precision    recall  f1-score   support

           0       0.90      0.75      0.82        12
           1       0.93      0.98      0.95        41

    accuracy                           0.92        53
   macro avg       0.92      0.86      0.89        53
weighted avg       0.92      0.92      0.92        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.900000    12.0
1   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.818182    12.0
3   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.930233    41.0
4   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.952381    41.0
6   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.923387    53.0
7   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0
8   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.921996    53.0
9   2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.915116    53.0
10  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.862805    53.0
11  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.885281    53.0
12  2025-04-14 07:31:11  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.158s]> Epoch [1/1] | loss: 0.0633, test loss: 0.1089, lr: 0.001000
Log [0.0h, 0.0m, 0.017s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.892s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a92.45]-[f0.9029]-[p0.8750]-[r0.9512].pt"
              precision    recall  f1-score   support

           0       0.75      1.00      0.86        12
           1       1.00      0.90      0.95        41

    accuracy                           0.92        53
   macro avg       0.88      0.95      0.90        53
weighted avg       0.94      0.92      0.93        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.750000    12.0
1   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
2   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.857143    12.0
3   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
4   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.902439    41.0
5   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.948718    41.0
6   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.943396    53.0
7   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0
8   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.927984    53.0
9   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.875000    53.0
10  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.951220    53.0
11  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.902930    53.0
12  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.084s]> Epoch [1/1] | loss: 0.0636, test loss: 0.1509, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.776s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/dlstm-[a86.79]-[f0.8339]-[p0.8096]-[r0.8852].pt"
              precision    recall  f1-score   support

           0       0.65      0.92      0.76        12
           1       0.97      0.85      0.91        41

    accuracy                           0.87        53
   macro avg       0.81      0.89      0.83        53
weighted avg       0.90      0.87      0.88        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.647059    12.0
1   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.916667    12.0
2   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.758621    12.0
3   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.972222    41.0
4   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.853659    41.0
5   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.909091    41.0
6   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.898600    53.0
7   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.867925    53.0
8   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.875022    53.0
9   2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.809641    53.0
10  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.885163    53.0
11  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.833856    53.0
12  2025-04-14 07:31:12  A-1-1cn^ --> A-1-1cn^^  ...  0.867925    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.214s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.132s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.208s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.064s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.150s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 22.298s]> Epoch [1/1] | loss: 0.0679, test loss: 0.6243, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.322s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a61.15]-[f0.4845]-[p0.5353]-[r0.5937].pt"
              precision    recall  f1-score   support

           0       0.14      0.57      0.23        14
           1       0.93      0.62      0.74       125

    accuracy                           0.61       139
   macro avg       0.54      0.59      0.48       139
weighted avg       0.85      0.61      0.69       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.142857    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.228571    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.927711   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.616000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.740385   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.848661   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.611511   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.688835   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.535284   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.593714   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.484478   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.611511   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.529s]> Epoch [1/1] | loss: 0.0593, test loss: 1.3901, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.566s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a48.20]-[f0.4214]-[p0.5433]-[r0.6169].pt"
              precision    recall  f1-score   support

           0       0.14      0.79      0.23        14
           1       0.95      0.45      0.61       125

    accuracy                           0.48       139
   macro avg       0.54      0.62      0.42       139
weighted avg       0.87      0.48      0.57       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.137500    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.234043    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.949153   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.448000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.608696   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.867403   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.482014   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.570961   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.543326   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.616857   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.421369   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.482014   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.142s]> Epoch [1/1] | loss: 0.0605, test loss: 0.5240, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.717s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a63.31]-[f0.5177]-[p0.5633]-[r0.6691].pt"
              precision    recall  f1-score   support

           0       0.18      0.71      0.28        14
           1       0.95      0.62      0.75       125

    accuracy                           0.63       139
   macro avg       0.56      0.67      0.52       139
weighted avg       0.87      0.63      0.71       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.175439    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.714286    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.281690    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.951220   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.624000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.753623   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.873083   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.633094   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.706090   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.563329   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.669143   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.517657   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.633094   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.004s]> Epoch [1/1] | loss: 0.0541, test loss: 1.0059, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 5.226s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a53.24]-[f0.4418]-[p0.5295]-[r0.5814].pt"
              precision    recall  f1-score   support

           0       0.13      0.64      0.22        14
           1       0.93      0.52      0.67       125

    accuracy                           0.53       139
   macro avg       0.53      0.58      0.44       139
weighted avg       0.85      0.53      0.62       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.130435    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.642857    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.216867    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.928571   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.520000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.666667   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.848184   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.532374   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.621363   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.529503   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.581429   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.441767   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.532374   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.368s]> Epoch [1/1] | loss: 0.0581, test loss: 0.5041, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.348s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a73.38]-[f0.5558]-[p0.5603]-[r0.6300].pt"
              precision    recall  f1-score   support

           0       0.19      0.50      0.27        14
           1       0.93      0.76      0.84       125

    accuracy                           0.73       139
   macro avg       0.56      0.63      0.56       139
weighted avg       0.86      0.73      0.78       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.189189    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.274510    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.931373   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.760000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.837004   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.856620   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.733813   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.780350   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.560281   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.630000   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.555757   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.733813   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.961s]> Epoch [1/1] | loss: 0.0592, test loss: 0.6229, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.315s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a66.91]-[f0.5522]-[p0.5842]-[r0.7209].pt"
              precision    recall  f1-score   support

           0       0.20      0.79      0.32        14
           1       0.96      0.66      0.78       125

    accuracy                           0.67       139
   macro avg       0.58      0.72      0.55       139
weighted avg       0.89      0.67      0.73       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.203704    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.323529    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.964706   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.656000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.780952   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.888058   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.669065   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.734881   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.584205   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.720857   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.552241   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.669065   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.334s]> Epoch [1/1] | loss: 0.0632, test loss: 0.7572, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.809s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a50.36]-[f0.4425]-[p0.5593]-[r0.6606].pt"
              precision    recall  f1-score   support

           0       0.15      0.86      0.26        14
           1       0.97      0.46      0.63       125

    accuracy                           0.50       139
   macro avg       0.56      0.66      0.44       139
weighted avg       0.88      0.50      0.59       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.151899    14.0
1   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.857143    14.0
2   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.258065    14.0
3   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.966667   125.0
4   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.464000   125.0
5   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.627027   125.0
6   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.884604   139.0
7   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.503597   139.0
8   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.589865   139.0
9   2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.559283   139.0
10  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.660571   139.0
11  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.442546   139.0
12  2025-04-14 07:31:49  A-1-1cn --> E-2-2cn  ...  0.503597   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.462s]> Epoch [1/1] | loss: 0.0570, test loss: 0.8963, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.638s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a57.55]-[f0.4613]-[p0.5271]-[r0.5737].pt"
              precision    recall  f1-score   support

           0       0.13      0.57      0.21        14
           1       0.92      0.58      0.71       125

    accuracy                           0.58       139
   macro avg       0.53      0.57      0.46       139
weighted avg       0.84      0.58      0.66       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.131148    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.213333    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.923077   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.576000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.709360   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.843314   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.575540   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.659400   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.527112   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.573714   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.461346   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.575540   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 24.019s]> Epoch [1/1] | loss: 0.0689, test loss: 0.0501, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.655s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.812s]> Epoch [1/1] | loss: 0.0622, test loss: 0.9166, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.509s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a50.36]-[f0.4228]-[p0.5238]-[r0.5654].pt"
              precision    recall  f1-score   support

           0       0.12      0.64      0.21        14
           1       0.92      0.49      0.64       125

    accuracy                           0.50       139
   macro avg       0.52      0.57      0.42       139
weighted avg       0.84      0.50      0.60       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.123288    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.642857    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.206897    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.924242   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.488000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.638743   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.843571   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.503597   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.595248   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.523765   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.565429   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.422820   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.503597   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 24.144s]> Epoch [1/1] | loss: 0.0639, test loss: 0.2387, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.248s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a10.07]-[f0.0940]-[p0.2974]-[r0.4683].pt"
              precision    recall  f1-score   support

           0       0.09      0.93      0.17        14
           1       0.50      0.01      0.02       125

    accuracy                           0.10       139
   macro avg       0.30      0.47      0.09       139
weighted avg       0.46      0.10      0.03       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.094891    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.928571    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.172185    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.500000   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.008000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.015748   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.459198   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.100719   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.031504   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.297445   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.468286   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.093967   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.100719   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.917s]> Epoch [1/1] | loss: 0.0609, test loss: 0.6005, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 5.154s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a64.03]-[f0.5133]-[p0.5539]-[r0.6414].pt"
              precision    recall  f1-score   support

           0       0.17      0.64      0.26        14
           1       0.94      0.64      0.76       125

    accuracy                           0.64       139
   macro avg       0.55      0.64      0.51       139
weighted avg       0.86      0.64      0.71       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.166667    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.642857    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.264706    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.941176   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.640000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.761905   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.863168   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.640288   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.711827   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.553922   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.641429   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.513305   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.640288   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.724s]> Epoch [1/1] | loss: 0.0554, test loss: 1.0334, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.638s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a48.92]-[f0.4264]-[p0.5446]-[r0.6209].pt"
              precision    recall  f1-score   support

           0       0.14      0.79      0.24        14
           1       0.95      0.46      0.62       125

    accuracy                           0.49       139
   macro avg       0.54      0.62      0.43       139
weighted avg       0.87      0.49      0.58       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.139241    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.236559    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.950000   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.456000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.616216   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.868341   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.489209   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.577977   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.544620   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.620857   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.426388   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.489209   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 24.289s]> Epoch [1/1] | loss: 0.0575, test loss: 1.1271, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.433s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a50.36]-[f0.4154]-[p0.5122]-[r0.5337].pt"
              precision    recall  f1-score   support

           0       0.11      0.57      0.19        14
           1       0.91      0.50      0.64       125

    accuracy                           0.50       139
   macro avg       0.51      0.53      0.42       139
weighted avg       0.83      0.50      0.60       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.112676    14.0
1   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.188235    14.0
3   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.911765   125.0
4   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.496000   125.0
5   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.642487   125.0
6   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.831281   139.0
7   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.503597   139.0
8   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.596735   139.0
9   2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.512220   139.0
10  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.533714   139.0
11  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.415361   139.0
12  2025-04-14 07:31:50  A-1-1cn --> E-2-2cn  ...  0.503597   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 24.902s]> Epoch [1/1] | loss: 0.0646, test loss: 0.8757, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.048s]> Saved model weights to "model-weights/a-1-1cn --> e-2-2cn/dlstm-[a51.80]-[f0.4463]-[p0.5499]-[r0.6369].pt"
              precision    recall  f1-score   support

           0       0.15      0.79      0.25        14
           1       0.95      0.49      0.65       125

    accuracy                           0.52       139
   macro avg       0.55      0.64      0.45       139
weighted avg       0.87      0.52      0.61       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.146667    14.0
1   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.247191    14.0
3   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.953125   125.0
4   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.488000   125.0
5   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.645503   125.0
6   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.871899   139.0
7   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.517986   139.0
8   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.605385   139.0
9   2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.549896   139.0
10  2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.636857   139.0
11  2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.446347   139.0
12  2025-04-14 07:31:51  A-1-1cn --> E-2-2cn  ...  0.517986   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.134s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.057s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.175s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.165s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.134s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.017s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.178s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.010s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 18.146s]> Epoch [1/1] | loss: 0.0580, test loss: 0.6135, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.278s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a70.00]-[f0.6000]-[p0.6863]-[r0.6044].pt"
              precision    recall  f1-score   support

           0       0.67      0.29      0.40         7
           1       0.71      0.92      0.80        13

    accuracy                           0.70        20
   macro avg       0.69      0.60      0.60        20
weighted avg       0.69      0.70      0.66        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.666667     7.0
1   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.400000     7.0
3   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.705882    13.0
4   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.800000    13.0
6   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.692157    20.0
7   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.700000    20.0
8   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.660000    20.0
9   2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.686275    20.0
10  2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.604396    20.0
11  2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.600000    20.0
12  2025-04-14 07:32:18  A-1-1cn --> O-2-2cn  ...  0.700000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.964s]> Epoch [1/1] | loss: 0.0544, test loss: 0.6887, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.127s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.5611]-[p0.5938]-[r0.5659].pt"
              precision    recall  f1-score   support

           0       0.50      0.29      0.36         7
           1       0.69      0.85      0.76        13

    accuracy                           0.65        20
   macro avg       0.59      0.57      0.56        20
weighted avg       0.62      0.65      0.62        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.363636     7.0
3   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.687500    13.0
4   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.758621    13.0
6   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.621875    20.0
7   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.620376    20.0
9   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.593750    20.0
10  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.565934    20.0
11  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.561129    20.0
12  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.846s]> Epoch [1/1] | loss: 0.0615, test loss: 0.5779, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.002s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a70.00]-[f0.6000]-[p0.6863]-[r0.6044].pt"
              precision    recall  f1-score   support

           0       0.67      0.29      0.40         7
           1       0.71      0.92      0.80        13

    accuracy                           0.70        20
   macro avg       0.69      0.60      0.60        20
weighted avg       0.69      0.70      0.66        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.666667     7.0
1   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.400000     7.0
3   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.705882    13.0
4   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.800000    13.0
6   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.692157    20.0
7   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.700000    20.0
8   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.660000    20.0
9   2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.686275    20.0
10  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.604396    20.0
11  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.600000    20.0
12  2025-04-14 07:32:19  A-1-1cn --> O-2-2cn  ...  0.700000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.640s]> Epoch [1/1] | loss: 0.0575, test loss: 0.4942, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.109s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.6491]-[p0.6875]-[r0.6978].pt"
              precision    recall  f1-score   support

           0       0.50      0.86      0.63         7
           1       0.88      0.54      0.67        13

    accuracy                           0.65        20
   macro avg       0.69      0.70      0.65        20
weighted avg       0.74      0.65      0.65        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.857143     7.0
2   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.631579     7.0
3   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.875000    13.0
4   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.538462    13.0
5   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.666667    13.0
6   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.743750    20.0
7   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.654386    20.0
9   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.687500    20.0
10  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.697802    20.0
11  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.649123    20.0
12  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.374s]> Epoch [1/1] | loss: 0.0748, test loss: 0.1994, lr: 0.001000
Log [0.0h, 0.0m, 0.016s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.674s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.381s]> Epoch [1/1] | loss: 0.0586, test loss: 0.6118, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.325s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a70.00]-[f0.6970]-[p0.7172]-[r0.7363].pt"
              precision    recall  f1-score   support

           0       0.55      0.86      0.67         7
           1       0.89      0.62      0.73        13

    accuracy                           0.70        20
   macro avg       0.72      0.74      0.70        20
weighted avg       0.77      0.70      0.71        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.545455     7.0
1   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.857143     7.0
2   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.666667     7.0
3   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.888889    13.0
4   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.615385    13.0
5   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.727273    13.0
6   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.768687    20.0
7   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.700000    20.0
8   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.706061    20.0
9   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.717172    20.0
10  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.736264    20.0
11  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.696970    20.0
12  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.700000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.380s]> Epoch [1/1] | loss: 0.0541, test loss: 0.5918, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.622s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a70.00]-[f0.6429]-[p0.6667]-[r0.6374].pt"
              precision    recall  f1-score   support

           0       0.60      0.43      0.50         7
           1       0.73      0.85      0.79        13

    accuracy                           0.70        20
   macro avg       0.67      0.64      0.64        20
weighted avg       0.69      0.70      0.69        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.600000     7.0
1   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.428571     7.0
2   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
3   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.733333    13.0
4   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.785714    13.0
6   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.686667    20.0
7   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.700000    20.0
8   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.685714    20.0
9   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.666667    20.0
10  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.637363    20.0
11  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.642857    20.0
12  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.700000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.262s]> Epoch [1/1] | loss: 0.0662, test loss: 0.5290, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.963s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a60.00]-[f0.5238]-[p0.5333]-[r0.5275].pt"
              precision    recall  f1-score   support

           0       0.40      0.29      0.33         7
           1       0.67      0.77      0.71        13

    accuracy                           0.60        20
   macro avg       0.53      0.53      0.52        20
weighted avg       0.57      0.60      0.58        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.400000     7.0
1   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.333333     7.0
3   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.666667    13.0
4   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.769231    13.0
5   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.714286    13.0
6   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.573333    20.0
7   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.600000    20.0
8   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.580952    20.0
9   2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.533333    20.0
10  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.527473    20.0
11  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.523810    20.0
12  2025-04-14 07:32:20  A-1-1cn --> O-2-2cn  ...  0.600000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.663s]> Epoch [1/1] | loss: 0.0548, test loss: 0.7981, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.868s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.5611]-[p0.5938]-[r0.5659].pt"
              precision    recall  f1-score   support

           0       0.50      0.29      0.36         7
           1       0.69      0.85      0.76        13

    accuracy                           0.65        20
   macro avg       0.59      0.57      0.56        20
weighted avg       0.62      0.65      0.62        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.363636     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.687500    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.758621    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.621875    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.620376    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.593750    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.565934    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.561129    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.958s]> Epoch [1/1] | loss: 0.0576, test loss: 0.6983, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.027s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.5611]-[p0.5938]-[r0.5659].pt"
              precision    recall  f1-score   support

           0       0.50      0.29      0.36         7
           1       0.69      0.85      0.76        13

    accuracy                           0.65        20
   macro avg       0.59      0.57      0.56        20
weighted avg       0.62      0.65      0.62        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.363636     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.687500    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.758621    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.621875    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.620376    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.593750    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.565934    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.561129    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.318s]> Epoch [1/1] | loss: 0.0518, test loss: 0.5601, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.554s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a75.00]-[f0.7442]-[p0.7500]-[r0.7747].pt"
              precision    recall  f1-score   support

           0       0.60      0.86      0.71         7
           1       0.90      0.69      0.78        13

    accuracy                           0.75        20
   macro avg       0.75      0.77      0.74        20
weighted avg       0.80      0.75      0.76        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.600000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.857143     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.705882     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.900000    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.692308    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.782609    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.795000    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.755754    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.774725    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.744246    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.114s]> Epoch [1/1] | loss: 0.0592, test loss: 0.5649, lr: 0.001000
Log [0.0h, 0.0m, 0.032s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.578s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.6267]-[p0.6250]-[r0.6319].pt"
              precision    recall  f1-score   support

           0       0.50      0.57      0.53         7
           1       0.75      0.69      0.72        13

    accuracy                           0.65        20
   macro avg       0.62      0.63      0.63        20
weighted avg       0.66      0.65      0.65        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.571429     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.533333     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.692308    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.720000    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.662500    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.654667    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.625000    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.631868    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.626667    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.450s]> Epoch [1/1] | loss: 0.0574, test loss: 0.5571, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.685s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a75.00]-[f0.7442]-[p0.7500]-[r0.7747].pt"
              precision    recall  f1-score   support

           0       0.60      0.86      0.71         7
           1       0.90      0.69      0.78        13

    accuracy                           0.75        20
   macro avg       0.75      0.77      0.74        20
weighted avg       0.80      0.75      0.76        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.600000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.857143     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.705882     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.900000    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.692308    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.782609    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.795000    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.755754    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.774725    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.744246    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.400s]> Epoch [1/1] | loss: 0.0590, test loss: 0.5259, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.642s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a75.00]-[f0.6416]-[p0.8611]-[r0.6429].pt"
              precision    recall  f1-score   support

           0       1.00      0.29      0.44         7
           1       0.72      1.00      0.84        13

    accuracy                           0.75        20
   macro avg       0.86      0.64      0.64        20
weighted avg       0.82      0.75      0.70        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  1.000000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.444444     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.722222    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.838710    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.819444    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.700717    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.861111    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.642857    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.641577    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.750000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.166s]> Epoch [1/1] | loss: 0.0569, test loss: 0.8006, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.431s]> Saved model weights to "model-weights/a-1-1cn --> o-2-2cn/dlstm-[a65.00]-[f0.5611]-[p0.5938]-[r0.5659].pt"
              precision    recall  f1-score   support

           0       0.50      0.29      0.36         7
           1       0.69      0.85      0.76        13

    accuracy                           0.65        20
   macro avg       0.59      0.57      0.56        20
weighted avg       0.62      0.65      0.62        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.500000     7.0
1   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.285714     7.0
2   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.363636     7.0
3   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.687500    13.0
4   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.846154    13.0
5   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.758621    13.0
6   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.621875    20.0
7   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.620376    20.0
9   2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.593750    20.0
10  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.565934    20.0
11  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.561129    20.0
12  2025-04-14 07:32:21  A-1-1cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.144s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.206s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.198s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.133s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.170s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.061s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.214s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.172s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 17.115s]> Epoch [1/1] | loss: 0.0608, test loss: 0.2470, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.822s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:32:49  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.701s]> Epoch [1/1] | loss: 0.0579, test loss: 0.3018, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.628s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:32:50  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.082s]> Epoch [1/1] | loss: 0.0558, test loss: 0.1890, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.320s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a90.48]-[f0.8688]-[p0.8688]-[r0.8688].pt"
              precision    recall  f1-score   support

           0       0.94      0.94      0.94        16
           1       0.80      0.80      0.80         5

    accuracy                           0.90        21
   macro avg       0.87      0.87      0.87        21
weighted avg       0.90      0.90      0.90        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.937500    16.0
1   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.937500    16.0
3   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
4   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
6   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.904762    21.0
7   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.904762    21.0
9   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.868750    21.0
10  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.868750    21.0
11  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.868750    21.0
12  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.256s]> Epoch [1/1] | loss: 0.0574, test loss: 0.3727, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.278s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.7429]-[p0.9211]-[r0.7000].pt"
              precision    recall  f1-score   support

           0       0.84      1.00      0.91        16
           1       1.00      0.40      0.57         5

    accuracy                           0.86        21
   macro avg       0.92      0.70      0.74        21
weighted avg       0.88      0.86      0.83        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.842105    16.0
1   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.914286    16.0
3   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.400000     5.0
5   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.571429     5.0
6   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.879699    21.0
7   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.832653    21.0
9   2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.921053    21.0
10  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.700000    21.0
11  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.742857    21.0
12  2025-04-14 07:32:51  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.251s]> Epoch [1/1] | loss: 0.0529, test loss: 0.1023, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.199s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.234s]> Epoch [1/1] | loss: 0.0645, test loss: 0.0838, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.055s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.340s]> Epoch [1/1] | loss: 0.0593, test loss: 0.3084, lr: 0.001000
Log [0.0h, 0.0m, 0.012s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.411s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.7879]-[p0.8162]-[r0.7688].pt"
              precision    recall  f1-score   support

           0       0.88      0.94      0.91        16
           1       0.75      0.60      0.67         5

    accuracy                           0.86        21
   macro avg       0.82      0.77      0.79        21
weighted avg       0.85      0.86      0.85        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.882353    16.0
1   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.909091    16.0
3   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.750000     5.0
4   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
6   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.850840    21.0
7   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.851371    21.0
9   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.816176    21.0
10  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.768750    21.0
11  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.787879    21.0
12  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.302s]> Epoch [1/1] | loss: 0.0564, test loss: 0.2603, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.400s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.778s]> Epoch [1/1] | loss: 0.0569, test loss: 0.3093, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.333s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:32:52  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.734s]> Epoch [1/1] | loss: 0.0624, test loss: 0.0973, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.771s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.147s]> Epoch [1/1] | loss: 0.0548, test loss: 0.3347, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.276s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.7879]-[p0.8162]-[r0.7688].pt"
              precision    recall  f1-score   support

           0       0.88      0.94      0.91        16
           1       0.75      0.60      0.67         5

    accuracy                           0.86        21
   macro avg       0.82      0.77      0.79        21
weighted avg       0.85      0.86      0.85        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.882353    16.0
1   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.909091    16.0
3   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.750000     5.0
4   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
6   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.850840    21.0
7   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.851371    21.0
9   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.816176    21.0
10  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.768750    21.0
11  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.787879    21.0
12  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.010s]> Epoch [1/1] | loss: 0.0594, test loss: 0.2795, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.991s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.7429]-[p0.9211]-[r0.7000].pt"
              precision    recall  f1-score   support

           0       0.84      1.00      0.91        16
           1       1.00      0.40      0.57         5

    accuracy                           0.86        21
   macro avg       0.92      0.70      0.74        21
weighted avg       0.88      0.86      0.83        21

Log [0.0h, 0.0m, 20.749s]> Epoch [1/1] | loss: 0.0551, test loss: 0.3154, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.071s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.7429]-[p0.9211]-[r0.7000].pt"
              precision    recall  f1-score   support

           0       0.84      1.00      0.91        16
           1       1.00      0.40      0.57         5

    accuracy                           0.86        21
   macro avg       0.92      0.70      0.74        21
weighted avg       0.88      0.86      0.83        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.842105    16.0
1   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.914286    16.0
3   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.400000     5.0
5   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.571429     5.0
6   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.879699    21.0
7   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.832653    21.0
9   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.921053    21.0
10  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.700000    21.0
11  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.742857    21.0
12  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.383s]> Epoch [1/1] | loss: 0.0568, test loss: 0.3534, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.218s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a80.95]-[f0.7667]-[p0.7500]-[r0.8063].pt"
              precision    recall  f1-score   support

           0       0.93      0.81      0.87        16
           1       0.57      0.80      0.67         5

    accuracy                           0.81        21
   macro avg       0.75      0.81      0.77        21
weighted avg       0.84      0.81      0.82        21

Log [0.0h, 0.0m, 20.557s]> Epoch [1/1] | loss: 0.0595, test loss: 0.1997, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.249s]> Saved model weights to "model-weights/a-1-1cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:32:53  A-1-1cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.033s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.154s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.240s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.202s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.201s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.065s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.207s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 20.134s]> Epoch [1/1] | loss: 0.0447, test loss: 0.4214, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.350s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:29  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.857s]> Epoch [1/1] | loss: 0.0460, test loss: 0.3899, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.916s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.943s]> Epoch [1/1] | loss: 0.0457, test loss: 0.4302, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.065s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:30  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.509s]> Epoch [1/1] | loss: 0.0461, test loss: 0.4027, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.412s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.658s]> Epoch [1/1] | loss: 0.0436, test loss: 0.4398, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.392s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.424s]> Epoch [1/1] | loss: 0.0455, test loss: 0.5216, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.744s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.621s]> Epoch [1/1] | loss: 0.0456, test loss: 0.4460, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.941s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.480s]> Epoch [1/1] | loss: 0.0453, test loss: 0.4150, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.390s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:31  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.900s]> Epoch [1/1] | loss: 0.0456, test loss: 0.4919, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.853s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 21.105s]> Epoch [1/1] | loss: 0.0449, test loss: 0.2726, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.401s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.112s]> Epoch [1/1] | loss: 0.0443, test loss: 0.4270, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.864s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.579s]> Epoch [1/1] | loss: 0.0455, test loss: 0.4956, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 9.310s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.004s]> Epoch [1/1] | loss: 0.0451, test loss: 0.4443, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.675s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.175s]> Epoch [1/1] | loss: 0.0462, test loss: 0.5783, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.592s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.708s]> Epoch [1/1] | loss: 0.0458, test loss: 0.4028, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.805s]> Saved model weights to "model-weights/e-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:33:32  E-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.039s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.047s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.067s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 9.967s]> Epoch [1/1] | loss: 0.0443, test loss: 0.1631, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.596s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.883s]> Epoch [1/1] | loss: 0.0460, test loss: 0.2359, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.194s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.728s]> Epoch [1/1] | loss: 0.0444, test loss: 0.1809, lr: 0.001000
Log [0.0h, 0.0m, 0.012s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.413s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.062s]> Epoch [1/1] | loss: 0.0450, test loss: 0.1911, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.889s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.518s]> Epoch [1/1] | loss: 0.0443, test loss: 0.1853, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.199s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:53  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.256s]> Epoch [1/1] | loss: 0.0448, test loss: 0.1899, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.064s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.210s]> Epoch [1/1] | loss: 0.0451, test loss: 0.2045, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.351s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.478s]> Epoch [1/1] | loss: 0.0433, test loss: 0.1837, lr: 0.001000
Log [0.0h, 0.0m, 0.010s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.928s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.270s]> Epoch [1/1] | loss: 0.0446, test loss: 0.2511, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.334s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.384s]> Epoch [1/1] | loss: 0.0443, test loss: 0.1525, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.665s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.641s]> Epoch [1/1] | loss: 0.0433, test loss: 0.2041, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.612s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.394s]> Epoch [1/1] | loss: 0.0442, test loss: 0.1422, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.845s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.553s]> Epoch [1/1] | loss: 0.0457, test loss: 0.2477, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.646s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.062s]> Epoch [1/1] | loss: 0.0447, test loss: 0.2149, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.563s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.510s]> Epoch [1/1] | loss: 0.0449, test loss: 0.2157, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.913s]> Saved model weights to "model-weights/e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:33:54  E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.067s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.127s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> O-2-2cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 12.148s]> Epoch [1/1] | loss: 0.0443, test loss: 0.7547, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.235s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:16  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.890s]> Epoch [1/1] | loss: 0.0454, test loss: 0.7670, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.128s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:17  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.265s]> Epoch [1/1] | loss: 0.0456, test loss: 0.7654, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.950s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.892s]> Epoch [1/1] | loss: 0.0456, test loss: 0.9051, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.046s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.799s]> Epoch [1/1] | loss: 0.0446, test loss: 0.4662, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.070s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

Log [0.0h, 0.0m, 13.238s]> Epoch [1/1] | loss: 0.0462, test loss: 0.7381, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.980s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.028s]> Epoch [1/1] | loss: 0.0450, test loss: 0.9524, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.005s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.401s]> Epoch [1/1] | loss: 0.0460, test loss: 0.9668, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.735s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.426s]> Epoch [1/1] | loss: 0.0460, test loss: 0.6534, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.917s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.580s]> Epoch [1/1] | loss: 0.0467, test loss: 0.6513, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.923s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.928s]> Epoch [1/1] | loss: 0.0453, test loss: 0.6768, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.811s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.866s]> Epoch [1/1] | loss: 0.0454, test loss: 0.4540, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.856s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.967s]> Epoch [1/1] | loss: 0.0464, test loss: 0.5315, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.531s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:18  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.802s]> Epoch [1/1] | loss: 0.0455, test loss: 0.7041, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.634s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.663s]> Epoch [1/1] | loss: 0.0459, test loss: 0.8601, lr: 0.001000
Log [0.0h, 0.0m, 0.022s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.706s]> Saved model weights to "model-weights/e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:34:19  E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.058s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.142s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.104s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.064s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 12.506s]> Epoch [1/1] | loss: 0.0459, test loss: 1.6779, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.658s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.920s]> Epoch [1/1] | loss: 0.0450, test loss: 1.3950, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.609s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.873s]> Epoch [1/1] | loss: 0.0452, test loss: 1.5368, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.353s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.300s]> Epoch [1/1] | loss: 0.0461, test loss: 1.0876, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.753s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:42  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.883s]> Epoch [1/1] | loss: 0.0452, test loss: 1.0327, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.016s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 14.024s]> Epoch [1/1] | loss: 0.0443, test loss: 1.5245, lr: 0.001000
Log [0.0h, 0.0m, 0.020s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.524s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.101s]> Epoch [1/1] | loss: 0.0450, test loss: 1.1472, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.278s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.512s]> Epoch [1/1] | loss: 0.0451, test loss: 1.3329, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.576s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:43  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.043s]> Epoch [1/1] | loss: 0.0458, test loss: 1.5036, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.069s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.318s]> Epoch [1/1] | loss: 0.0458, test loss: 1.4135, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.755s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.919s]> Epoch [1/1] | loss: 0.0457, test loss: 1.3323, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.533s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 14.252s]> Epoch [1/1] | loss: 0.0452, test loss: 0.8694, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.284s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.983s]> Epoch [1/1] | loss: 0.0459, test loss: 1.2592, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.495s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.094s]> Epoch [1/1] | loss: 0.0439, test loss: 1.2101, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.158s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:44  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.163s]> Epoch [1/1] | loss: 0.0460, test loss: 1.4543, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.256s]> Saved model weights to "model-weights/e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:34:45  E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.188s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.149s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.166s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.236s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> A-1-1cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 11.807s]> Epoch [1/1] | loss: 0.1064, test loss: 0.0962, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.391s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 11.328s]> Epoch [1/1] | loss: 0.0890, test loss: 0.3830, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.128s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:13  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.582s]> Epoch [1/1] | loss: 0.1056, test loss: 0.0884, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.463s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.57]-[f0.4680]-[p0.5915]-[r0.5099].pt"
              precision    recall  f1-score   support

           0       0.40      0.03      0.06        58
           1       0.78      0.99      0.87       205

    accuracy                           0.78       263
   macro avg       0.59      0.51      0.47       263
weighted avg       0.70      0.78      0.69       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.400000    58.0
1   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.034483    58.0
2   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.063492    58.0
3   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.782946   205.0
4   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.985366   205.0
5   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.872570   205.0
6   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.698494   263.0
7   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.775665   263.0
8   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.694142   263.0
9   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.591473   263.0
10  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.509924   263.0
11  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.468031   263.0
12  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.775665   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.387s]> Epoch [1/1] | loss: 0.0942, test loss: 0.1732, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.878s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:14  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.757s]> Epoch [1/1] | loss: 0.0922, test loss: 0.2126, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.668s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.558s]> Epoch [1/1] | loss: 0.0900, test loss: 0.9174, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.738s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.912s]> Epoch [1/1] | loss: 0.0911, test loss: 0.2873, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.939s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.017s]> Epoch [1/1] | loss: 0.1003, test loss: 0.2985, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.171s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.931s]> Epoch [1/1] | loss: 0.1098, test loss: 0.1022, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.013s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.565s]> Epoch [1/1] | loss: 0.1137, test loss: 0.0723, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.848s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a65.02]-[f0.5146]-[p0.5146]-[r0.5160].pt"
              precision    recall  f1-score   support

           0       0.24      0.28      0.26        58
           1       0.79      0.76      0.77       205

    accuracy                           0.65       263
   macro avg       0.51      0.52      0.51       263
weighted avg       0.67      0.65      0.66       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.242424    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.275862    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.258065    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.786802   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.756098   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.771144   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.666749   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.650190   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.657994   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.514613   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.515980   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.514604   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.650190   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.323s]> Epoch [1/1] | loss: 0.0935, test loss: 0.0671, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.817s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

Log [0.0h, 0.0m, 12.788s]> Epoch [1/1] | loss: 0.1087, test loss: 0.1215, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.236s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a26.24]-[f0.2401]-[p0.5755]-[r0.5206].pt"
              precision    recall  f1-score   support

           0       0.23      0.98      0.37        58
           1       0.92      0.06      0.11       205

    accuracy                           0.26       263
   macro avg       0.58      0.52      0.24       263
weighted avg       0.77      0.26      0.17       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.228000    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.982759    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.370130    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.923077   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.058537   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.110092   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.769790   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.262357   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.167439   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.575538   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.520648   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.240111   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.262357   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.913s]> Epoch [1/1] | loss: 0.1046, test loss: 0.0745, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.382s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.007s]> Epoch [1/1] | loss: 0.0952, test loss: 0.1082, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.444s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:35:15  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.124s]> Epoch [1/1] | loss: 0.0978, test loss: 0.1206, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.195s]> Saved model weights to "model-weights/o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:35:16  O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.072s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> E-2-2cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 7.998s]> Epoch [1/1] | loss: 0.1115, test loss: 0.0560, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.768s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a71.94]-[f0.4830]-[p0.4975]-[r0.4951].pt"
              precision    recall  f1-score   support

           0       0.10      0.21      0.13        14
           1       0.90      0.78      0.83       125

    accuracy                           0.72       139
   macro avg       0.50      0.50      0.48       139
weighted avg       0.82      0.72      0.76       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.096774    14.0
1   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.214286    14.0
2   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.133333    14.0
3   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.898148   125.0
4   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.776000   125.0
5   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.832618   125.0
6   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.817434   139.0
7   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.719424   139.0
8   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.762186   139.0
9   2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.497461   139.0
10  2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.495143   139.0
11  2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.482976   139.0
12  2025-04-14 07:35:37  O-2-2cn --> E-2-2cn  ...  0.719424   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.588s]> Epoch [1/1] | loss: 0.1092, test loss: 0.0492, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.651s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.681s]> Epoch [1/1] | loss: 0.1202, test loss: 0.0581, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.700s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a48.92]-[f0.3902]-[p0.4863]-[r0.4623].pt"
              precision    recall  f1-score   support

           0       0.09      0.43      0.14        14
           1       0.89      0.50      0.64       125

    accuracy                           0.49       139
   macro avg       0.49      0.46      0.39       139
weighted avg       0.81      0.49      0.59       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.086957    14.0
1   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.428571    14.0
2   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.144578    14.0
3   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.885714   125.0
4   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.496000   125.0
5   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.635897   125.0
6   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.805264   139.0
7   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.489209   139.0
8   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.586412   139.0
9   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.486335   139.0
10  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.462286   139.0
11  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.390238   139.0
12  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.489209   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.047s]> Epoch [1/1] | loss: 0.0888, test loss: 0.0599, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.603s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a33.81]-[f0.3195]-[p0.5318]-[r0.5686].pt"
              precision    recall  f1-score   support

           0       0.12      0.86      0.21        14
           1       0.95      0.28      0.43       125

    accuracy                           0.34       139
   macro avg       0.53      0.57      0.32       139
weighted avg       0.86      0.34      0.41       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.117647    14.0
1   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.857143    14.0
2   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.206897    14.0
3   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.945946   125.0
4   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.280000   125.0
5   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.432099   125.0
6   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.862520   139.0
7   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.338129   139.0
8   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.409417   139.0
9   2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.531797   139.0
10  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.568571   139.0
11  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.319498   139.0
12  2025-04-14 07:35:38  O-2-2cn --> E-2-2cn  ...  0.338129   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.706s]> Epoch [1/1] | loss: 0.1128, test loss: 0.0548, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 3.934s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a10.07]-[f0.0915]-[p0.0504]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.10      1.00      0.18        14
           1       0.00      0.00      0.00       125

    accuracy                           0.10       139
   macro avg       0.05      0.50      0.09       139
weighted avg       0.01      0.10      0.02       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  1.000000    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.183007    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.010144   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.018432   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.050360   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.091503   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 8.768s]> Epoch [1/1] | loss: 0.0985, test loss: 0.1595, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.464s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a10.07]-[f0.0915]-[p0.0504]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.10      1.00      0.18        14
           1       0.00      0.00      0.00       125

    accuracy                           0.10       139
   macro avg       0.05      0.50      0.09       139
weighted avg       0.01      0.10      0.02       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  1.000000    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.183007    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.010144   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.018432   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.050360   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.091503   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.276s]> Epoch [1/1] | loss: 0.0940, test loss: 0.1241, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.373s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a75.54]-[f0.5410]-[p0.5420]-[r0.5786].pt"
              precision    recall  f1-score   support

           0       0.17      0.36      0.23        14
           1       0.92      0.80      0.85       125

    accuracy                           0.76       139
   macro avg       0.54      0.58      0.54       139
weighted avg       0.84      0.76      0.79       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.166667    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.357143    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.227273    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.917431   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.800000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.854701   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.841815   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.755396   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.791507   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.542049   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.578571   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.540987   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.755396   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.526s]> Epoch [1/1] | loss: 0.1034, test loss: 0.0565, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.229s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.505s]> Epoch [1/1] | loss: 0.0807, test loss: 0.1055, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.310s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a51.80]-[f0.4395]-[p0.5382]-[r0.6051].pt"
              precision    recall  f1-score   support

           0       0.14      0.71      0.23        14
           1       0.94      0.50      0.65       125

    accuracy                           0.52       139
   macro avg       0.54      0.61      0.44       139
weighted avg       0.86      0.52      0.61       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.136986    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.714286    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.229885    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.939394   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.496000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.649215   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.858576   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.517986   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.606980   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.538190   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.605143   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.439550   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.517986   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.457s]> Epoch [1/1] | loss: 0.0932, test loss: 0.1417, lr: 0.001000
Log [0.0h, 0.0m, 0.008s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.551s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a10.07]-[f0.0915]-[p0.0504]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.10      1.00      0.18        14
           1       0.00      0.00      0.00       125

    accuracy                           0.10       139
   macro avg       0.05      0.50      0.09       139
weighted avg       0.01      0.10      0.02       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  1.000000    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.183007    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.010144   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.018432   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.050360   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.091503   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.100719   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.416s]> Epoch [1/1] | loss: 0.0942, test loss: 0.0698, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.679s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:35:39  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.306s]> Epoch [1/1] | loss: 0.1172, test loss: 0.0520, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 5.065s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.820s]> Epoch [1/1] | loss: 0.1213, test loss: 0.1278, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.594s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a89.93]-[f0.4735]-[p0.4496]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        14
           1       0.90      1.00      0.95       125

    accuracy                           0.90       139
   macro avg       0.45      0.50      0.47       139
weighted avg       0.81      0.90      0.85       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
1   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
2   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.000000    14.0
3   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   125.0
4   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  1.000000   125.0
5   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.946970   125.0
6   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.808706   139.0
7   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   139.0
8   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.851591   139.0
9   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.449640   139.0
10  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.500000   139.0
11  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.473485   139.0
12  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.899281   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 9.857s]> Epoch [1/1] | loss: 0.0921, test loss: 0.1155, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.387s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a23.02]-[f0.2223]-[p0.4513]-[r0.4134].pt"
              precision    recall  f1-score   support

           0       0.08      0.64      0.14        14
           1       0.82      0.18      0.30       125

    accuracy                           0.23       139
   macro avg       0.45      0.41      0.22       139
weighted avg       0.75      0.23      0.28       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.081081    14.0
1   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.642857    14.0
2   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.144000    14.0
3   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.821429   125.0
4   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.184000   125.0
5   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.300654   125.0
6   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.746861   139.0
7   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.230216   139.0
8   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.284876   139.0
9   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.451255   139.0
10  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.413429   139.0
11  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.222327   139.0
12  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.230216   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 10.031s]> Epoch [1/1] | loss: 0.0973, test loss: 0.1336, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.249s]> Saved model weights to "model-weights/o-2-2cn --> e-2-2cn/dlstm-[a39.57]-[f0.3249]-[p0.4550]-[r0.3786].pt"
              precision    recall  f1-score   support

           0       0.06      0.36      0.11        14
           1       0.85      0.40      0.54       125

    accuracy                           0.40       139
   macro avg       0.45      0.38      0.32       139
weighted avg       0.77      0.40      0.50       139

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.062500    14.0
1   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.357143    14.0
2   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.106383    14.0
3   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.847458   125.0
4   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.400000   125.0
5   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.543478   125.0
6   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.768397   139.0
7   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.395683   139.0
8   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.499454   139.0
9   2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.454979   139.0
10  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.378571   139.0
11  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.324931   139.0
12  2025-04-14 07:35:40  O-2-2cn --> E-2-2cn  ...  0.395683   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.020s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 3.252s]> Epoch [1/1] | loss: 0.1159, test loss: 0.1125, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.175s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.183s]> Epoch [1/1] | loss: 0.1119, test loss: 0.1258, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.375s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:53  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.206s]> Epoch [1/1] | loss: 0.0945, test loss: 0.0591, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.213s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.374s]> Epoch [1/1] | loss: 0.0993, test loss: 0.2134, lr: 0.001000
Log [0.0h, 0.0m, 0.016s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.334s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 3.920s]> Epoch [1/1] | loss: 0.0888, test loss: 0.0701, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.370s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.344s]> Epoch [1/1] | loss: 0.0964, test loss: 0.1200, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

Log [0.0h, 0.0m, 4.283s]> Epoch [1/1] | loss: 0.1216, test loss: 0.4228, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.185s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.401s]> Epoch [1/1] | loss: 0.1099, test loss: 0.0927, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.173s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.7619]-[p0.8750]-[r0.7500].pt"
              precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.75      1.00      0.86         3

    accuracy                           0.80         5
   macro avg       0.88      0.75      0.76         5
weighted avg       0.85      0.80      0.78         5

Log [0.0h, 0.0m, 3.852s]> Epoch [1/1] | loss: 0.0910, test loss: 0.0792, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.172s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.497s]> Epoch [1/1] | loss: 0.0858, test loss: 0.1003, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.199s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a100.00]-[f1.0000]-[p1.0000]-[r1.0000].pt"
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         3

    accuracy                           1.00         5
   macro avg       1.00      1.00      1.00         5
weighted avg       1.00      1.00      1.00         5

                   date       transfer_strategy  ... perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.372s]> Epoch [1/1] | loss: 0.0984, test loss: 0.2237, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.340s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.994s]> Epoch [1/1] | loss: 0.0977, test loss: 0.1441, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.388s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.152s]> Epoch [1/1] | loss: 0.1226, test loss: 0.1100, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.092s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date       transfer_strategy  ...   perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.462s]> Epoch [1/1] | loss: 0.0901, test loss: 0.1293, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.138s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.40      1.00      0.57         2
           1       0.00      0.00      0.00         3

    accuracy                           0.40         5
   macro avg       0.20      0.50      0.29         5
weighted avg       0.16      0.40      0.23         5

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     2.0
1   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.571429     2.0
3   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
4   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
5   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
6   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.160000     5.0
7   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.228571     5.0
9   2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.200000     5.0
10  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.500000     5.0
11  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:35:54  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.584s]> Epoch [1/1] | loss: 0.1015, test loss: 0.0797, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.201s]> Saved model weights to "model-weights/o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.40      1.00      0.57         2
           1       0.00      0.00      0.00         3

    accuracy                           0.40         5
   macro avg       0.20      0.50      0.29         5
weighted avg       0.16      0.40      0.23         5

                   date       transfer_strategy  ...      perf support
0   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     2.0
1   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.571429     2.0
3   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
4   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
5   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.000000     3.0
6   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.160000     5.0
7   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.228571     5.0
9   2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.200000     5.0
10  2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.500000     5.0
11  2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:35:55  O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `O-2-2cn --> G-3-4cn`
Options selected for train set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 3.740s]> Epoch [1/1] | loss: 0.1047, test loss: 0.0850, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.813s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.387s]> Epoch [1/1] | loss: 0.0965, test loss: 0.0895, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.788s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:09  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.586s]> Epoch [1/1] | loss: 0.0834, test loss: 0.0667, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.407s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.690s]> Epoch [1/1] | loss: 0.1171, test loss: 0.1557, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.226s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 4.807s]> Epoch [1/1] | loss: 0.0987, test loss: 0.0992, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.511s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:10  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.726s]> Epoch [1/1] | loss: 0.0981, test loss: 0.0986, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.496s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.883s]> Epoch [1/1] | loss: 0.1167, test loss: 0.2622, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.006s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 5.714s]> Epoch [1/1] | loss: 0.0835, test loss: 0.0722, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.470s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:11  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.449s]> Epoch [1/1] | loss: 0.0953, test loss: 0.0708, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.028s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.482s]> Epoch [1/1] | loss: 0.1012, test loss: 0.1250, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.951s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 5.986s]> Epoch [1/1] | loss: 0.1020, test loss: 0.1211, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.370s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a71.43]-[f0.4167]-[p0.3750]-[r0.4688].pt"
              precision    recall  f1-score   support

           0       0.75      0.94      0.83        16
           1       0.00      0.00      0.00         5

    accuracy                           0.71        21
   macro avg       0.38      0.47      0.42        21
weighted avg       0.57      0.71      0.63        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.750000    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.833333    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.571429    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.714286    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.634921    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.375000    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.468750    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.416667    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.714286    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.358s]> Epoch [1/1] | loss: 0.0845, test loss: 0.1048, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.397s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.944s]> Epoch [1/1] | loss: 0.1007, test loss: 0.1115, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.035s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.818s]> Epoch [1/1] | loss: 0.1080, test loss: 0.1279, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.050s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 6.936s]> Epoch [1/1] | loss: 0.0969, test loss: 0.0982, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.232s]> Saved model weights to "model-weights/o-2-2cn --> g-3-4cn/dlstm-[a71.43]-[f0.4167]-[p0.3750]-[r0.4688].pt"
              precision    recall  f1-score   support

           0       0.75      0.94      0.83        16
           1       0.00      0.00      0.00         5

    accuracy                           0.71        21
   macro avg       0.38      0.47      0.42        21
weighted avg       0.57      0.71      0.63        21

                   date    transfer_strategy  ...      perf support
0   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.750000    16.0
1   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.833333    16.0
3   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.571429    21.0
7   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.714286    21.0
8   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.634921    21.0
9   2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.375000    21.0
10  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.468750    21.0
11  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.416667    21.0
12  2025-04-14 07:36:12  O-2-2cn --> G-3-4cn  ...  0.714286    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.155s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.072s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.119s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.177s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.132s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 17.487s]> Epoch [1/1] | loss: 0.0607, test loss: 0.3578, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.897s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a81.13]-[f0.7675]-[p0.7492]-[r0.8191].pt"
              precision    recall  f1-score   support

           0       0.56      0.83      0.67        12
           1       0.94      0.80      0.87        41

    accuracy                           0.81        53
   macro avg       0.75      0.82      0.77        53
weighted avg       0.86      0.81      0.82        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.555556    12.0
1   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.833333    12.0
2   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
3   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.942857    41.0
4   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.804878    41.0
5   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.868421    41.0
6   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.855166    53.0
7   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.811321    53.0
8   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.822741    53.0
9   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.749206    53.0
10  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.819106    53.0
11  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.767544    53.0
12  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.811321    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.408s]> Epoch [1/1] | loss: 0.0643, test loss: 0.1711, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.890s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a88.68]-[f0.8151]-[p0.8819]-[r0.7795].pt"
              precision    recall  f1-score   support

           0       0.88      0.58      0.70        12
           1       0.89      0.98      0.93        41

    accuracy                           0.89        53
   macro avg       0.88      0.78      0.82        53
weighted avg       0.89      0.89      0.88        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.875000    12.0
1   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.583333    12.0
2   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.700000    12.0
3   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.888889    41.0
4   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.930233    41.0
6   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.885744    53.0
7   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0
8   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.878104    53.0
9   2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.881944    53.0
10  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.779472    53.0
11  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.815116    53.0
12  2025-04-14 07:36:41  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.014s]> Epoch [1/1] | loss: 0.0630, test loss: 0.1927, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.275s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a86.79]-[f0.8168]-[p0.8087]-[r0.8262].pt"
              precision    recall  f1-score   support

           0       0.69      0.75      0.72        12
           1       0.93      0.90      0.91        41

    accuracy                           0.87        53
   macro avg       0.81      0.83      0.82        53
weighted avg       0.87      0.87      0.87        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.692308    12.0
1   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.720000    12.0
3   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.925000    41.0
4   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.902439    41.0
5   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.913580    41.0
6   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872315    53.0
7   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0
8   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.869751    53.0
9   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.808654    53.0
10  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.826220    53.0
11  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.816790    53.0
12  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.473s]> Epoch [1/1] | loss: 0.0625, test loss: 0.2487, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.631s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a84.91]-[f0.7056]-[p0.9184]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.84      1.00      0.91        41

    accuracy                           0.85        53
   macro avg       0.92      0.67      0.71        53
weighted avg       0.87      0.85      0.82        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.333333    12.0
2   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.500000    12.0
3   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.836735    41.0
4   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.911111    41.0
6   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.873700    53.0
7   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.849057    53.0
8   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.818029    53.0
9   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.918367    53.0
10  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    53.0
11  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.705556    53.0
12  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.849057    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.175s]> Epoch [1/1] | loss: 0.0619, test loss: 0.0954, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.593s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a90.57]-[f0.8515]-[p0.8990]-[r0.8211].pt"
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.91      0.98      0.94        41

    accuracy                           0.91        53
   macro avg       0.90      0.82      0.85        53
weighted avg       0.90      0.91      0.90        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.888889    12.0
1   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.761905    12.0
3   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.909091    41.0
4   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.941176    41.0
6   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.904517    53.0
7   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.905660    53.0
8   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.900587    53.0
9   2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.898990    53.0
10  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.821138    53.0
11  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.851541    53.0
12  2025-04-14 07:36:42  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.905660    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.865s]> Epoch [1/1] | loss: 0.0642, test loss: 0.1539, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.199s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a86.79]-[f0.7922]-[p0.8321]-[r0.7673].pt"
              precision    recall  f1-score   support

           0       0.78      0.58      0.67        12
           1       0.89      0.95      0.92        41

    accuracy                           0.87        53
   macro avg       0.83      0.77      0.79        53
weighted avg       0.86      0.87      0.86        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.777778    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.583333    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886364    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.951220    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.917647    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.861778    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.860821    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.832071    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.767276    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.792157    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.644s]> Epoch [1/1] | loss: 0.0646, test loss: 0.0918, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.251s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a90.57]-[f0.8515]-[p0.8990]-[r0.8211].pt"
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.91      0.98      0.94        41

    accuracy                           0.91        53
   macro avg       0.90      0.82      0.85        53
weighted avg       0.90      0.91      0.90        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.888889    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.761905    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.909091    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.941176    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.904517    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.905660    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.900587    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.898990    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.821138    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.851541    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.905660    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.272s]> Epoch [1/1] | loss: 0.0601, test loss: 0.1811, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.607s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a88.68]-[f0.8151]-[p0.8819]-[r0.7795].pt"
              precision    recall  f1-score   support

           0       0.88      0.58      0.70        12
           1       0.89      0.98      0.93        41

    accuracy                           0.89        53
   macro avg       0.88      0.78      0.82        53
weighted avg       0.89      0.89      0.88        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.875000    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.583333    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.700000    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.888889    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.930233    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.885744    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.878104    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.881944    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.779472    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.815116    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.292s]> Epoch [1/1] | loss: 0.0582, test loss: 0.3870, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.515s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a79.25]-[f0.7492]-[p0.7337]-[r0.8069].pt"
              precision    recall  f1-score   support

           0       0.53      0.83      0.65        12
           1       0.94      0.78      0.85        41

    accuracy                           0.79        53
   macro avg       0.73      0.81      0.75        53
weighted avg       0.85      0.79      0.81        53

Log [0.0h, 0.0m, 19.053s]> Epoch [1/1] | loss: 0.0634, test loss: 0.0968, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.451s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a94.34]-[f0.9109]-[p0.9659]-[r0.8750].pt"
              precision    recall  f1-score   support

           0       1.00      0.75      0.86        12
           1       0.93      1.00      0.96        41

    accuracy                           0.94        53
   macro avg       0.97      0.88      0.91        53
weighted avg       0.95      0.94      0.94        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.857143    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.931818    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.964706    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.947256    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.943396    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.940352    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.965909    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.875000    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.910924    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.943396    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.021s]> Epoch [1/1] | loss: 0.0600, test loss: 0.4143, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.100s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a79.25]-[f0.7267]-[p0.7140]-[r0.7480].pt"
              precision    recall  f1-score   support

           0       0.53      0.67      0.59        12
           1       0.89      0.83      0.86        41

    accuracy                           0.79        53
   macro avg       0.71      0.75      0.73        53
weighted avg       0.81      0.79      0.80        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.533333    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.592593    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.894737    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.829268    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.860759    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.812910    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.792453    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.800042    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.714035    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.747967    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.726676    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.792453    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.551s]> Epoch [1/1] | loss: 0.0711, test loss: 0.1568, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.729s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a75.47]-[f0.7037]-[p0.6927]-[r0.7530].pt"
              precision    recall  f1-score   support

           0       0.47      0.75      0.58        12
           1       0.91      0.76      0.83        41

    accuracy                           0.75        53
   macro avg       0.69      0.75      0.70        53
weighted avg       0.81      0.75      0.77        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.473684    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.750000    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.580645    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.911765    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.756098    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.826667    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.812577    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.754717    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.770964    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.692724    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.753049    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.703656    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.754717    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.365s]> Epoch [1/1] | loss: 0.0615, test loss: 0.1558, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.029s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a86.79]-[f0.8261]-[p0.8070]-[r0.8557].pt"
              precision    recall  f1-score   support

           0       0.67      0.83      0.74        12
           1       0.95      0.88      0.91        41

    accuracy                           0.87        53
   macro avg       0.81      0.86      0.83        53
weighted avg       0.88      0.87      0.87        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.833333    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.740741    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.947368    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.878049    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.911392    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.883813    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.872754    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.807018    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.855691    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.826067    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.867925    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 19.892s]> Epoch [1/1] | loss: 0.0689, test loss: 0.0836, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.221s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a88.68]-[f0.8279]-[p0.8535]-[r0.8089].pt"
              precision    recall  f1-score   support

           0       0.80      0.67      0.73        12
           1       0.91      0.95      0.93        41

    accuracy                           0.89        53
   macro avg       0.85      0.81      0.83        53
weighted avg       0.88      0.89      0.88        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.800000    12.0
1   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.727273    12.0
3   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.906977    41.0
4   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.951220    41.0
5   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.928571    41.0
6   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.882756    53.0
7   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0
8   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.882994    53.0
9   2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.853488    53.0
10  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.808943    53.0
11  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.827922    53.0
12  2025-04-14 07:36:43  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.886792    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 20.569s]> Epoch [1/1] | loss: 0.0593, test loss: 0.4137, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.010s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> a-1-1cn^^/dlstm-[a79.25]-[f0.7492]-[p0.7337]-[r0.8069].pt"
              precision    recall  f1-score   support

           0       0.53      0.83      0.65        12
           1       0.94      0.78      0.85        41

    accuracy                           0.79        53
   macro avg       0.73      0.81      0.75        53
weighted avg       0.85      0.79      0.81        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.526316    12.0
1   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.833333    12.0
2   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.645161    12.0
3   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.941176    41.0
4   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.780488    41.0
5   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.853333    41.0
6   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.847246    53.0
7   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.792453    53.0
8   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.806200    53.0
9   2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.733746    53.0
10  2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.806911    53.0
11  2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.749247    53.0
12  2025-04-14 07:36:44  A-1-1cn^ + O-2-2cn --> A-1-1cn^^  ...  0.792453    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.139s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.159s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.135s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.122s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.171s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.103s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn --> E-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 21.147s]> Epoch [1/1] | loss: 0.0746, test loss: 0.2257, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.772s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a38.13]-[f0.3341]-[p0.4866]-[r0.4657].pt"
              precision    recall  f1-score   support

           0       0.09      0.57      0.16        14
           1       0.88      0.36      0.51       125

    accuracy                           0.38       139
   macro avg       0.49      0.47      0.33       139
weighted avg       0.80      0.38      0.48       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.090909    14.0
1   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.156863    14.0
3   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.882353   125.0
4   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.360000   125.0
5   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.511364   125.0
6   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.802639   139.0
7   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.381295   139.0
8   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.475659   139.0
9   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.486631   139.0
10  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.465714   139.0
11  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.334113   139.0
12  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.381295   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.853s]> Epoch [1/1] | loss: 0.0570, test loss: 0.6004, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.692s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a60.43]-[f0.4798]-[p0.5336]-[r0.5897].pt"
              precision    recall  f1-score   support

           0       0.14      0.57      0.23        14
           1       0.93      0.61      0.73       125

    accuracy                           0.60       139
   macro avg       0.53      0.59      0.48       139
weighted avg       0.85      0.60      0.68       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.140351    14.0
1   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.571429    14.0
2   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.225352    14.0
3   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.926829   125.0
4   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.608000   125.0
5   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.734300   125.0
6   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.847616   139.0
7   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.604317   139.0
8   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.683039   139.0
9   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.533590   139.0
10  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.589714   139.0
11  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.479826   139.0
12  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.604317   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.708s]> Epoch [1/1] | loss: 0.0579, test loss: 0.9933, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.686s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a50.36]-[f0.4364]-[p0.5472]-[r0.6289].pt"
              precision    recall  f1-score   support

           0       0.14      0.79      0.24        14
           1       0.95      0.47      0.63       125

    accuracy                           0.50       139
   macro avg       0.55      0.63      0.44       139
weighted avg       0.87      0.50      0.59       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.142857    14.0
1   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.241758    14.0
3   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.951613   125.0
4   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.472000   125.0
5   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.631016   125.0
6   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.870155   139.0
7   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.503597   139.0
8   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.591810   139.0
9   2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.547235   139.0
10  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.628857   139.0
11  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.436387   139.0
12  2025-04-14 07:37:19  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.503597   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.493s]> Epoch [1/1] | loss: 0.0692, test loss: 0.7042, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.114s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a53.24]-[f0.4253]-[p0.5065]-[r0.5180].pt"
              precision    recall  f1-score   support

           0       0.11      0.50      0.18        14
           1       0.91      0.54      0.67       125

    accuracy                           0.53       139
   macro avg       0.51      0.52      0.43       139
weighted avg       0.83      0.53      0.62       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.107692    14.0
1   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.177215    14.0
3   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.905405   125.0
4   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.536000   125.0
5   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.673367   125.0
6   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.825060   139.0
7   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.532374   139.0
8   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.623395   139.0
9   2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.506549   139.0
10  2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.518000   139.0
11  2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.425291   139.0
12  2025-04-14 07:37:20  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.532374   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.552s]> Epoch [1/1] | loss: 0.0630, test loss: 0.6072, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.431s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a61.87]-[f0.4789]-[p0.5253]-[r0.5660].pt"
              precision    recall  f1-score   support

           0       0.13      0.50      0.21        14
           1       0.92      0.63      0.75       125

    accuracy                           0.62       139
   macro avg       0.53      0.57      0.48       139
weighted avg       0.84      0.62      0.69       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.132075    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.208955    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.918605   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.632000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.748815   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.839386   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.618705   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.694441   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.525340   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.566000   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.478885   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.618705   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.505s]> Epoch [1/1] | loss: 0.0599, test loss: 0.8161, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.891s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a46.04]-[f0.4062]-[p0.5395]-[r0.6049].pt"
              precision    recall  f1-score   support

           0       0.13      0.79      0.23        14
           1       0.95      0.42      0.59       125

    accuracy                           0.46       139
   macro avg       0.54      0.60      0.41       139
weighted avg       0.86      0.46      0.55       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.132530    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.226804    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.946429   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.424000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.585635   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.864453   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.460432   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.549494   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.539479   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.604857   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.406220   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.460432   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.820s]> Epoch [1/1] | loss: 0.0663, test loss: 0.6812, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.750s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a64.03]-[f0.4687]-[p0.5060]-[r0.5146].pt"
              precision    recall  f1-score   support

           0       0.11      0.36      0.17        14
           1       0.90      0.67      0.77       125

    accuracy                           0.64       139
   macro avg       0.51      0.51      0.47       139
weighted avg       0.82      0.64      0.71       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.108696    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.357143    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.166667    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.903226   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.672000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.770642   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.823201   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.640288   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.709810   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.505961   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.514571   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.468654   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.640288   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.423s]> Epoch [1/1] | loss: 0.0645, test loss: 0.9809, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.945s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a55.40]-[f0.4712]-[p0.5568]-[r0.6569].pt"
              precision    recall  f1-score   support

           0       0.16      0.79      0.26        14
           1       0.96      0.53      0.68       125

    accuracy                           0.55       139
   macro avg       0.56      0.66      0.47       139
weighted avg       0.88      0.55      0.64       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.157143    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.261905    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.956522   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.528000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.680412   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.876009   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.553957   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.638261   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.556832   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.656857   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.471159   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.553957   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.326s]> Epoch [1/1] | loss: 0.0602, test loss: 0.9131, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.333s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a41.01]-[f0.3701]-[p0.5305]-[r0.5769].pt"
              precision    recall  f1-score   support

           0       0.12      0.79      0.21        14
           1       0.94      0.37      0.53       125

    accuracy                           0.41       139
   macro avg       0.53      0.58      0.37       139
weighted avg       0.86      0.41      0.50       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.122222    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.211538    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.938776   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.368000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.528736   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.856533   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.410072   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.496788   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.530499   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.576857   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.370137   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.410072   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.787s]> Epoch [1/1] | loss: 0.0616, test loss: 0.9742, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.744s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a53.96]-[f0.4612]-[p0.5540]-[r0.6489].pt"
              precision    recall  f1-score   support

           0       0.15      0.79      0.26        14
           1       0.96      0.51      0.67       125

    accuracy                           0.54       139
   macro avg       0.55      0.65      0.46       139
weighted avg       0.87      0.54      0.63       139

Log [0.0h, 0.0m, 21.853s]> Epoch [1/1] | loss: 0.0632, test loss: 1.2466, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.763s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a23.02]-[f0.2277]-[p0.5058]-[r0.5086].pt"
              precision    recall  f1-score   support

           0       0.10      0.86      0.18        14
           1       0.91      0.16      0.27       125

    accuracy                           0.23       139
   macro avg       0.51      0.51      0.23       139
weighted avg       0.83      0.23      0.26       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.102564    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.857143    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.183206    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.909091   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.160000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.272109   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.827858   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.230216   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.263155   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.505828   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.508571   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.227657   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.230216   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.244s]> Epoch [1/1] | loss: 0.0590, test loss: 0.8040, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 3.967s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a53.96]-[f0.4297]-[p0.5080]-[r0.5220].pt"
              precision    recall  f1-score   support

           0       0.11      0.50      0.18        14
           1       0.91      0.54      0.68       125

    accuracy                           0.54       139
   macro avg       0.51      0.52      0.43       139
weighted avg       0.83      0.54      0.63       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.109375    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.179487    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.906667   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.544000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.680000   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.826364   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.539568   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.629589   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.508021   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.522000   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.429744   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.539568   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.762s]> Epoch [1/1] | loss: 0.0629, test loss: 0.7164, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.765s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a64.03]-[f0.5314]-[p0.5763]-[r0.7049].pt"
              precision    recall  f1-score   support

           0       0.19      0.79      0.31        14
           1       0.96      0.62      0.76       125

    accuracy                           0.64       139
   macro avg       0.58      0.70      0.53       139
weighted avg       0.89      0.64      0.71       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.189655    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.305556    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.962963   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.624000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.757282   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.885076   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.640288   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.711784   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.576309   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.704857   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.531419   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.640288   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.319s]> Epoch [1/1] | loss: 0.0633, test loss: 1.2910, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.659s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a43.17]-[f0.3857]-[p0.5344]-[r0.5889].pt"
              precision    recall  f1-score   support

           0       0.13      0.79      0.22        14
           1       0.94      0.39      0.55       125

    accuracy                           0.43       139
   macro avg       0.53      0.59      0.39       139
weighted avg       0.86      0.43      0.52       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.126437    14.0
1   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.785714    14.0
2   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.217822    14.0
3   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.942308   125.0
4   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.392000   125.0
5   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.553672   125.0
6   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.860134   139.0
7   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.431655   139.0
8   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.519846   139.0
9   2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.534372   139.0
10  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.588857   139.0
11  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.385747   139.0
12  2025-04-14 07:37:21  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.431655   139.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.792s]> Epoch [1/1] | loss: 0.0639, test loss: 0.4408, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 4.905s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn --> e-2-2cn/dlstm-[a55.40]-[f0.4386]-[p0.5110]-[r0.5300].pt"
              precision    recall  f1-score   support

           0       0.11      0.50      0.18        14
           1       0.91      0.56      0.69       125

    accuracy                           0.55       139
   macro avg       0.51      0.53      0.44       139
weighted avg       0.83      0.55      0.64       139

                   date               transfer_strategy  ...      perf support
0   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.112903    14.0
1   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.500000    14.0
2   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.184211    14.0
3   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.909091   125.0
4   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.560000   125.0
5   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.693069   125.0
6   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.828899   139.0
7   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.553957   139.0
8   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.641817   139.0
9   2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.510997   139.0
10  2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.530000   139.0
11  2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.438640   139.0
12  2025-04-14 07:37:22  A-1-1cn^ + O-2-2cn --> E-2-2cn  ...  0.553957   139.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.136s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 16.541s]> Epoch [1/1] | loss: 0.0620, test loss: 0.9015, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.322s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:37:47  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.774s]> Epoch [1/1] | loss: 0.0580, test loss: 0.3792, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.325s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.862s]> Epoch [1/1] | loss: 0.0617, test loss: 1.0569, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.335s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.719s]> Epoch [1/1] | loss: 0.0618, test loss: 0.7989, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.316s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.180s]> Epoch [1/1] | loss: 0.0630, test loss: 0.8480, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.204s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:37:48  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.463s]> Epoch [1/1] | loss: 0.0625, test loss: 0.3289, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.190s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.5833]-[p0.5833]-[r0.5833].pt"
              precision    recall  f1-score   support

           0       0.50      0.50      0.50         2
           1       0.67      0.67      0.67         3

    accuracy                           0.60         5
   macro avg       0.58      0.58      0.58         5
weighted avg       0.60      0.60      0.60         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.711s]> Epoch [1/1] | loss: 0.0635, test loss: 0.3398, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.313s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.963s]> Epoch [1/1] | loss: 0.0664, test loss: 0.0895, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.151s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                  transfer_strategy  ...   perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.407s]> Epoch [1/1] | loss: 0.0612, test loss: 0.4069, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.159s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.5833]-[p0.5833]-[r0.5833].pt"
              precision    recall  f1-score   support

           0       0.50      0.50      0.50         2
           1       0.67      0.67      0.67         3

    accuracy                           0.60         5
   macro avg       0.58      0.58      0.58         5
weighted avg       0.60      0.60      0.60         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.583333     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.600000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.283s]> Epoch [1/1] | loss: 0.0655, test loss: 0.1396, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.333s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.588s]> Epoch [1/1] | loss: 0.0704, test loss: 0.0873, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.113s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:37:49  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.337s]> Epoch [1/1] | loss: 0.0630, test loss: 0.1406, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.139s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.320s]> Epoch [1/1] | loss: 0.0618, test loss: 1.1368, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.224s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.296s]> Epoch [1/1] | loss: 0.0621, test loss: 0.7927, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.216s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
1   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
2   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.000000     2.0
3   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.500000     3.0
4   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.571429     3.0
6   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.300000     5.0
7   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0
8   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.342857     5.0
9   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.250000     5.0
10  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.333333     5.0
11  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.285714     5.0
12  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.400000     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 18.219s]> Epoch [1/1] | loss: 0.0636, test loss: 0.0402, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.188s]> Saved model weights to "model-weights/a-1-1cn^_o-2-2cn^ --> o-2-2cn^^/dlstm-[a80.00]-[f0.8000]-[p0.8333]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       0.67      1.00      0.80         2
           1       1.00      0.67      0.80         3

    accuracy                           0.80         5
   macro avg       0.83      0.83      0.80         5
weighted avg       0.87      0.80      0.80         5

                   date                  transfer_strategy  ...      perf support
0   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     2.0
1   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     2.0
2   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     2.0
3   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  1.000000     3.0
4   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.666667     3.0
5   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     3.0
6   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.866667     5.0
7   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
8   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
9   2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
10  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.833333     5.0
11  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0
12  2025-04-14 07:37:50  A-1-1cn^ + O-2-2cn^ --> O-2-2cn^^  ...  0.800000     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.234s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.134s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.067s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.265s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.220s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.237s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.041s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.170s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 21.599s]> Epoch [1/1] | loss: 0.0627, test loss: 0.1305, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.440s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889    16.0
1   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
3   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000     5.0
6   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.915344    21.0
7   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.895658    21.0
9   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.944444    21.0
10  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
11  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.845588    21.0
12  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.949s]> Epoch [1/1] | loss: 0.0549, test loss: 0.1118, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.409s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.656s]> Epoch [1/1] | loss: 0.0575, test loss: 0.3542, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.385s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.7429]-[p0.9211]-[r0.7000].pt"
              precision    recall  f1-score   support

           0       0.84      1.00      0.91        16
           1       1.00      0.40      0.57         5

    accuracy                           0.86        21
   macro avg       0.92      0.70      0.74        21
weighted avg       0.88      0.86      0.83        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.842105    16.0
1   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.914286    16.0
3   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.400000     5.0
5   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.571429     5.0
6   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.879699    21.0
7   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.832653    21.0
9   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.921053    21.0
10  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.700000    21.0
11  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.742857    21.0
12  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.558s]> Epoch [1/1] | loss: 0.0544, test loss: 0.4445, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.163s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a80.95]-[f0.7375]-[p0.7375]-[r0.7375].pt"
              precision    recall  f1-score   support

           0       0.88      0.88      0.88        16
           1       0.60      0.60      0.60         5

    accuracy                           0.81        21
   macro avg       0.74      0.74      0.74        21
weighted avg       0.81      0.81      0.81        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    16.0
1   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    16.0
3   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
4   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
6   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0
7   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0
8   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0
9   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.737500    21.0
10  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.737500    21.0
11  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.737500    21.0
12  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.923s]> Epoch [1/1] | loss: 0.0611, test loss: 0.2795, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.944s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.7879]-[p0.8162]-[r0.7688].pt"
              precision    recall  f1-score   support

           0       0.88      0.94      0.91        16
           1       0.75      0.60      0.67         5

    accuracy                           0.86        21
   macro avg       0.82      0.77      0.79        21
weighted avg       0.85      0.86      0.85        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.882353    16.0
1   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.909091    16.0
3   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000     5.0
4   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.666667     5.0
6   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.850840    21.0
7   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.851371    21.0
9   2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.816176    21.0
10  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.768750    21.0
11  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.787879    21.0
12  2025-04-14 07:38:23  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.087s]> Epoch [1/1] | loss: 0.0595, test loss: 0.2138, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.313s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8688]-[p0.8688]-[r0.8688].pt"
              precision    recall  f1-score   support

           0       0.94      0.94      0.94        16
           1       0.80      0.80      0.80         5

    accuracy                           0.90        21
   macro avg       0.87      0.87      0.87        21
weighted avg       0.90      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
1   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
3   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
4   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
6   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
7   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
9   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
10  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
11  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
12  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.195s]> Epoch [1/1] | loss: 0.0613, test loss: 0.2137, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.110s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.7429]-[p0.9211]-[r0.7000].pt"
              precision    recall  f1-score   support

           0       0.84      1.00      0.91        16
           1       1.00      0.40      0.57         5

    accuracy                           0.86        21
   macro avg       0.92      0.70      0.74        21
weighted avg       0.88      0.86      0.83        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.842105    16.0
1   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.914286    16.0
3   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.400000     5.0
5   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.571429     5.0
6   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.879699    21.0
7   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.832653    21.0
9   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.921053    21.0
10  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.700000    21.0
11  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.742857    21.0
12  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.742s]> Epoch [1/1] | loss: 0.0603, test loss: 0.2190, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.541s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889    16.0
1   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
3   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000     5.0
6   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.915344    21.0
7   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.895658    21.0
9   2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.944444    21.0
10  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
11  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.845588    21.0
12  2025-04-14 07:38:24  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.732s]> Epoch [1/1] | loss: 0.0626, test loss: 0.2545, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.986s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.798s]> Epoch [1/1] | loss: 0.0674, test loss: 0.0942, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.834s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a71.43]-[f0.4167]-[p0.3750]-[r0.4688].pt"
              precision    recall  f1-score   support

           0       0.75      0.94      0.83        16
           1       0.00      0.00      0.00         5

    accuracy                           0.71        21
   macro avg       0.38      0.47      0.42        21
weighted avg       0.57      0.71      0.63        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.833333    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.571429    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.714286    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.634921    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.375000    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.468750    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.416667    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.714286    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.205s]> Epoch [1/1] | loss: 0.0578, test loss: 0.1299, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.125s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a95.24]-[f0.9293]-[p0.9706]-[r0.9000].pt"
              precision    recall  f1-score   support

           0       0.94      1.00      0.97        16
           1       1.00      0.80      0.89         5

    accuracy                           0.95        21
   macro avg       0.97      0.90      0.93        21
weighted avg       0.96      0.95      0.95        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.969697    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.955182    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.952381    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.950457    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.970588    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.900000    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.929293    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.952381    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.592s]> Epoch [1/1] | loss: 0.0672, test loss: 0.1203, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.261s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a57.14]-[f0.3636]-[p0.3529]-[r0.3750].pt"
              precision    recall  f1-score   support

           0       0.71      0.75      0.73        16
           1       0.00      0.00      0.00         5

    accuracy                           0.57        21
   macro avg       0.35      0.38      0.36        21
weighted avg       0.54      0.57      0.55        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.705882    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.727273    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.537815    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.571429    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.554113    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.352941    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.375000    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.363636    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.571429    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.236s]> Epoch [1/1] | loss: 0.0623, test loss: 0.1631, lr: 0.001000
Log [0.0h, 0.0m, 0.017s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.402s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8688]-[p0.8688]-[r0.8688].pt"
              precision    recall  f1-score   support

           0       0.94      0.94      0.94        16
           1       0.80      0.80      0.80         5

    accuracy                           0.90        21
   macro avg       0.87      0.87      0.87        21
weighted avg       0.90      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.868750    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.996s]> Epoch [1/1] | loss: 0.0604, test loss: 0.2198, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.445s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.888889    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.941176    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.600000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.750000     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.915344    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.895658    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.944444    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.845588    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.904762    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.500s]> Epoch [1/1] | loss: 0.0664, test loss: 0.2574, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.086s]> Saved model weights to "model-weights/a-1-1cn_o-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:38:25  A-1-1cn + O-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.224s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.180s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.142s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.014s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.222s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.141s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.176s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.049s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.223s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.061s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.162s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.160s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> A-1-1cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 22.266s]> Epoch [1/1] | loss: 0.0515, test loss: 0.0779, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.611s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a78.33]-[f0.6788]-[p0.6824]-[r0.6755].pt"
              precision    recall  f1-score   support

           0       0.51      0.48      0.50        58
           1       0.86      0.87      0.86       205

    accuracy                           0.78       263
   macro avg       0.68      0.68      0.68       263
weighted avg       0.78      0.78      0.78       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.509091    58.0
1   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.482759    58.0
2   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.495575    58.0
3   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.855769   205.0
4   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.868293   205.0
5   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.861985   205.0
6   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779315   263.0
7   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.783270   263.0
8   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.781180   263.0
9   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682430   263.0
10  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.675526   263.0
11  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.678780   263.0
12  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.783270   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 21.823s]> Epoch [1/1] | loss: 0.0542, test loss: 0.0808, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.351s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:04  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.677s]> Epoch [1/1] | loss: 0.0540, test loss: 0.0965, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.171s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.059s]> Epoch [1/1] | loss: 0.0554, test loss: 0.0785, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.149s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.357s]> Epoch [1/1] | loss: 0.0548, test loss: 0.2061, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.339s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.709s]> Epoch [1/1] | loss: 0.0526, test loss: 0.2968, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.509s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a22.81]-[f0.1915]-[p0.6111]-[r0.5049].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       1.00      0.01      0.02       205

    accuracy                           0.23       263
   macro avg       0.61      0.50      0.19       263
weighted avg       0.83      0.23      0.10       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.222222    58.0
1   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.363636    58.0
3   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
4   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.009756   205.0
5   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.019324   205.0
6   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.828475   263.0
7   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.228137   263.0
8   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.095256   263.0
9   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.611111   263.0
10  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.504878   263.0
11  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.191480   263.0
12  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.228137   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.005s]> Epoch [1/1] | loss: 0.0561, test loss: 0.2074, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.392s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 22.239s]> Epoch [1/1] | loss: 0.0552, test loss: 0.0794, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.139s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.19]-[f0.4933]-[p0.5933]-[r0.5198].pt"
              precision    recall  f1-score   support

           0       0.40      0.07      0.12        58
           1       0.79      0.97      0.87       205

    accuracy                           0.77       263
   macro avg       0.59      0.52      0.49       263
weighted avg       0.70      0.77      0.70       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.400000    58.0
1   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.068966    58.0
2   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.117647    58.0
3   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.786561   205.0
4   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.970732   205.0
5   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.868996   205.0
6   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.701312   263.0
7   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.771863   263.0
8   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.703299   263.0
9   2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.593281   263.0
10  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.519849   263.0
11  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.493321   263.0
12  2025-04-14 07:39:05  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.771863   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.104s]> Epoch [1/1] | loss: 0.0541, test loss: 0.3686, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.368s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 23.029s]> Epoch [1/1] | loss: 0.0531, test loss: 0.2217, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.252s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.933s]> Epoch [1/1] | loss: 0.0552, test loss: 0.0975, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.150s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a78.33]-[f0.4559]-[p0.8912]-[r0.5086].pt"
              precision    recall  f1-score   support

           0       1.00      0.02      0.03        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.89      0.51      0.46       263
weighted avg       0.83      0.78      0.69       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000    58.0
1   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.017241    58.0
2   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.033898    58.0
3   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.782443   205.0
4   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.877944   205.0
6   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.830421   263.0
7   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.783270   263.0
8   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.691805   263.0
9   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.891221   263.0
10  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.508621   263.0
11  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.455921   263.0
12  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.783270   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.568s]> Epoch [1/1] | loss: 0.0534, test loss: 0.3713, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.377s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a22.05]-[f0.1807]-[p0.1103]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.22      1.00      0.36        58
           1       0.00      0.00      0.00       205

    accuracy                           0.22       263
   macro avg       0.11      0.50      0.18       263
weighted avg       0.05      0.22      0.08       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.220532    58.0
1   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000    58.0
2   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.361371    58.0
3   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000   205.0
4   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000   205.0
5   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000   205.0
6   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.048635   263.0
7   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.220532   263.0
8   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.079694   263.0
9   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.110266   263.0
10  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.180685   263.0
12  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.220532   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 22.941s]> Epoch [1/1] | loss: 0.0553, test loss: 0.1220, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.688s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

Log [0.0h, 0.0m, 23.735s]> Epoch [1/1] | loss: 0.0549, test loss: 0.0987, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 7.881s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a77.95]-[f0.4380]-[p0.3897]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        58
           1       0.78      1.00      0.88       205

    accuracy                           0.78       263
   macro avg       0.39      0.50      0.44       263
weighted avg       0.61      0.78      0.68       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
1   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
2   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.000000    58.0
3   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   205.0
4   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  1.000000   205.0
5   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.876068   205.0
6   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.607570   263.0
7   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0
8   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.682867   263.0
9   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.389734   263.0
10  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.500000   263.0
11  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.438034   263.0
12  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.779468   263.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 23.628s]> Epoch [1/1] | loss: 0.0537, test loss: 0.0873, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 8.255s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> a-1-1cn/dlstm-[a69.20]-[f0.6003]-[p0.5957]-[r0.6170].pt"
              precision    recall  f1-score   support

           0       0.35      0.48      0.41        58
           1       0.84      0.75      0.79       205

    accuracy                           0.69       263
   macro avg       0.60      0.62      0.60       263
weighted avg       0.73      0.69      0.71       263

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.354430    58.0
1   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.482759    58.0
2   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.408759    58.0
3   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.836957   205.0
4   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.751220   205.0
5   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.791774   205.0
6   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.730544   263.0
7   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.692015   263.0
8   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.707307   263.0
9   2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.595693   263.0
10  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.616989   263.0
11  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.600266   263.0
12  2025-04-14 07:39:06  E-2-2cn + O-2-2cn --> A-1-1cn  ...  0.692015   263.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.028s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.057s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.052s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.060s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.033s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 13.038s]> Epoch [1/1] | loss: 0.0567, test loss: 0.0427, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.021s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 12.192s]> Epoch [1/1] | loss: 0.0553, test loss: 0.0607, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.424s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.747s]> Epoch [1/1] | loss: 0.0561, test loss: 0.1461, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.083s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a71.43]-[f0.6190]-[p0.6364]-[r0.8400].pt"
              precision    recall  f1-score   support

           0       0.27      1.00      0.43         3
           1       1.00      0.68      0.81        25

    accuracy                           0.71        28
   macro avg       0.64      0.84      0.62        28
weighted avg       0.92      0.71      0.77        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.272727     3.0
1   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000     3.0
2   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.428571     3.0
3   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
4   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.680000    25.0
5   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.809524    25.0
6   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.922078    28.0
7   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.714286    28.0
8   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.768707    28.0
9   2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.636364    28.0
10  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.840000    28.0
11  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.619048    28.0
12  2025-04-14 07:39:30  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.714286    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.653s]> Epoch [1/1] | loss: 0.0566, test loss: 0.0619, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.754s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.394s]> Epoch [1/1] | loss: 0.0559, test loss: 0.0596, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.119s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.500s]> Epoch [1/1] | loss: 0.0543, test loss: 0.1721, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.113s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a10.71]-[f0.0968]-[p0.0536]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.11      1.00      0.19         3
           1       0.00      0.00      0.00        25

    accuracy                           0.11        28
   macro avg       0.05      0.50      0.10        28
weighted avg       0.01      0.11      0.02        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.193548     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.011480    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.020737    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.053571    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.096774    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.595s]> Epoch [1/1] | loss: 0.0549, test loss: 0.3058, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.612s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a10.71]-[f0.0968]-[p0.0536]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.11      1.00      0.19         3
           1       0.00      0.00      0.00        25

    accuracy                           0.11        28
   macro avg       0.05      0.50      0.10        28
weighted avg       0.01      0.11      0.02        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.193548     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.011480    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.020737    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.053571    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.096774    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.107143    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.498s]> Epoch [1/1] | loss: 0.0580, test loss: 0.0974, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.919s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.350s]> Epoch [1/1] | loss: 0.0573, test loss: 0.0528, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.986s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.830s]> Epoch [1/1] | loss: 0.0571, test loss: 0.0496, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.813s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.719s]> Epoch [1/1] | loss: 0.0565, test loss: 0.0598, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.855s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.979s]> Epoch [1/1] | loss: 0.0545, test loss: 0.1054, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.699s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.331s]> Epoch [1/1] | loss: 0.0529, test loss: 0.0511, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.700s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:31  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.117s]> Epoch [1/1] | loss: 0.0569, test loss: 0.0677, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.786s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.644s]> Epoch [1/1] | loss: 0.0573, test loss: 0.0808, lr: 0.001000
Log [0.0h, 0.0m, 0.011s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.719s]> Saved model weights to "model-weights/e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:39:32  E-2-2cn^ + O-2-2cn --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.065s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.002s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.006s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.010s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 12.708s]> Epoch [1/1] | loss: 0.0508, test loss: 0.2544, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.499s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:54  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.053s]> Epoch [1/1] | loss: 0.0516, test loss: 0.0291, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.381s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 13.752s]> Epoch [1/1] | loss: 0.0524, test loss: 0.6405, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.230s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:55  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.212s]> Epoch [1/1] | loss: 0.0522, test loss: 0.4765, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.268s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.436s]> Epoch [1/1] | loss: 0.0528, test loss: 0.8345, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.183s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.434s]> Epoch [1/1] | loss: 0.0505, test loss: 0.0628, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.247s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a100.00]-[f1.0000]-[p1.0000]-[r1.0000].pt"
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         3

    accuracy                           1.00         5
   macro avg       1.00      1.00      1.00         5
weighted avg       1.00      1.00      1.00         5

                   date                 transfer_strategy  ... perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.0     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.589s]> Epoch [1/1] | loss: 0.0519, test loss: 0.5429, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.202s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.072s]> Epoch [1/1] | loss: 0.0524, test loss: 0.6923, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.184s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.050s]> Epoch [1/1] | loss: 0.0528, test loss: 0.7164, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.156s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.528s]> Epoch [1/1] | loss: 0.0529, test loss: 0.0974, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.154s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.757s]> Epoch [1/1] | loss: 0.0525, test loss: 0.7490, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.103s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.515s]> Epoch [1/1] | loss: 0.0530, test loss: 0.5910, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.123s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:56  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.970s]> Epoch [1/1] | loss: 0.0535, test loss: 0.5633, lr: 0.001000
Log [0.0h, 0.0m, 0.007s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.239s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.382s]> Epoch [1/1] | loss: 0.0535, test loss: 0.9542, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.163s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.772s]> Epoch [1/1] | loss: 0.0522, test loss: 0.1236, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.187s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date                 transfer_strategy  ...   perf support
0   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
1   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
2   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.000     2.0
3   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     3.0
4   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  1.000     3.0
5   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.750     3.0
6   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.360     5.0
7   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0
8   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.450     5.0
9   2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.300     5.0
10  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.500     5.0
11  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.375     5.0
12  2025-04-14 07:39:57  E-2-2cn + O-2-2cn^ --> O-2-2cn^^  ...  0.600     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.037s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.017s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.013s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 13.010s]> Epoch [1/1] | loss: 0.0560, test loss: 0.7950, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.745s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:21  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 14.592s]> Epoch [1/1] | loss: 0.0549, test loss: 0.1916, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.178s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:23  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.956s]> Epoch [1/1] | loss: 0.0488, test loss: 0.0978, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.162s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.167s]> Epoch [1/1] | loss: 0.0558, test loss: 0.5658, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.620s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.578s]> Epoch [1/1] | loss: 0.0564, test loss: 0.4662, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.739s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.486s]> Epoch [1/1] | loss: 0.0548, test loss: 0.6260, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.213s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.421s]> Epoch [1/1] | loss: 0.0523, test loss: 0.1940, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.393s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a80.95]-[f0.6912]-[p0.7500]-[r0.6687].pt"
              precision    recall  f1-score   support

           0       0.83      0.94      0.88        16
           1       0.67      0.40      0.50         5

    accuracy                           0.81        21
   macro avg       0.75      0.67      0.69        21
weighted avg       0.79      0.81      0.79        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.833333    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.937500    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.882353    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.400000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.793651    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.791317    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.750000    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.668750    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.691176    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.809524    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.533s]> Epoch [1/1] | loss: 0.0544, test loss: 0.3889, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.259s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 16.291s]> Epoch [1/1] | loss: 0.0550, test loss: 0.8474, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.370s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.975s]> Epoch [1/1] | loss: 0.0560, test loss: 0.8310, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.205s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 17.061s]> Epoch [1/1] | loss: 0.0566, test loss: 1.6157, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.948s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.892s]> Epoch [1/1] | loss: 0.0553, test loss: 1.5360, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.201s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:24  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 16.735s]> Epoch [1/1] | loss: 0.0559, test loss: 1.5490, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.500s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 15.977s]> Epoch [1/1] | loss: 0.0545, test loss: 0.4209, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.264s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 17.345s]> Epoch [1/1] | loss: 0.0537, test loss: 0.0905, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.950s]> Saved model weights to "model-weights/e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.4324]-[p0.3810]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.76      1.00      0.86        16
           1       0.00      0.00      0.00         5

    accuracy                           0.76        21
   macro avg       0.38      0.50      0.43        21
weighted avg       0.58      0.76      0.66        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    16.0
1   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  1.000000    16.0
2   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.864865    16.0
3   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
4   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
5   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.000000     5.0
6   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.580499    21.0
7   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0
8   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.658945    21.0
9   2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.380952    21.0
10  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.432432    21.0
12  2025-04-14 07:40:25  E-2-2cn + O-2-2cn --> G-3-4cn  ...  0.761905    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.085s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.078s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.060s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.043s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.120s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.070s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.043s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.126s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 26.909s]> Epoch [1/1] | loss: 0.0551, test loss: 0.3036, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.820s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 26.861s]> Epoch [1/1] | loss: 0.0532, test loss: 0.4195, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.588s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 26.791s]> Epoch [1/1] | loss: 0.0561, test loss: 0.3463, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.811s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:03  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.798s]> Epoch [1/1] | loss: 0.0552, test loss: 0.3412, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.533s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.180s]> Epoch [1/1] | loss: 0.0519, test loss: 0.5722, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.356s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 27.376s]> Epoch [1/1] | loss: 0.0549, test loss: 0.2080, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.523s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.461s]> Epoch [1/1] | loss: 0.0570, test loss: 0.3991, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.200s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.921s]> Epoch [1/1] | loss: 0.0537, test loss: 0.4100, lr: 0.001000
Log [0.0h, 0.0m, 0.010s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.432s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.745s]> Epoch [1/1] | loss: 0.0580, test loss: 0.2835, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.139s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.325s]> Epoch [1/1] | loss: 0.0541, test loss: 0.1717, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.663s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.673s]> Epoch [1/1] | loss: 0.0587, test loss: 0.2800, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.293s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 28.265s]> Epoch [1/1] | loss: 0.0639, test loss: 0.2071, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.904s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.473s]> Epoch [1/1] | loss: 0.0637, test loss: 0.2010, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.689s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:04  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.801s]> Epoch [1/1] | loss: 0.0542, test loss: 0.4365, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.978s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a79.25]-[f0.5178]-[p0.8942]-[r0.5417].pt"
              precision    recall  f1-score   support

           0       1.00      0.08      0.15        12
           1       0.79      1.00      0.88        41

    accuracy                           0.79        53
   macro avg       0.89      0.54      0.52        53
weighted avg       0.84      0.79      0.72        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.083333    12.0
2   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.153846    12.0
3   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.788462    41.0
4   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.881720    41.0
6   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.836357    53.0
7   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.792453    53.0
8   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.716919    53.0
9   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.894231    53.0
10  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.541667    53.0
11  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.517783    53.0
12  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.792453    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.581s]> Epoch [1/1] | loss: 0.0546, test loss: 0.4867, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.985s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
1   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
2   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.000000    12.0
3   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    41.0
4   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.872340    41.0
6   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.598434    53.0
7   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0
8   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.674829    53.0
9   2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.386792    53.0
10  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.500000    53.0
11  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.436170    53.0
12  2025-04-14 07:41:05  A-1-1cn^ + E-2-2cn --> A-1-1cn^^  ...  0.773585    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.158s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.185s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.145s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.169s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.179s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.215s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.140s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.080s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.173s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.034s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.083s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.105s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.018s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.025s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.030s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 26.413s]> Epoch [1/1] | loss: 0.0539, test loss: 0.2343, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.667s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a82.14]-[f0.5918]-[p0.5833]-[r0.6067].pt"
              precision    recall  f1-score   support

           0       0.25      0.33      0.29         3
           1       0.92      0.88      0.90        25

    accuracy                           0.82        28
   macro avg       0.58      0.61      0.59        28
weighted avg       0.85      0.82      0.83        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.250000     3.0
1   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
2   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.285714     3.0
3   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.916667    25.0
4   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
5   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.897959    25.0
6   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.845238    28.0
7   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.821429    28.0
8   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.832362    28.0
9   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.583333    28.0
10  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.606667    28.0
11  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.591837    28.0
12  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.821429    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.233s]> Epoch [1/1] | loss: 0.0535, test loss: 0.2132, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.851s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.099s]> Epoch [1/1] | loss: 0.0563, test loss: 0.2248, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.486s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a78.57]-[f0.4400]-[p0.4400]-[r0.4400].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.88      0.88      0.88        25

    accuracy                           0.79        28
   macro avg       0.44      0.44      0.44        28
weighted avg       0.79      0.79      0.79        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
4   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
5   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
6   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
7   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
8   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
9   2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
10  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
11  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
12  2025-04-14 07:41:43  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.549s]> Epoch [1/1] | loss: 0.0555, test loss: 0.2914, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.300s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a85.71]-[f0.4615]-[p0.4444]-[r0.4800].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      0.96      0.92        25

    accuracy                           0.86        28
   macro avg       0.44      0.48      0.46        28
weighted avg       0.79      0.86      0.82        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.888889    25.0
4   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.960000    25.0
5   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.923077    25.0
6   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.793651    28.0
7   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0
8   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.824176    28.0
9   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.444444    28.0
10  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.480000    28.0
11  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.461538    28.0
12  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.783s]> Epoch [1/1] | loss: 0.0520, test loss: 0.2415, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.178s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.991s]> Epoch [1/1] | loss: 0.0597, test loss: 0.1207, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.990s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a78.57]-[f0.4400]-[p0.4400]-[r0.4400].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.88      0.88      0.88        25

    accuracy                           0.79        28
   macro avg       0.44      0.44      0.44        28
weighted avg       0.79      0.79      0.79        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
4   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
5   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
6   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
7   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
8   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
9   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
10  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
11  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
12  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.248s]> Epoch [1/1] | loss: 0.0572, test loss: 0.1375, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.707s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a85.71]-[f0.6267]-[p0.6267]-[r0.6267].pt"
              precision    recall  f1-score   support

           0       0.33      0.33      0.33         3
           1       0.92      0.92      0.92        25

    accuracy                           0.86        28
   macro avg       0.63      0.63      0.63        28
weighted avg       0.86      0.86      0.86        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
1   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
2   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
3   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.920000    25.0
4   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.920000    25.0
5   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.920000    25.0
6   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0
7   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0
8   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0
9   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.626667    28.0
10  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.626667    28.0
11  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.626667    28.0
12  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.857143    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.212s]> Epoch [1/1] | loss: 0.0520, test loss: 0.8287, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.772s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a53.57]-[f0.4510]-[p0.5357]-[r0.5933].pt"
              precision    recall  f1-score   support

           0       0.14      0.67      0.24         3
           1       0.93      0.52      0.67        25

    accuracy                           0.54        28
   macro avg       0.54      0.59      0.45        28
weighted avg       0.84      0.54      0.62        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.142857     3.0
1   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.666667     3.0
2   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.235294     3.0
3   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.928571    25.0
4   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.520000    25.0
5   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.666667    25.0
6   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.844388    28.0
7   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.535714    28.0
8   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.620448    28.0
9   2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.535714    28.0
10  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.593333    28.0
11  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.450980    28.0
12  2025-04-14 07:41:44  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.535714    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.469s]> Epoch [1/1] | loss: 0.0521, test loss: 0.0800, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.910s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a92.86]-[f0.7308]-[p0.9630]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       1.00      0.33      0.50         3
           1       0.93      1.00      0.96        25

    accuracy                           0.93        28
   macro avg       0.96      0.67      0.73        28
weighted avg       0.93      0.93      0.91        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000     3.0
1   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
2   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000     3.0
3   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.925926    25.0
4   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.961538    25.0
6   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.933862    28.0
7   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.928571    28.0
8   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.912088    28.0
9   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.962963    28.0
10  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.666667    28.0
11  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.730769    28.0
12  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.928571    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.849s]> Epoch [1/1] | loss: 0.0565, test loss: 0.2327, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.923s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.387s]> Epoch [1/1] | loss: 0.0516, test loss: 0.3079, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.820s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a82.14]-[f0.5918]-[p0.5833]-[r0.6067].pt"
              precision    recall  f1-score   support

           0       0.25      0.33      0.29         3
           1       0.92      0.88      0.90        25

    accuracy                           0.82        28
   macro avg       0.58      0.61      0.59        28
weighted avg       0.85      0.82      0.83        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.250000     3.0
1   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.333333     3.0
2   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.285714     3.0
3   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.916667    25.0
4   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
5   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.897959    25.0
6   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.845238    28.0
7   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.821429    28.0
8   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.832362    28.0
9   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.583333    28.0
10  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.606667    28.0
11  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.591837    28.0
12  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.821429    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.150s]> Epoch [1/1] | loss: 0.0532, test loss: 0.1722, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.586s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a78.57]-[f0.4400]-[p0.4400]-[r0.4400].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.88      0.88      0.88        25

    accuracy                           0.79        28
   macro avg       0.44      0.44      0.44        28
weighted avg       0.79      0.79      0.79        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
4   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
5   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.880000    25.0
6   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
7   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
8   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0
9   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
10  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
11  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.440000    28.0
12  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.785714    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.543s]> Epoch [1/1] | loss: 0.0507, test loss: 0.1242, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.718s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:45  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.601s]> Epoch [1/1] | loss: 0.0542, test loss: 0.3058, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.601s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.248s]> Epoch [1/1] | loss: 0.0548, test loss: 0.1645, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.738s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^ --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date                 transfer_strategy  ...      perf support
0   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
1   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
2   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.000000     3.0
3   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    25.0
4   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  1.000000    25.0
5   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.943396    25.0
6   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.797194    28.0
7   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0
8   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.842318    28.0
9   2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.446429    28.0
10  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.500000    28.0
11  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.471698    28.0
12  2025-04-14 07:41:46  A-1-1cn + E-2-2cn^ --> E-2-2cn^^  ...  0.892857    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.130s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.263s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.166s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.086s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.236s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.089s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.119s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.167s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.065s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.035s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.056s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.164s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.106s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.062s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> O-2-2cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 26.916s]> Epoch [1/1] | loss: 0.0534, test loss: 0.4491, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.081s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:23  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.599s]> Epoch [1/1] | loss: 0.0590, test loss: 0.5651, lr: 0.001000
Log [0.0h, 0.0m, 0.014s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.265s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.409s]> Epoch [1/1] | loss: 0.0556, test loss: 0.6358, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.051s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.363s]> Epoch [1/1] | loss: 0.0559, test loss: 0.4162, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.853s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.107s]> Epoch [1/1] | loss: 0.0540, test loss: 0.6384, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.170s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

Log [0.0h, 0.0m, 30.388s]> Epoch [1/1] | loss: 0.0555, test loss: 0.5887, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.799s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.618s]> Epoch [1/1] | loss: 0.0539, test loss: 0.7923, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.916s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

Log [0.0h, 0.0m, 30.653s]> Epoch [1/1] | loss: 0.0541, test loss: 0.4590, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.754s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.772s]> Epoch [1/1] | loss: 0.0541, test loss: 0.6389, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.815s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.011s]> Epoch [1/1] | loss: 0.0541, test loss: 0.6511, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.555s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.363s]> Epoch [1/1] | loss: 0.0513, test loss: 0.5906, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.841s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:27  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.516s]> Epoch [1/1] | loss: 0.0544, test loss: 0.7382, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.577s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a70.00]-[f0.5312]-[p0.8421]-[r0.5714].pt"
              precision    recall  f1-score   support

           0       1.00      0.14      0.25         7
           1       0.68      1.00      0.81        13

    accuracy                           0.70        20
   macro avg       0.84      0.57      0.53        20
weighted avg       0.79      0.70      0.62        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000     7.0
1   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.142857     7.0
2   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.250000     7.0
3   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.684211    13.0
4   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.812500    13.0
6   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.794737    20.0
7   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.700000    20.0
8   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.615625    20.0
9   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.842105    20.0
10  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.571429    20.0
11  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.531250    20.0
12  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.700000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.132s]> Epoch [1/1] | loss: 0.0596, test loss: 0.5747, lr: 0.001000
Log [0.0h, 0.0m, 0.015s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.971s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.535s]> Epoch [1/1] | loss: 0.0566, test loss: 0.7826, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.649s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a60.00]-[f0.3750]-[p0.3158]-[r0.4615].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.63      0.92      0.75        13

    accuracy                           0.60        20
   macro avg       0.32      0.46      0.38        20
weighted avg       0.41      0.60      0.49        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.631579    13.0
4   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.923077    13.0
5   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.750000    13.0
6   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.410526    20.0
7   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.600000    20.0
8   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.487500    20.0
9   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.315789    20.0
10  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.461538    20.0
11  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.375000    20.0
12  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.600000    20.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.037s]> Epoch [1/1] | loss: 0.0541, test loss: 0.3746, lr: 0.001000
Log [0.0h, 0.0m, 0.013s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.890s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> o-2-2cn/dlstm-[a65.00]-[f0.3939]-[p0.3250]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         7
           1       0.65      1.00      0.79        13

    accuracy                           0.65        20
   macro avg       0.33      0.50      0.39        20
weighted avg       0.42      0.65      0.51        20

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
1   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
2   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.000000     7.0
3   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    13.0
4   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  1.000000    13.0
5   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.787879    13.0
6   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.422500    20.0
7   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0
8   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.512121    20.0
9   2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.325000    20.0
10  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.500000    20.0
11  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.393939    20.0
12  2025-04-14 07:42:28  A-1-1cn + E-2-2cn --> O-2-2cn  ...  0.650000    20.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.116s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.092s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.158s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.027s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.001s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.192s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.223s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.032s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.156s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.002s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.152s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.131s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.151s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.008s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 27.696s]> Epoch [1/1] | loss: 0.0560, test loss: 1.1944, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.479s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:06  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.723s]> Epoch [1/1] | loss: 0.0557, test loss: 0.4374, lr: 0.001000
Log [0.0h, 0.0m, 0.010s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.525s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:07  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.844s]> Epoch [1/1] | loss: 0.0537, test loss: 1.2122, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.561s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.115s]> Epoch [1/1] | loss: 0.0557, test loss: 0.8379, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.908s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.799s]> Epoch [1/1] | loss: 0.0561, test loss: 0.8678, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.897s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.544s]> Epoch [1/1] | loss: 0.0536, test loss: 0.6901, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.502s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:08  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.932s]> Epoch [1/1] | loss: 0.0573, test loss: 1.6110, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.121s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.273s]> Epoch [1/1] | loss: 0.0553, test loss: 0.2867, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.787s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a85.71]-[f0.8152]-[p0.8000]-[r0.8375].pt"
              precision    recall  f1-score   support

           0       0.93      0.88      0.90        16
           1       0.67      0.80      0.73         5

    accuracy                           0.86        21
   macro avg       0.80      0.84      0.82        21
weighted avg       0.87      0.86      0.86        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.933333    16.0
1   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.875000    16.0
2   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.903226    16.0
3   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.666667     5.0
4   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.800000     5.0
5   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.727273     5.0
6   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.869841    21.0
7   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.857143    21.0
8   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.861332    21.0
9   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.800000    21.0
10  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.837500    21.0
11  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.815249    21.0
12  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.857143    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.035s]> Epoch [1/1] | loss: 0.0566, test loss: 0.7240, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.357s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:09  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.634s]> Epoch [1/1] | loss: 0.0584, test loss: 1.2588, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.155s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.301s]> Epoch [1/1] | loss: 0.0504, test loss: 1.4892, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.397s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a28.57]-[f0.2588]-[p0.6250]-[r0.5312].pt"
              precision    recall  f1-score   support

           0       1.00      0.06      0.12        16
           1       0.25      1.00      0.40         5

    accuracy                           0.29        21
   macro avg       0.62      0.53      0.26        21
weighted avg       0.82      0.29      0.18        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000    16.0
1   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.062500    16.0
2   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.117647    16.0
3   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.250000     5.0
4   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.400000     5.0
6   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.821429    21.0
7   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.285714    21.0
8   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.184874    21.0
9   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.625000    21.0
10  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.531250    21.0
11  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.258824    21.0
12  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.285714    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.218s]> Epoch [1/1] | loss: 0.0543, test loss: 0.2383, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.832s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.881s]> Epoch [1/1] | loss: 0.0569, test loss: 0.8324, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.947s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.029s]> Epoch [1/1] | loss: 0.0537, test loss: 1.8564, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.135s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:10  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 32.249s]> Epoch [1/1] | loss: 0.0523, test loss: 0.7023, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.813s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date              transfer_strategy  ...      perf support
0   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
1   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
2   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.000000    16.0
3   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095     5.0
4   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  1.000000     5.0
5   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.384615     5.0
6   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.056689    21.0
7   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0
8   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.091575    21.0
9   2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.119048    21.0
10  2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.500000    21.0
11  2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.192308    21.0
12  2025-04-14 07:43:11  A-1-1cn + E-2-2cn --> G-3-4cn  ...  0.238095    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.122s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.050s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.036s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.123s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.165s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.129s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.075s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.076s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.124s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.144s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.086s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.135s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.085s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.052s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.165s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn + O-2-2cn --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.051s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 28.584s]> Epoch [1/1] | loss: 0.0595, test loss: 0.2375, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.142s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:50  ...    12.0
1   2025-04-14 07:43:50  ...    12.0
2   2025-04-14 07:43:50  ...    12.0
3   2025-04-14 07:43:50  ...    41.0
4   2025-04-14 07:43:50  ...    41.0
5   2025-04-14 07:43:50  ...    41.0
6   2025-04-14 07:43:50  ...    53.0
7   2025-04-14 07:43:50  ...    53.0
8   2025-04-14 07:43:50  ...    53.0
9   2025-04-14 07:43:50  ...    53.0
10  2025-04-14 07:43:50  ...    53.0
11  2025-04-14 07:43:50  ...    53.0
12  2025-04-14 07:43:50  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.012s]> Epoch [1/1] | loss: 0.0575, test loss: 0.1640, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.818s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:50  ...    12.0
1   2025-04-14 07:43:50  ...    12.0
2   2025-04-14 07:43:50  ...    12.0
3   2025-04-14 07:43:50  ...    41.0
4   2025-04-14 07:43:50  ...    41.0
5   2025-04-14 07:43:50  ...    41.0
6   2025-04-14 07:43:50  ...    53.0
7   2025-04-14 07:43:50  ...    53.0
8   2025-04-14 07:43:50  ...    53.0
9   2025-04-14 07:43:50  ...    53.0
10  2025-04-14 07:43:50  ...    53.0
11  2025-04-14 07:43:50  ...    53.0
12  2025-04-14 07:43:50  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.434s]> Epoch [1/1] | loss: 0.0598, test loss: 0.4538, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.603s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

Log [0.0h, 0.0m, 29.909s]> Epoch [1/1] | loss: 0.0551, test loss: 0.5363, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.233s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.960s]> Epoch [1/1] | loss: 0.0581, test loss: 0.0917, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.673s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.986s]> Epoch [1/1] | loss: 0.0612, test loss: 0.0856, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.762s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a86.79]-[f0.7548]-[p0.9271]-[r0.7083].pt"
              precision    recall  f1-score   support

           0       1.00      0.42      0.59        12
           1       0.85      1.00      0.92        41

    accuracy                           0.87        53
   macro avg       0.93      0.71      0.75        53
weighted avg       0.89      0.87      0.85        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.792s]> Epoch [1/1] | loss: 0.0596, test loss: 0.0978, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.435s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a81.13]-[f0.7573]-[p0.7407]-[r0.7896].pt"
              precision    recall  f1-score   support

           0       0.56      0.75      0.64        12
           1       0.92      0.83      0.87        41

    accuracy                           0.81        53
   macro avg       0.74      0.79      0.76        53
weighted avg       0.84      0.81      0.82        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.605s]> Epoch [1/1] | loss: 0.0550, test loss: 0.1638, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.856s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a90.57]-[f0.8397]-[p0.9457]-[r0.7917].pt"
              precision    recall  f1-score   support

           0       1.00      0.58      0.74        12
           1       0.89      1.00      0.94        41

    accuracy                           0.91        53
   macro avg       0.95      0.79      0.84        53
weighted avg       0.92      0.91      0.90        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.993s]> Epoch [1/1] | loss: 0.0597, test loss: 0.3268, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.207s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.399s]> Epoch [1/1] | loss: 0.0592, test loss: 0.1184, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.453s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.179s]> Epoch [1/1] | loss: 0.0614, test loss: 0.0510, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.324s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a88.68]-[f0.7992]-[p0.9362]-[r0.7500].pt"
              precision    recall  f1-score   support

           0       1.00      0.50      0.67        12
           1       0.87      1.00      0.93        41

    accuracy                           0.89        53
   macro avg       0.94      0.75      0.80        53
weighted avg       0.90      0.89      0.87        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.801s]> Epoch [1/1] | loss: 0.0579, test loss: 0.3886, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.946s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a22.64]-[f0.1846]-[p0.1132]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.23      1.00      0.37        12
           1       0.00      0.00      0.00        41

    accuracy                           0.23        53
   macro avg       0.11      0.50      0.18        53
weighted avg       0.05      0.23      0.08        53

                   date  ... support
0   2025-04-14 07:43:51  ...    12.0
1   2025-04-14 07:43:51  ...    12.0
2   2025-04-14 07:43:51  ...    12.0
3   2025-04-14 07:43:51  ...    41.0
4   2025-04-14 07:43:51  ...    41.0
5   2025-04-14 07:43:51  ...    41.0
6   2025-04-14 07:43:51  ...    53.0
7   2025-04-14 07:43:51  ...    53.0
8   2025-04-14 07:43:51  ...    53.0
9   2025-04-14 07:43:51  ...    53.0
10  2025-04-14 07:43:51  ...    53.0
11  2025-04-14 07:43:51  ...    53.0
12  2025-04-14 07:43:51  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.362s]> Epoch [1/1] | loss: 0.0603, test loss: 0.2072, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.307s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:52  ...    12.0
1   2025-04-14 07:43:52  ...    12.0
2   2025-04-14 07:43:52  ...    12.0
3   2025-04-14 07:43:52  ...    41.0
4   2025-04-14 07:43:52  ...    41.0
5   2025-04-14 07:43:52  ...    41.0
6   2025-04-14 07:43:52  ...    53.0
7   2025-04-14 07:43:52  ...    53.0
8   2025-04-14 07:43:52  ...    53.0
9   2025-04-14 07:43:52  ...    53.0
10  2025-04-14 07:43:52  ...    53.0
11  2025-04-14 07:43:52  ...    53.0
12  2025-04-14 07:43:52  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.166s]> Epoch [1/1] | loss: 0.0586, test loss: 0.4088, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.047s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a77.36]-[f0.4362]-[p0.3868]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        12
           1       0.77      1.00      0.87        41

    accuracy                           0.77        53
   macro avg       0.39      0.50      0.44        53
weighted avg       0.60      0.77      0.67        53

                   date  ... support
0   2025-04-14 07:43:52  ...    12.0
1   2025-04-14 07:43:52  ...    12.0
2   2025-04-14 07:43:52  ...    12.0
3   2025-04-14 07:43:52  ...    41.0
4   2025-04-14 07:43:52  ...    41.0
5   2025-04-14 07:43:52  ...    41.0
6   2025-04-14 07:43:52  ...    53.0
7   2025-04-14 07:43:52  ...    53.0
8   2025-04-14 07:43:52  ...    53.0
9   2025-04-14 07:43:52  ...    53.0
10  2025-04-14 07:43:52  ...    53.0
11  2025-04-14 07:43:52  ...    53.0
12  2025-04-14 07:43:52  ...    53.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.947s]> Epoch [1/1] | loss: 0.0573, test loss: 0.3022, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.792s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn_o-2-2cn --> a-1-1cn^^/dlstm-[a20.75]-[f0.1719]-[p0.1058]-[r0.4583].pt"
              precision    recall  f1-score   support

           0       0.21      0.92      0.34        12
           1       0.00      0.00      0.00        41

    accuracy                           0.21        53
   macro avg       0.11      0.46      0.17        53
weighted avg       0.05      0.21      0.08        53

                   date  ... support
0   2025-04-14 07:43:53  ...    12.0
1   2025-04-14 07:43:53  ...    12.0
2   2025-04-14 07:43:53  ...    12.0
3   2025-04-14 07:43:53  ...    41.0
4   2025-04-14 07:43:53  ...    41.0
5   2025-04-14 07:43:53  ...    41.0
6   2025-04-14 07:43:53  ...    53.0
7   2025-04-14 07:43:53  ...    53.0
8   2025-04-14 07:43:53  ...    53.0
9   2025-04-14 07:43:53  ...    53.0
10  2025-04-14 07:43:53  ...    53.0
11  2025-04-14 07:43:53  ...    53.0
12  2025-04-14 07:43:53  ...    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.132s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.058s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.041s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.090s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.163s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.081s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.033s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.028s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.027s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.053s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.048s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.187s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.098s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.128s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.146s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.091s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.048s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.062s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.143s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.073s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.040s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn^ + O-2-2cn --> E-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.186s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.031s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 27.990s]> Epoch [1/1] | loss: 0.0561, test loss: 0.1979, lr: 0.001000
Log [0.0h, 0.0m, 0.008s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.764s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

Log [0.0h, 0.0m, 28.085s]> Epoch [1/1] | loss: 0.0560, test loss: 0.0829, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.322s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:31  ...     3.0
1   2025-04-14 07:44:31  ...     3.0
2   2025-04-14 07:44:31  ...     3.0
3   2025-04-14 07:44:31  ...    25.0
4   2025-04-14 07:44:31  ...    25.0
5   2025-04-14 07:44:31  ...    25.0
6   2025-04-14 07:44:31  ...    28.0
7   2025-04-14 07:44:31  ...    28.0
8   2025-04-14 07:44:31  ...    28.0
9   2025-04-14 07:44:31  ...    28.0
10  2025-04-14 07:44:31  ...    28.0
11  2025-04-14 07:44:31  ...    28.0
12  2025-04-14 07:44:31  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.002s]> Epoch [1/1] | loss: 0.0645, test loss: 0.0713, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.214s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:32  ...     3.0
1   2025-04-14 07:44:32  ...     3.0
2   2025-04-14 07:44:32  ...     3.0
3   2025-04-14 07:44:32  ...    25.0
4   2025-04-14 07:44:32  ...    25.0
5   2025-04-14 07:44:32  ...    25.0
6   2025-04-14 07:44:32  ...    28.0
7   2025-04-14 07:44:32  ...    28.0
8   2025-04-14 07:44:32  ...    28.0
9   2025-04-14 07:44:32  ...    28.0
10  2025-04-14 07:44:32  ...    28.0
11  2025-04-14 07:44:32  ...    28.0
12  2025-04-14 07:44:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.190s]> Epoch [1/1] | loss: 0.0562, test loss: 0.1171, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.244s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:32  ...     3.0
1   2025-04-14 07:44:32  ...     3.0
2   2025-04-14 07:44:32  ...     3.0
3   2025-04-14 07:44:32  ...    25.0
4   2025-04-14 07:44:32  ...    25.0
5   2025-04-14 07:44:32  ...    25.0
6   2025-04-14 07:44:32  ...    28.0
7   2025-04-14 07:44:32  ...    28.0
8   2025-04-14 07:44:32  ...    28.0
9   2025-04-14 07:44:32  ...    28.0
10  2025-04-14 07:44:32  ...    28.0
11  2025-04-14 07:44:32  ...    28.0
12  2025-04-14 07:44:32  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.329s]> Epoch [1/1] | loss: 0.0622, test loss: 0.1703, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.895s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a64.29]-[f0.5238]-[p0.5615]-[r0.6533].pt"
              precision    recall  f1-score   support

           0       0.18      0.67      0.29         3
           1       0.94      0.64      0.76        25

    accuracy                           0.64        28
   macro avg       0.56      0.65      0.52        28
weighted avg       0.86      0.64      0.71        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.104s]> Epoch [1/1] | loss: 0.0570, test loss: 0.1513, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.032s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a82.14]-[f0.4510]-[p0.4423]-[r0.4600].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.88      0.92      0.90        25

    accuracy                           0.82        28
   macro avg       0.44      0.46      0.45        28
weighted avg       0.79      0.82      0.81        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.981s]> Epoch [1/1] | loss: 0.0543, test loss: 0.2301, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.372s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a32.14]-[f0.2991]-[p0.4875]-[r0.4733].pt"
              precision    recall  f1-score   support

           0       0.10      0.67      0.17         3
           1       0.88      0.28      0.42        25

    accuracy                           0.32        28
   macro avg       0.49      0.47      0.30        28
weighted avg       0.79      0.32      0.40        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.750s]> Epoch [1/1] | loss: 0.0595, test loss: 0.0482, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.852s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a35.71]-[f0.3262]-[p0.4971]-[r0.4933].pt"
              precision    recall  f1-score   support

           0       0.11      0.67      0.18         3
           1       0.89      0.32      0.47        25

    accuracy                           0.36        28
   macro avg       0.50      0.49      0.33        28
weighted avg       0.80      0.36      0.44        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.090s]> Epoch [1/1] | loss: 0.0651, test loss: 0.1659, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.610s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a85.71]-[f0.4615]-[p0.4444]-[r0.4800].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      0.96      0.92        25

    accuracy                           0.86        28
   macro avg       0.44      0.48      0.46        28
weighted avg       0.79      0.86      0.82        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.809s]> Epoch [1/1] | loss: 0.0586, test loss: 0.1537, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.547s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a21.43]-[f0.2103]-[p0.4435]-[r0.4133].pt"
              precision    recall  f1-score   support

           0       0.09      0.67      0.15         3
           1       0.80      0.16      0.27        25

    accuracy                           0.21        28
   macro avg       0.44      0.41      0.21        28
weighted avg       0.72      0.21      0.25        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.354s]> Epoch [1/1] | loss: 0.0590, test loss: 0.1018, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.612s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.589s]> Epoch [1/1] | loss: 0.0607, test loss: 0.0859, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.622s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a50.00]-[f0.4269]-[p0.5282]-[r0.5733].pt"
              precision    recall  f1-score   support

           0       0.13      0.67      0.22         3
           1       0.92      0.48      0.63        25

    accuracy                           0.50        28
   macro avg       0.53      0.57      0.43        28
weighted avg       0.84      0.50      0.59        28

                   date  ... support
0   2025-04-14 07:44:33  ...     3.0
1   2025-04-14 07:44:33  ...     3.0
2   2025-04-14 07:44:33  ...     3.0
3   2025-04-14 07:44:33  ...    25.0
4   2025-04-14 07:44:33  ...    25.0
5   2025-04-14 07:44:33  ...    25.0
6   2025-04-14 07:44:33  ...    28.0
7   2025-04-14 07:44:33  ...    28.0
8   2025-04-14 07:44:33  ...    28.0
9   2025-04-14 07:44:33  ...    28.0
10  2025-04-14 07:44:33  ...    28.0
11  2025-04-14 07:44:33  ...    28.0
12  2025-04-14 07:44:33  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.595s]> Epoch [1/1] | loss: 0.0560, test loss: 0.2214, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.966s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a53.57]-[f0.4510]-[p0.5357]-[r0.5933].pt"
              precision    recall  f1-score   support

           0       0.14      0.67      0.24         3
           1       0.93      0.52      0.67        25

    accuracy                           0.54        28
   macro avg       0.54      0.59      0.45        28
weighted avg       0.84      0.54      0.62        28

                   date  ... support
0   2025-04-14 07:44:34  ...     3.0
1   2025-04-14 07:44:34  ...     3.0
2   2025-04-14 07:44:34  ...     3.0
3   2025-04-14 07:44:34  ...    25.0
4   2025-04-14 07:44:34  ...    25.0
5   2025-04-14 07:44:34  ...    25.0
6   2025-04-14 07:44:34  ...    28.0
7   2025-04-14 07:44:34  ...    28.0
8   2025-04-14 07:44:34  ...    28.0
9   2025-04-14 07:44:34  ...    28.0
10  2025-04-14 07:44:34  ...    28.0
11  2025-04-14 07:44:34  ...    28.0
12  2025-04-14 07:44:34  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.758s]> Epoch [1/1] | loss: 0.0614, test loss: 0.0901, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.655s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:34  ...     3.0
1   2025-04-14 07:44:34  ...     3.0
2   2025-04-14 07:44:34  ...     3.0
3   2025-04-14 07:44:34  ...    25.0
4   2025-04-14 07:44:34  ...    25.0
5   2025-04-14 07:44:34  ...    25.0
6   2025-04-14 07:44:34  ...    28.0
7   2025-04-14 07:44:34  ...    28.0
8   2025-04-14 07:44:34  ...    28.0
9   2025-04-14 07:44:34  ...    28.0
10  2025-04-14 07:44:34  ...    28.0
11  2025-04-14 07:44:34  ...    28.0
12  2025-04-14 07:44:34  ...    28.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.447s]> Epoch [1/1] | loss: 0.0559, test loss: 0.1315, lr: 0.001000
Log [0.0h, 0.0m, 0.023s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.813s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn^_o-2-2cn --> e-2-2cn^^/dlstm-[a89.29]-[f0.4717]-[p0.4464]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         3
           1       0.89      1.00      0.94        25

    accuracy                           0.89        28
   macro avg       0.45      0.50      0.47        28
weighted avg       0.80      0.89      0.84        28

                   date  ... support
0   2025-04-14 07:44:34  ...     3.0
1   2025-04-14 07:44:34  ...     3.0
2   2025-04-14 07:44:34  ...     3.0
3   2025-04-14 07:44:34  ...    25.0
4   2025-04-14 07:44:34  ...    25.0
5   2025-04-14 07:44:34  ...    25.0
6   2025-04-14 07:44:34  ...    28.0
7   2025-04-14 07:44:34  ...    28.0
8   2025-04-14 07:44:34  ...    28.0
9   2025-04-14 07:44:34  ...    28.0
10  2025-04-14 07:44:34  ...    28.0
11  2025-04-14 07:44:34  ...    28.0
12  2025-04-14 07:44:34  ...    28.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.118s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.047s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.191s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.149s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.024s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.072s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.104s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.200s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.104s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.176s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.056s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.134s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.018s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.016s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.100s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.016s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.005s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.108s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.165s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.059s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn^ --> O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.096s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 28.508s]> Epoch [1/1] | loss: 0.0553, test loss: 0.6243, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.411s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:11  ...     2.0
1   2025-04-14 07:45:11  ...     2.0
2   2025-04-14 07:45:11  ...     2.0
3   2025-04-14 07:45:11  ...     3.0
4   2025-04-14 07:45:11  ...     3.0
5   2025-04-14 07:45:11  ...     3.0
6   2025-04-14 07:45:11  ...     5.0
7   2025-04-14 07:45:11  ...     5.0
8   2025-04-14 07:45:11  ...     5.0
9   2025-04-14 07:45:11  ...     5.0
10  2025-04-14 07:45:11  ...     5.0
11  2025-04-14 07:45:11  ...     5.0
12  2025-04-14 07:45:11  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.816s]> Epoch [1/1] | loss: 0.0546, test loss: 0.2262, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.265s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:13  ...     2.0
1   2025-04-14 07:45:13  ...     2.0
2   2025-04-14 07:45:13  ...     2.0
3   2025-04-14 07:45:13  ...     3.0
4   2025-04-14 07:45:13  ...     3.0
5   2025-04-14 07:45:13  ...     3.0
6   2025-04-14 07:45:13  ...     5.0
7   2025-04-14 07:45:13  ...     5.0
8   2025-04-14 07:45:13  ...     5.0
9   2025-04-14 07:45:13  ...     5.0
10  2025-04-14 07:45:13  ...     5.0
11  2025-04-14 07:45:13  ...     5.0
12  2025-04-14 07:45:13  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.709s]> Epoch [1/1] | loss: 0.0551, test loss: 0.6474, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.337s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date  ... support
0   2025-04-14 07:45:13  ...     2.0
1   2025-04-14 07:45:13  ...     2.0
2   2025-04-14 07:45:13  ...     2.0
3   2025-04-14 07:45:13  ...     3.0
4   2025-04-14 07:45:13  ...     3.0
5   2025-04-14 07:45:13  ...     3.0
6   2025-04-14 07:45:13  ...     5.0
7   2025-04-14 07:45:13  ...     5.0
8   2025-04-14 07:45:13  ...     5.0
9   2025-04-14 07:45:13  ...     5.0
10  2025-04-14 07:45:13  ...     5.0
11  2025-04-14 07:45:13  ...     5.0
12  2025-04-14 07:45:13  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.273s]> Epoch [1/1] | loss: 0.0558, test loss: 0.6545, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.244s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

Log [0.0h, 0.0m, 29.602s]> Epoch [1/1] | loss: 0.0557, test loss: 0.8077, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.193s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date  ... support
0   2025-04-14 07:45:13  ...     2.0
1   2025-04-14 07:45:13  ...     2.0
2   2025-04-14 07:45:13  ...     2.0
3   2025-04-14 07:45:13  ...     3.0
4   2025-04-14 07:45:13  ...     3.0
5   2025-04-14 07:45:13  ...     3.0
6   2025-04-14 07:45:13  ...     5.0
7   2025-04-14 07:45:13  ...     5.0
8   2025-04-14 07:45:13  ...     5.0
9   2025-04-14 07:45:13  ...     5.0
10  2025-04-14 07:45:13  ...     5.0
11  2025-04-14 07:45:13  ...     5.0
12  2025-04-14 07:45:13  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.866s]> Epoch [1/1] | loss: 0.0564, test loss: 0.6776, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.337s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:13  ...     2.0
1   2025-04-14 07:45:13  ...     2.0
2   2025-04-14 07:45:13  ...     2.0
3   2025-04-14 07:45:13  ...     3.0
4   2025-04-14 07:45:13  ...     3.0
5   2025-04-14 07:45:13  ...     3.0
6   2025-04-14 07:45:13  ...     5.0
7   2025-04-14 07:45:13  ...     5.0
8   2025-04-14 07:45:13  ...     5.0
9   2025-04-14 07:45:13  ...     5.0
10  2025-04-14 07:45:13  ...     5.0
11  2025-04-14 07:45:13  ...     5.0
12  2025-04-14 07:45:13  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.488s]> Epoch [1/1] | loss: 0.0628, test loss: 0.4797, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.255s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:13  ...     2.0
1   2025-04-14 07:45:13  ...     2.0
2   2025-04-14 07:45:13  ...     2.0
3   2025-04-14 07:45:13  ...     3.0
4   2025-04-14 07:45:13  ...     3.0
5   2025-04-14 07:45:13  ...     3.0
6   2025-04-14 07:45:13  ...     5.0
7   2025-04-14 07:45:13  ...     5.0
8   2025-04-14 07:45:13  ...     5.0
9   2025-04-14 07:45:13  ...     5.0
10  2025-04-14 07:45:13  ...     5.0
11  2025-04-14 07:45:13  ...     5.0
12  2025-04-14 07:45:13  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 29.707s]> Epoch [1/1] | loss: 0.0541, test loss: 0.6022, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.168s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date  ... support
0   2025-04-14 07:45:14  ...     2.0
1   2025-04-14 07:45:14  ...     2.0
2   2025-04-14 07:45:14  ...     2.0
3   2025-04-14 07:45:14  ...     3.0
4   2025-04-14 07:45:14  ...     3.0
5   2025-04-14 07:45:14  ...     3.0
6   2025-04-14 07:45:14  ...     5.0
7   2025-04-14 07:45:14  ...     5.0
8   2025-04-14 07:45:14  ...     5.0
9   2025-04-14 07:45:14  ...     5.0
10  2025-04-14 07:45:14  ...     5.0
11  2025-04-14 07:45:14  ...     5.0
12  2025-04-14 07:45:14  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.786s]> Epoch [1/1] | loss: 0.0615, test loss: 0.4617, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.149s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:14  ...     2.0
1   2025-04-14 07:45:14  ...     2.0
2   2025-04-14 07:45:14  ...     2.0
3   2025-04-14 07:45:14  ...     3.0
4   2025-04-14 07:45:14  ...     3.0
5   2025-04-14 07:45:14  ...     3.0
6   2025-04-14 07:45:14  ...     5.0
7   2025-04-14 07:45:14  ...     5.0
8   2025-04-14 07:45:14  ...     5.0
9   2025-04-14 07:45:14  ...     5.0
10  2025-04-14 07:45:14  ...     5.0
11  2025-04-14 07:45:14  ...     5.0
12  2025-04-14 07:45:14  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.797s]> Epoch [1/1] | loss: 0.0560, test loss: 0.4696, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.141s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:15  ...     2.0
1   2025-04-14 07:45:15  ...     2.0
2   2025-04-14 07:45:15  ...     2.0
3   2025-04-14 07:45:15  ...     3.0
4   2025-04-14 07:45:15  ...     3.0
5   2025-04-14 07:45:15  ...     3.0
6   2025-04-14 07:45:15  ...     5.0
7   2025-04-14 07:45:15  ...     5.0
8   2025-04-14 07:45:15  ...     5.0
9   2025-04-14 07:45:15  ...     5.0
10  2025-04-14 07:45:15  ...     5.0
11  2025-04-14 07:45:15  ...     5.0
12  2025-04-14 07:45:15  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.635s]> Epoch [1/1] | loss: 0.0568, test loss: 0.1102, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.103s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date  ... support
0   2025-04-14 07:45:15  ...     2.0
1   2025-04-14 07:45:15  ...     2.0
2   2025-04-14 07:45:15  ...     2.0
3   2025-04-14 07:45:15  ...     3.0
4   2025-04-14 07:45:15  ...     3.0
5   2025-04-14 07:45:15  ...     3.0
6   2025-04-14 07:45:15  ...     5.0
7   2025-04-14 07:45:15  ...     5.0
8   2025-04-14 07:45:15  ...     5.0
9   2025-04-14 07:45:15  ...     5.0
10  2025-04-14 07:45:15  ...     5.0
11  2025-04-14 07:45:15  ...     5.0
12  2025-04-14 07:45:15  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.066s]> Epoch [1/1] | loss: 0.0535, test loss: 0.1969, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.126s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:15  ...     2.0
1   2025-04-14 07:45:15  ...     2.0
2   2025-04-14 07:45:15  ...     2.0
3   2025-04-14 07:45:15  ...     3.0
4   2025-04-14 07:45:15  ...     3.0
5   2025-04-14 07:45:15  ...     3.0
6   2025-04-14 07:45:15  ...     5.0
7   2025-04-14 07:45:15  ...     5.0
8   2025-04-14 07:45:15  ...     5.0
9   2025-04-14 07:45:15  ...     5.0
10  2025-04-14 07:45:15  ...     5.0
11  2025-04-14 07:45:15  ...     5.0
12  2025-04-14 07:45:15  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.440s]> Epoch [1/1] | loss: 0.0623, test loss: 0.1313, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.168s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:15  ...     2.0
1   2025-04-14 07:45:15  ...     2.0
2   2025-04-14 07:45:15  ...     2.0
3   2025-04-14 07:45:15  ...     3.0
4   2025-04-14 07:45:15  ...     3.0
5   2025-04-14 07:45:15  ...     3.0
6   2025-04-14 07:45:15  ...     5.0
7   2025-04-14 07:45:15  ...     5.0
8   2025-04-14 07:45:15  ...     5.0
9   2025-04-14 07:45:15  ...     5.0
10  2025-04-14 07:45:15  ...     5.0
11  2025-04-14 07:45:15  ...     5.0
12  2025-04-14 07:45:15  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.486s]> Epoch [1/1] | loss: 0.0593, test loss: 0.8005, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.112s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a40.00]-[f0.2857]-[p0.2500]-[r0.3333].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.50      0.67      0.57         3

    accuracy                           0.40         5
   macro avg       0.25      0.33      0.29         5
weighted avg       0.30      0.40      0.34         5

                   date  ... support
0   2025-04-14 07:45:15  ...     2.0
1   2025-04-14 07:45:15  ...     2.0
2   2025-04-14 07:45:15  ...     2.0
3   2025-04-14 07:45:15  ...     3.0
4   2025-04-14 07:45:15  ...     3.0
5   2025-04-14 07:45:15  ...     3.0
6   2025-04-14 07:45:15  ...     5.0
7   2025-04-14 07:45:15  ...     5.0
8   2025-04-14 07:45:15  ...     5.0
9   2025-04-14 07:45:15  ...     5.0
10  2025-04-14 07:45:15  ...     5.0
11  2025-04-14 07:45:15  ...     5.0
12  2025-04-14 07:45:15  ...     5.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.994s]> Epoch [1/1] | loss: 0.0552, test loss: 0.4340, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.078s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn^ --> o-2-2cn^^/dlstm-[a60.00]-[f0.3750]-[p0.3000]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00         2
           1       0.60      1.00      0.75         3

    accuracy                           0.60         5
   macro avg       0.30      0.50      0.38         5
weighted avg       0.36      0.60      0.45         5

                   date  ... support
0   2025-04-14 07:45:16  ...     2.0
1   2025-04-14 07:45:16  ...     2.0
2   2025-04-14 07:45:16  ...     2.0
3   2025-04-14 07:45:16  ...     3.0
4   2025-04-14 07:45:16  ...     3.0
5   2025-04-14 07:45:16  ...     3.0
6   2025-04-14 07:45:16  ...     5.0
7   2025-04-14 07:45:16  ...     5.0
8   2025-04-14 07:45:16  ...     5.0
9   2025-04-14 07:45:16  ...     5.0
10  2025-04-14 07:45:16  ...     5.0
11  2025-04-14 07:45:16  ...     5.0
12  2025-04-14 07:45:16  ...     5.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.042s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.113s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.102s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.025s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.112s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.077s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.109s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.115s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.101s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.122s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.107s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.029s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.135s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.024s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.097s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.072s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.211s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.064s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.066s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.189s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.094s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.069s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.014s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.025s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.110s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.010s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.026s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.121s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.074s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.114s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.067s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.004s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Github>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn + E-2-2cn + O-2-2cn --> G-3-4cn`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 100.00% of the data reserved for training
Options selected for test set:
	github dataset, version tech: 3, social: 4 with feature-subset, normalize-actdev using 100.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.071s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.125s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.003s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 263
	y: 263
	graduated:          205
	retired:            58
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.065s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.009s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.011s]> Generating tensors

<Tensor Info For Github>
<train>
	x: 139
	y: 139
	graduated:          125
	retired:            14
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 20
	y: 20
	graduated:          13
	retired:            7
	incubating/skipped: 0

<Tensor For Github For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Github>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 21
	y: 21
	graduated:          5
	retired:            16
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 29.902s]> Epoch [1/1] | loss: 0.0594, test loss: 0.3264, lr: 0.001000
Log [0.0h, 0.0m, 0.012s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.049s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:45:57  ...    16.0
1   2025-04-14 07:45:57  ...    16.0
2   2025-04-14 07:45:57  ...    16.0
3   2025-04-14 07:45:57  ...     5.0
4   2025-04-14 07:45:57  ...     5.0
5   2025-04-14 07:45:57  ...     5.0
6   2025-04-14 07:45:57  ...    21.0
7   2025-04-14 07:45:57  ...    21.0
8   2025-04-14 07:45:57  ...    21.0
9   2025-04-14 07:45:57  ...    21.0
10  2025-04-14 07:45:57  ...    21.0
11  2025-04-14 07:45:57  ...    21.0
12  2025-04-14 07:45:57  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 30.653s]> Epoch [1/1] | loss: 0.0549, test loss: 0.2740, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.258s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a76.19]-[f0.7407]-[p0.7500]-[r0.8438].pt"
              precision    recall  f1-score   support

           0       1.00      0.69      0.81        16
           1       0.50      1.00      0.67         5

    accuracy                           0.76        21
   macro avg       0.75      0.84      0.74        21
weighted avg       0.88      0.76      0.78        21

                   date  ... support
0   2025-04-14 07:45:57  ...    16.0
1   2025-04-14 07:45:57  ...    16.0
2   2025-04-14 07:45:57  ...    16.0
3   2025-04-14 07:45:57  ...     5.0
4   2025-04-14 07:45:57  ...     5.0
5   2025-04-14 07:45:57  ...     5.0
6   2025-04-14 07:45:57  ...    21.0
7   2025-04-14 07:45:57  ...    21.0
8   2025-04-14 07:45:57  ...    21.0
9   2025-04-14 07:45:57  ...    21.0
10  2025-04-14 07:45:57  ...    21.0
11  2025-04-14 07:45:57  ...    21.0
12  2025-04-14 07:45:57  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.275s]> Epoch [1/1] | loss: 0.0570, test loss: 0.4301, lr: 0.001000
Log [0.0h, 0.0m, 0.018s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.430s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a61.90]-[f0.6111]-[p0.6923]-[r0.7500].pt"
              precision    recall  f1-score   support

           0       1.00      0.50      0.67        16
           1       0.38      1.00      0.56         5

    accuracy                           0.62        21
   macro avg       0.69      0.75      0.61        21
weighted avg       0.85      0.62      0.64        21

                   date  ... support
0   2025-04-14 07:45:58  ...    16.0
1   2025-04-14 07:45:58  ...    16.0
2   2025-04-14 07:45:58  ...    16.0
3   2025-04-14 07:45:58  ...     5.0
4   2025-04-14 07:45:58  ...     5.0
5   2025-04-14 07:45:58  ...     5.0
6   2025-04-14 07:45:58  ...    21.0
7   2025-04-14 07:45:58  ...    21.0
8   2025-04-14 07:45:58  ...    21.0
9   2025-04-14 07:45:58  ...    21.0
10  2025-04-14 07:45:58  ...    21.0
11  2025-04-14 07:45:58  ...    21.0
12  2025-04-14 07:45:58  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.591s]> Epoch [1/1] | loss: 0.0606, test loss: 0.2385, lr: 0.001000
Log [0.0h, 0.0m, 0.005s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.650s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a28.57]-[f0.2588]-[p0.6250]-[r0.5312].pt"
              precision    recall  f1-score   support

           0       1.00      0.06      0.12        16
           1       0.25      1.00      0.40         5

    accuracy                           0.29        21
   macro avg       0.62      0.53      0.26        21
weighted avg       0.82      0.29      0.18        21

                   date  ... support
0   2025-04-14 07:45:59  ...    16.0
1   2025-04-14 07:45:59  ...    16.0
2   2025-04-14 07:45:59  ...    16.0
3   2025-04-14 07:45:59  ...     5.0
4   2025-04-14 07:45:59  ...     5.0
5   2025-04-14 07:45:59  ...     5.0
6   2025-04-14 07:45:59  ...    21.0
7   2025-04-14 07:45:59  ...    21.0
8   2025-04-14 07:45:59  ...    21.0
9   2025-04-14 07:45:59  ...    21.0
10  2025-04-14 07:45:59  ...    21.0
11  2025-04-14 07:45:59  ...    21.0
12  2025-04-14 07:45:59  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 31.988s]> Epoch [1/1] | loss: 0.0554, test loss: 0.9868, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.259s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

Log [0.0h, 0.0m, 32.393s]> Epoch [1/1] | loss: 0.0642, test loss: 0.0393, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.358s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a90.48]-[f0.8456]-[p0.9444]-[r0.8000].pt"
              precision    recall  f1-score   support

           0       0.89      1.00      0.94        16
           1       1.00      0.60      0.75         5

    accuracy                           0.90        21
   macro avg       0.94      0.80      0.85        21
weighted avg       0.92      0.90      0.90        21

Log [0.0h, 0.0m, 31.843s]> Epoch [1/1] | loss: 0.0568, test loss: 0.4296, lr: 0.001000
Log [0.0h, 0.0m, 0.019s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.534s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:45:59  ...    16.0
1   2025-04-14 07:45:59  ...    16.0
2   2025-04-14 07:45:59  ...    16.0
3   2025-04-14 07:45:59  ...     5.0
4   2025-04-14 07:45:59  ...     5.0
5   2025-04-14 07:45:59  ...     5.0
6   2025-04-14 07:45:59  ...    21.0
7   2025-04-14 07:45:59  ...    21.0
8   2025-04-14 07:45:59  ...    21.0
9   2025-04-14 07:45:59  ...    21.0
10  2025-04-14 07:45:59  ...    21.0
11  2025-04-14 07:45:59  ...    21.0
12  2025-04-14 07:45:59  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 32.355s]> Epoch [1/1] | loss: 0.0577, test loss: 0.3374, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.348s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a71.43]-[f0.6971]-[p0.7273]-[r0.8125].pt"
              precision    recall  f1-score   support

           0       1.00      0.62      0.77        16
           1       0.45      1.00      0.62         5

    accuracy                           0.71        21
   macro avg       0.73      0.81      0.70        21
weighted avg       0.87      0.71      0.73        21

                   date  ... support
0   2025-04-14 07:45:59  ...    16.0
1   2025-04-14 07:45:59  ...    16.0
2   2025-04-14 07:45:59  ...    16.0
3   2025-04-14 07:45:59  ...     5.0
4   2025-04-14 07:45:59  ...     5.0
5   2025-04-14 07:45:59  ...     5.0
6   2025-04-14 07:45:59  ...    21.0
7   2025-04-14 07:45:59  ...    21.0
8   2025-04-14 07:45:59  ...    21.0
9   2025-04-14 07:45:59  ...    21.0
10  2025-04-14 07:45:59  ...    21.0
11  2025-04-14 07:45:59  ...    21.0
12  2025-04-14 07:45:59  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 33.051s]> Epoch [1/1] | loss: 0.0569, test loss: 0.7336, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.345s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a33.33]-[f0.3194]-[p0.6316]-[r0.5625].pt"
              precision    recall  f1-score   support

           0       1.00      0.12      0.22        16
           1       0.26      1.00      0.42         5

    accuracy                           0.33        21
   macro avg       0.63      0.56      0.32        21
weighted avg       0.82      0.33      0.27        21

Log [0.0h, 0.0m, 32.616s]> Epoch [1/1] | loss: 0.0594, test loss: 0.8098, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.112s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:45:59  ...    16.0
1   2025-04-14 07:45:59  ...    16.0
2   2025-04-14 07:45:59  ...    16.0
3   2025-04-14 07:45:59  ...     5.0
4   2025-04-14 07:45:59  ...     5.0
5   2025-04-14 07:45:59  ...     5.0
6   2025-04-14 07:45:59  ...    21.0
7   2025-04-14 07:45:59  ...    21.0
8   2025-04-14 07:45:59  ...    21.0
9   2025-04-14 07:45:59  ...    21.0
10  2025-04-14 07:45:59  ...    21.0
11  2025-04-14 07:45:59  ...    21.0
12  2025-04-14 07:45:59  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 32.244s]> Epoch [1/1] | loss: 0.0592, test loss: 0.5888, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.410s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:45:59  ...    16.0
1   2025-04-14 07:45:59  ...    16.0
2   2025-04-14 07:45:59  ...    16.0
3   2025-04-14 07:45:59  ...     5.0
4   2025-04-14 07:45:59  ...     5.0
5   2025-04-14 07:45:59  ...     5.0
6   2025-04-14 07:45:59  ...    21.0
7   2025-04-14 07:45:59  ...    21.0
8   2025-04-14 07:45:59  ...    21.0
9   2025-04-14 07:45:59  ...    21.0
10  2025-04-14 07:45:59  ...    21.0
11  2025-04-14 07:45:59  ...    21.0
12  2025-04-14 07:45:59  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 32.931s]> Epoch [1/1] | loss: 0.0595, test loss: 0.3489, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.396s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:46:00  ...    16.0
1   2025-04-14 07:46:00  ...    16.0
2   2025-04-14 07:46:00  ...    16.0
3   2025-04-14 07:46:00  ...     5.0
4   2025-04-14 07:46:00  ...     5.0
5   2025-04-14 07:46:00  ...     5.0
6   2025-04-14 07:46:00  ...    21.0
7   2025-04-14 07:46:00  ...    21.0
8   2025-04-14 07:46:00  ...    21.0
9   2025-04-14 07:46:00  ...    21.0
10  2025-04-14 07:46:00  ...    21.0
11  2025-04-14 07:46:00  ...    21.0
12  2025-04-14 07:46:00  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 34.088s]> Epoch [1/1] | loss: 0.0524, test loss: 0.6808, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.888s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a71.43]-[f0.6786]-[p0.6806]-[r0.7438].pt"
              precision    recall  f1-score   support

           0       0.92      0.69      0.79        16
           1       0.44      0.80      0.57         5

    accuracy                           0.71        21
   macro avg       0.68      0.74      0.68        21
weighted avg       0.80      0.71      0.73        21

                   date  ... support
0   2025-04-14 07:46:00  ...    16.0
1   2025-04-14 07:46:00  ...    16.0
2   2025-04-14 07:46:00  ...    16.0
3   2025-04-14 07:46:00  ...     5.0
4   2025-04-14 07:46:00  ...     5.0
5   2025-04-14 07:46:00  ...     5.0
6   2025-04-14 07:46:00  ...    21.0
7   2025-04-14 07:46:00  ...    21.0
8   2025-04-14 07:46:00  ...    21.0
9   2025-04-14 07:46:00  ...    21.0
10  2025-04-14 07:46:00  ...    21.0
11  2025-04-14 07:46:00  ...    21.0
12  2025-04-14 07:46:00  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 34.344s]> Epoch [1/1] | loss: 0.0580, test loss: 0.8499, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.733s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a23.81]-[f0.1923]-[p0.1190]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        16
           1       0.24      1.00      0.38         5

    accuracy                           0.24        21
   macro avg       0.12      0.50      0.19        21
weighted avg       0.06      0.24      0.09        21

                   date  ... support
0   2025-04-14 07:46:01  ...    16.0
1   2025-04-14 07:46:01  ...    16.0
2   2025-04-14 07:46:01  ...    16.0
3   2025-04-14 07:46:01  ...     5.0
4   2025-04-14 07:46:01  ...     5.0
5   2025-04-14 07:46:01  ...     5.0
6   2025-04-14 07:46:01  ...    21.0
7   2025-04-14 07:46:01  ...    21.0
8   2025-04-14 07:46:01  ...    21.0
9   2025-04-14 07:46:01  ...    21.0
10  2025-04-14 07:46:01  ...    21.0
11  2025-04-14 07:46:01  ...    21.0
12  2025-04-14 07:46:01  ...    21.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 34.605s]> Epoch [1/1] | loss: 0.0564, test loss: 0.3557, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.918s]> Saved model weights to "model-weights/a-1-1cn_e-2-2cn_o-2-2cn --> g-3-4cn/dlstm-[a80.95]-[f0.7857]-[p0.7778]-[r0.8750].pt"
              precision    recall  f1-score   support

           0       1.00      0.75      0.86        16
           1       0.56      1.00      0.71         5

    accuracy                           0.81        21
   macro avg       0.78      0.88      0.79        21
weighted avg       0.89      0.81      0.82        21

                   date  ... support
0   2025-04-14 07:46:01  ...    16.0
1   2025-04-14 07:46:01  ...    16.0
2   2025-04-14 07:46:01  ...    16.0
3   2025-04-14 07:46:01  ...     5.0
4   2025-04-14 07:46:01  ...     5.0
5   2025-04-14 07:46:01  ...     5.0
6   2025-04-14 07:46:01  ...    21.0
7   2025-04-14 07:46:01  ...    21.0
8   2025-04-14 07:46:01  ...    21.0
9   2025-04-14 07:46:01  ...    21.0
10  2025-04-14 07:46:01  ...    21.0
11  2025-04-14 07:46:01  ...    21.0
12  2025-04-14 07:46:01  ...    21.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.138s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.144s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.053s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.095s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.035s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.160s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.129s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.087s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.084s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.040s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.147s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.025s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.049s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.038s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.038s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.174s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.055s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.023s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.032s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.051s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.067s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.026s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.117s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.007s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.004s]> Reading in/generating data
Log [0.0h, 0.0m, 0.011s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.079s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.039s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.082s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.021s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.036s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.154s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.045s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.007s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.008s]> Generating tensors

<Tensor Info For Osgeo>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.023s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.088s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.031s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.044s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.010s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.017s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.044s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.012s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.019s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.030s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.024s]> Generating tensors

<Tensor Info For Apache>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.046s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.157s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.022s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.003s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.042s]> Generating tensors

<Tensor Info For Eclipse>
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ + E-2-2cn^ + O-2-2cn^ --> A-1-1cn^^ + E-2-2cn^^ + O-2-2cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	eclipse dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing
	osgeo dataset, version tech: 2, social: 2 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.034s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.099s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.009s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.001s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.020s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.016s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Eclipse For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.037s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.111s]> Generating tensors

<Tensor Info For Eclipse>
<train>
	x: 111
	y: 111
	graduated:          100
	retired:            11
	incubating/skipped: 0

<Tensor For Osgeo For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.006s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.029s]> Generating tensors

<Tensor Info For Osgeo>
<train>
	x: 15
	y: 15
	graduated:          10
	retired:            5
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.067s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.021s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Tensor For Eclipse For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.028s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Eclipse>
<test>
	x: 28
	y: 28
	graduated:          25
	retired:            3
	incubating/skipped: 0

<Tensor For Osgeo For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.005s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.004s]> Generating tensors

<Tensor Info For Osgeo>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
<test>
	x: 5
	y: 5
	graduated:          3
	retired:            2
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Dilated Lstm>
Log [0.0h, 0.0m, 27.227s]> Epoch [1/1] | loss: 0.0595, test loss: 0.1259, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.825s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:46:40  ...    17.0
1   2025-04-14 07:46:40  ...    17.0
2   2025-04-14 07:46:40  ...    17.0
3   2025-04-14 07:46:40  ...    69.0
4   2025-04-14 07:46:40  ...    69.0
5   2025-04-14 07:46:40  ...    69.0
6   2025-04-14 07:46:40  ...    86.0
7   2025-04-14 07:46:40  ...    86.0
8   2025-04-14 07:46:40  ...    86.0
9   2025-04-14 07:46:40  ...    86.0
10  2025-04-14 07:46:40  ...    86.0
11  2025-04-14 07:46:40  ...    86.0
12  2025-04-14 07:46:40  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.574s]> Epoch [1/1] | loss: 0.0601, test loss: 0.3399, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.522s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a76.74]-[f0.4342]-[p0.3976]-[r0.4783].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      0.96      0.87        69

    accuracy                           0.77        86
   macro avg       0.40      0.48      0.43        86
weighted avg       0.64      0.77      0.70        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.757s]> Epoch [1/1] | loss: 0.0583, test loss: 0.1357, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 3.140s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a76.74]-[f0.4788]-[p0.5012]-[r0.5004].pt"
              precision    recall  f1-score   support

           0       0.20      0.06      0.09        17
           1       0.80      0.94      0.87        69

    accuracy                           0.77        86
   macro avg       0.50      0.50      0.48        86
weighted avg       0.68      0.77      0.71        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.740s]> Epoch [1/1] | loss: 0.0588, test loss: 0.1477, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.991s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.622s]> Epoch [1/1] | loss: 0.0597, test loss: 0.1497, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.763s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 27.976s]> Epoch [1/1] | loss: 0.0572, test loss: 0.1157, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.709s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a81.40]-[f0.5036]-[p0.9059]-[r0.5294].pt"
              precision    recall  f1-score   support

           0       1.00      0.06      0.11        17
           1       0.81      1.00      0.90        69

    accuracy                           0.81        86
   macro avg       0.91      0.53      0.50        86
weighted avg       0.85      0.81      0.74        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.131s]> Epoch [1/1] | loss: 0.0578, test loss: 0.1947, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.668s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 28.293s]> Epoch [1/1] | loss: 0.0573, test loss: 0.2077, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.608s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a77.91]-[f0.4379]-[p0.3988]-[r0.4855].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      0.97      0.88        69

    accuracy                           0.78        86
   macro avg       0.40      0.49      0.44        86
weighted avg       0.64      0.78      0.70        86

Log [0.0h, 0.0m, 28.104s]> Epoch [1/1] | loss: 0.0587, test loss: 0.1290, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 3.031s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a77.91]-[f0.4847]-[p0.5274]-[r0.5077].pt"
              precision    recall  f1-score   support

           0       0.25      0.06      0.10        17
           1       0.80      0.96      0.87        69

    accuracy                           0.78        86
   macro avg       0.53      0.51      0.48        86
weighted avg       0.70      0.78      0.72        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.709s]> Epoch [1/1] | loss: 0.0614, test loss: 0.2107, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.786s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

                   date  ... support
0   2025-04-14 07:46:41  ...    17.0
1   2025-04-14 07:46:41  ...    17.0
2   2025-04-14 07:46:41  ...    17.0
3   2025-04-14 07:46:41  ...    69.0
4   2025-04-14 07:46:41  ...    69.0
5   2025-04-14 07:46:41  ...    69.0
6   2025-04-14 07:46:41  ...    86.0
7   2025-04-14 07:46:41  ...    86.0
8   2025-04-14 07:46:41  ...    86.0
9   2025-04-14 07:46:41  ...    86.0
10  2025-04-14 07:46:41  ...    86.0
11  2025-04-14 07:46:41  ...    86.0
12  2025-04-14 07:46:41  ...    86.0

[13 rows x 8 columns]
Log [0.0h, 0.0m, 28.584s]> Epoch [1/1] | loss: 0.0575, test loss: 0.2856, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 3.132s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 28.628s]> Epoch [1/1] | loss: 0.0633, test loss: 0.1279, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.479s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 29.405s]> Epoch [1/1] | loss: 0.0582, test loss: 0.1668, lr: 0.001000
Log [0.0h, 0.0m, 0.003s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 1.967s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 29.320s]> Epoch [1/1] | loss: 0.0580, test loss: 0.2592, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.337s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

Log [0.0h, 0.0m, 29.435s]> Epoch [1/1] | loss: 0.0579, test loss: 0.3648, lr: 0.001000
Log [0.0h, 0.0m, 0.004s]> Training completed.
Model Name: DLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 2.070s]> Saved model weights to "model-weights/a-1-1cn^_e-2-2cn^_o-2-2cn^ --> a-1-1cn^^_e-2-2cn^^_o-2-2cn^^/dlstm-[a80.23]-[f0.4452]-[p0.4012]-[r0.5000].pt"
              precision    recall  f1-score   support

           0       0.00      0.00      0.00        17
           1       0.80      1.00      0.89        69

    accuracy                           0.80        86
   macro avg       0.40      0.50      0.45        86
weighted avg       0.64      0.80      0.71        86

INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 3.241s]> Epoch [1/1] | loss: 0.0564, test loss: 0.0305, lr: 0.001000
Log [0.0h, 0.0m, 0.001s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.053s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a92.45]-[f0.8767]-[p0.9556]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       1.00      0.67      0.80        12
           1       0.91      1.00      0.95        41

    accuracy                           0.92        53
   macro avg       0.96      0.83      0.88        53
weighted avg       0.93      0.92      0.92        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.800000    12.0
3   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.911111    41.0
4   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.953488    41.0
6   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.931237    53.0
7   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0
8   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.918736    53.0
9   2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.955556    53.0
10  2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.833333    53.0
11  2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.876744    53.0
12  2025-04-14 08:02:11  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.046s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 2.938s]> Epoch [1/1] | loss: 0.0528, test loss: 0.0584, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.074s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a90.57]-[f0.8515]-[p0.8990]-[r0.8211].pt"
              precision    recall  f1-score   support

           0       0.89      0.67      0.76        12
           1       0.91      0.98      0.94        41

    accuracy                           0.91        53
   macro avg       0.90      0.82      0.85        53
weighted avg       0.90      0.91      0.90        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.888889    12.0
1   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.761905    12.0
3   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.909091    41.0
4   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.975610    41.0
5   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.941176    41.0
6   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.904517    53.0
7   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.905660    53.0
8   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.900587    53.0
9   2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.898990    53.0
10  2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.821138    53.0
11  2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.851541    53.0
12  2025-04-14 08:02:19  A-1-1cn^ --> A-1-1cn^^  ...  0.905660    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.047s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 3.112s]> Epoch [1/1] | loss: 0.0542, test loss: 0.1088, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.088s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a84.91]-[f0.7056]-[p0.9184]-[r0.6667].pt"
              precision    recall  f1-score   support

           0       1.00      0.33      0.50        12
           1       0.84      1.00      0.91        41

    accuracy                           0.85        53
   macro avg       0.92      0.67      0.71        53
weighted avg       0.87      0.85      0.82        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.333333    12.0
2   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.500000    12.0
3   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.836735    41.0
4   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.911111    41.0
6   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.873700    53.0
7   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0
8   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.818029    53.0
9   2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.918367    53.0
10  2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    53.0
11  2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.705556    53.0
12  2025-04-14 08:02:27  A-1-1cn^ --> A-1-1cn^^  ...  0.849057    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.020s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.055s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.013s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 3.131s]> Epoch [1/1] | loss: 0.0599, test loss: 0.0390, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.099s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a94.34]-[f0.9215]-[p0.9106]-[r0.9339].pt"
              precision    recall  f1-score   support

           0       0.85      0.92      0.88        12
           1       0.97      0.95      0.96        41

    accuracy                           0.94        53
   macro avg       0.91      0.93      0.92        53
weighted avg       0.95      0.94      0.94        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.846154    12.0
1   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.916667    12.0
2   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.880000    12.0
3   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.975000    41.0
4   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.951220    41.0
5   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.962963    41.0
6   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.945827    53.0
7   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.943396    53.0
8   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.944179    53.0
9   2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.910577    53.0
10  2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.933943    53.0
11  2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.921481    53.0
12  2025-04-14 08:02:35  A-1-1cn^ --> A-1-1cn^^  ...  0.943396    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.019s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.050s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.013s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.012s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 3.094s]> Epoch [1/1] | loss: 0.0569, test loss: 0.0792, lr: 0.001000
Log [0.0h, 0.0m, 0.001s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.069s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a92.45]-[f0.8767]-[p0.9556]-[r0.8333].pt"
              precision    recall  f1-score   support

           0       1.00      0.67      0.80        12
           1       0.91      1.00      0.95        41

    accuracy                           0.92        53
   macro avg       0.96      0.83      0.88        53
weighted avg       0.93      0.92      0.92        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.666667    12.0
2   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.800000    12.0
3   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.911111    41.0
4   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.953488    41.0
6   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.931237    53.0
7   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0
8   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.918736    53.0
9   2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.955556    53.0
10  2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.833333    53.0
11  2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.876744    53.0
12  2025-04-14 08:02:43  A-1-1cn^ --> A-1-1cn^^  ...  0.924528    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.022s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.014s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
Log [0.0h, 0.0m, 3.098s]> Epoch [1/1] | loss: 0.0552, test loss: 0.1369, lr: 0.001000
Log [0.0h, 0.0m, 0.002s]> Training completed.
Model Name: BLSTM
Input size: 13
Hidden size: 64
Number of layers: 2
Log [0.0h, 0.0m, 0.079s]> Saved model weights to "model-weights/a-1-1cn^ --> a-1-1cn^^/blstm-[a79.25]-[f0.5178]-[p0.8942]-[r0.5417].pt"
              precision    recall  f1-score   support

           0       1.00      0.08      0.15        12
           1       0.79      1.00      0.88        41

    accuracy                           0.79        53
   macro avg       0.89      0.54      0.52        53
weighted avg       0.84      0.79      0.72        53

                   date       transfer_strategy  ...      perf support
0   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    12.0
1   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.083333    12.0
2   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.153846    12.0
3   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.788462    41.0
4   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  1.000000    41.0
5   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.881720    41.0
6   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.836357    53.0
7   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.792453    53.0
8   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.716919    53.0
9   2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.894231    53.0
10  2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.541667    53.0
11  2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.517783    53.0
12  2025-04-14 08:02:50  A-1-1cn^ --> A-1-1cn^^  ...  0.792453    53.0

[13 rows x 8 columns]
INFO: Pandarallel will run on 12 workers.
INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.

<Decoded Transfer Strategy>
Original: `A-1-1cn^ --> A-1-1cn^^`
Options selected for train set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 80.00% of the data reserved for training
Options selected for test set:
	apache dataset, version tech: 1, social: 1 with feature-subset, normalize-actdev using 20.00% of the data reserved for testing

<Generating Tensors For Model Data>

<Tensor For Apache For Train>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.015s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.054s]> Generating tensors

<Tensor Info For Apache>
<train>
	x: 210
	y: 210
	graduated:          164
	retired:            46
	incubating/skipped: 0

<Tensor For Apache For Test>
Log [0.0h, 0.0m, 0.000s]> Setting up netdata
Log [0.0h, 0.0m, 0.000s]> Reading in/generating data
Log [0.0h, 0.0m, 0.014s]> Generating project status, split
Log [0.0h, 0.0m, 0.000s]> Generating data lookup
Log [0.0h, 0.0m, 0.015s]> Generating tensors

<Tensor Info For Apache>
<test>
	x: 53
	y: 53
	graduated:          41
	retired:            12
	incubating/skipped: 0

<Model Setup>
using ***cuda*** for training...

<Model Chosen :: Bidirectional Lstm>
